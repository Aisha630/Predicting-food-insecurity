{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 **Re-Implementation of \"Predicting Food Crises Using News Streams\"**\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 **Objective**\n",
    "\n",
    "This notebook aims to **reproduce and analyze** the methodology presented in the paper:\n",
    "\n",
    "📄 **Paper:** [Predicting food crises using news streams](https://www.science.org/doi/10.1126/sciadv.abm3449)  \n",
    "📊 **Dataset:** [Harvard Dataverse Repository](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CJDWUW)  \n",
    "📜 **Original Code & Methods:** [GitHub - Regression Modeling (Step 5)](https://github.com/philippzi98/food_insecurity_predictions_nlp/blob/main/Step%205%20-%20Regression%20Modelling/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🛠 **Methodology**\n",
    "\n",
    "This implementation follows the **key steps** outlined in the paper to predict **food insecurity crises** using a combination of:\n",
    "1️⃣ **Traditional Risk Factors** (conflict, climate, food prices, etc.)  \n",
    "2️⃣ **News-Based Indicators** (text feature frequencies from news articles)  \n",
    "3️⃣ **Lagging & Aggregation** (temporal dependencies at district, province, and country levels)  \n",
    "4️⃣ **Machine Learning Models** (Random Forest, OLS, Lasso)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔗 **Reference Materials**\n",
    "\n",
    "📄 **Supplementary Material:** Available in `supplemental_material_from_paper.pdf`  \n",
    "📊 **Datasets Used:**\n",
    "\n",
    "- `time_series_with_causes_zscore_full.csv` (Main dataset with time-series features)\n",
    "- `famine-country-province-district-years-CS.csv` (Food insecurity classification)\n",
    "- `matching_districts.csv` (Geographical standardization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚🔧 Import Libraries\n",
    "\n",
    "In this notebook, we will use uv to manage our Python environment and packages efficiently. uv is a modern and fast package manager that simplifies virtual environment creation, and dependency installation. We will create a virtual environment, install necessary libraries, and ensure our environment stays consistent across different setups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncoment the below cell to install `uv` if you have not already. You can also install it trhiugh `pip` by running `!pip install uv` but this will be within your current python environment and not globally.\n",
    "\n",
    "# !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# !uv venv world-bank\n",
    "# !source world-bank/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "from fuzzywuzzy import fuzz\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have the data downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 Load and Clean Data\n",
    "\n",
    "**Understanding the Time-Series Dataset & Column Selection**\n",
    "\n",
    "This dataset contains **district-level time-series data** on food insecurity risk factors, including:\n",
    "\n",
    "- **📅 Temporal Information:** `year`, `month`, `year_month`\n",
    "- **📍 Geographical Identifiers:** `admin_code`, `admin_name`, `province`, `country`\n",
    "- **🌍 Traditional Risk Factors:** Climate (`rain_mean`, `ndvi_mean`), conflict (`acled_count`), food prices (`p_staple_food`)\n",
    "- **📰 News-Based Indicators:** Proportions of news articles mentioning crisis-related keywords (`conflict_0`, `famine_0`, etc.)\n",
    "- **📉 Food Insecurity Label:** `fews_ipc` (Integrated Phase Classification)\n",
    "\n",
    "🔥 **Columns We Will Drop & Why**\n",
    "✔ **Redundant Aggregations:** `_1`, `_2` columns (province & country-level values) since we will recompute aggregations from scratch anyways.  \n",
    "✔ **Unnamed/Index Columns:** `Unnamed: 0` as it is unnecessary. It is just a duplicate of default index.\n",
    "✔ **Unnecessary Identifiers:** If `admin_code` and `admin_name`, after matching these to `matching_districts.csv`, we can drop them.\n",
    "\n",
    "---\n",
    "\n",
    "> ⚠️ **NOTE:**  \n",
    "> For a detailed explanation of the dataset and features, refer to the [`explore_time_series.ipynb`](./explore_time_series.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = pd.read_csv('./data/time_series_with_causes_zscore_full.csv')\n",
    "admins = pd.read_csv('./data/famine-country-province-district-years-CS.csv')\n",
    "valid_matching = pd.read_csv('./data/matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>centx</th>\n",
       "      <th>centy</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon_2</th>\n",
       "      <th>mayhem_0</th>\n",
       "      <th>mayhem_1</th>\n",
       "      <th>mayhem_2</th>\n",
       "      <th>dehydrated_0</th>\n",
       "      <th>dehydrated_1</th>\n",
       "      <th>dehydrated_2</th>\n",
       "      <th>mismanagement_0</th>\n",
       "      <th>mismanagement_1</th>\n",
       "      <th>mismanagement_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>-0.171000</td>\n",
       "      <td>-0.833000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>1.284667</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>-0.427667</td>\n",
       "      <td>0.668333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660812</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.520247</td>\n",
       "      <td>-0.782913</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.612254</td>\n",
       "      <td>-0.926921</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>-0.625133</td>\n",
       "      <td>-0.452467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.844333</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>-0.689667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>-0.471333</td>\n",
       "      <td>0.955333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326927</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>0.164790</td>\n",
       "      <td>-0.905210</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-0.810600</td>\n",
       "      <td>-0.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.085146</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.867913</td>\n",
       "      <td>-0.770247</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.974587</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>-0.709800</td>\n",
       "      <td>-0.622800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index      country  admin_code admin_name      centx  \\\n",
       "0           0     30  Afghanistan         202   Kandahar  65.709343   \n",
       "1           1     33  Afghanistan         202   Kandahar  65.709343   \n",
       "2           2     36  Afghanistan         202   Kandahar  65.709343   \n",
       "3           3     39  Afghanistan         202   Kandahar  65.709343   \n",
       "4           4     42  Afghanistan         202   Kandahar  65.709343   \n",
       "\n",
       "       centy year_month  year  month  ...  carbon_2  mayhem_0  mayhem_1  \\\n",
       "0  31.043618    2009_07  2009      7  ...  1.053000  0.667000 -0.171000   \n",
       "1  31.043618    2009_10  2009     10  ... -0.660812 -0.636580 -0.520247   \n",
       "2  31.043618    2010_01  2010      1  ... -0.134333  1.447667 -0.844333   \n",
       "3  31.043618    2010_04  2010      4  ... -0.326927 -0.594877  0.164790   \n",
       "4  31.043618    2010_07  2010      7  ... -1.085146 -0.709913 -0.867913   \n",
       "\n",
       "   mayhem_2  dehydrated_0  dehydrated_1  dehydrated_2  mismanagement_0  \\\n",
       "0 -0.833000      0.173667      0.168000      1.284667        -0.073000   \n",
       "1 -0.782913     -0.671587     -0.612254     -0.926921        -0.510467   \n",
       "2  0.778667     -0.676000     -0.689667      0.293333         0.530333   \n",
       "3 -0.905210     -0.620540      0.165794      0.045794        -1.011600   \n",
       "4 -0.770247     -0.787921     -0.974587     -0.946921        -0.611133   \n",
       "\n",
       "   mismanagement_1  mismanagement_2  \n",
       "0        -0.427667         0.668333  \n",
       "1        -0.625133        -0.452467  \n",
       "2        -0.471333         0.955333  \n",
       "3        -0.810600        -0.205600  \n",
       "4        -0.709800        -0.622800  \n",
       "\n",
       "[5 rows x 532 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = ['ndvi_mean', 'ndvi_anom', 'rain_mean', 'rain_anom', 'et_mean', 'et_anom', \n",
    "                                    'acled_count', 'acled_fatalities', 'p_staple_food']\n",
    "t_invariant_traditional_factors = ['area', 'cropland_pct', 'pop', 'ruggedness_mean', 'pasture_pct']\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'land seizures_0'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count BEFORE dropping:  532\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count BEFORE dropping: \", len(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Unnamed: 0\", \"centx\", \"centy\", 'change_fews', 'fews_ha', 'fews_proj_med', 'fews_proj_med_ha', 'fews_proj_near_ha'] + [col for col in time_series.columns if col.endswith(('_1', '_2', '_3'))]\n",
    "time_series.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential extra columns ['country', 'year_month', 'admin_code', 'admin_name', 'fews_proj_near', 'year', 'index', 'fews_ipc', 'month']\n"
     ]
    }
   ],
   "source": [
    "potential_extra_cols = set(time_series.columns.values) - set(t_variant_traditional_factors) - set(t_invariant_traditional_factors) - set(news_factors)\n",
    "potential_extra_cols = [col for col in potential_extra_cols if not col.endswith(('_1', '_2', '_3'))]\n",
    "print(\"Potential extra columns\", potential_extra_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count after dropping:  190\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count after dropping: \", len(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌍 Admin Level Mapping: Standardizing Geographical Identifiers\n",
    "\n",
    "In this section, we will **map and standardize** the `admin_code` and `admin_name` fields to their corresponding **district, province, and country names**. This step is **crucial** for ensuring **consistency** across different datasets and enabling **accurate aggregations** at multiple administrative levels.\n",
    "\n",
    "🛠 **Why is Admin Level Mapping Important?**\n",
    "✅ Different datasets may use **slightly different spellings or formats** for district names.  \n",
    "✅ Some district names might be **missing or misspelled**, requiring standardization.  \n",
    "✅ We need to **match and align** district names across various sources before aggregating at **province and country levels**.  \n",
    "✅ Proper mapping allows us to **merge datasets correctly** without losing information.  \n",
    "\n",
    "📌 **Steps in Admin Mapping**\n",
    "1️⃣ **Load the `matching_districts.csv` file**, which provides the mapping between different district name variations.  \n",
    "2️⃣ **Identify missing or unmatched `admin_name` values** and find their closest matches using fuzzy matching techniques.  \n",
    "3️⃣ **Ensure that each `admin_code` uniquely maps to one `district`, `province`, and `country`.**  \n",
    "4️⃣ **Replace inconsistent names** in the dataset with their standardized versions.  \n",
    "5️⃣ **Aggregate data at the `province` and `country` levels** after ensuring all districts are correctly mapped.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(admins.country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'country', 'district', 'year', 'month', 'CS',\n",
       "       'province'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admins.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142 4113 474 39\n",
      "369\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy String Matching for Missing Names\n",
    "\n",
    "The function uses **fuzzy string matching** to find the best approximate matches for missing administrative names (e.g., districts and provinces). \n",
    "\n",
    "- Finds the **best matching district/province** for each missing name.\n",
    "- Uses **fuzzy string matching** to calculate the similarity between missing names and known names.\n",
    "- Returns a dictionary that maps each missing name to its closest match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saint-Raphael Saint Raphael Santa Rosa\n",
      "North al Gazera Ganze North\n",
      "Mangwe (South) Mangwe Southern\n",
      "Agnuak Awgu Ouaka\n",
      "Nyala.1 Nyala Nyamira\n",
      "Balleyara Bale Mara\n",
      "La Pendé La Pende Lac\n",
      "Muranga Mkuranga Murang'a\n",
      "Al Rahd El Rahad Al Mahrah\n",
      "Chegutu Chegutu Rural Hodh ech Chargui\n",
      "Khartoum Bahri Khartoum Khartoum\n",
      "Mwene-Ditu City of Mwene-Ditu Kitui\n",
      "Bankilaré Bankilare Sila\n",
      "Adan Yabaal Aadan Yabaal `Adan\n",
      "Sharg En Nile Sahar Niger\n",
      "Illéla Illela Sila\n",
      "Tanganyka Tanga Tanga\n",
      "Gonave La Gonave Gao\n",
      "Siti Sirisia Simiyu\n",
      "Galdogob Goldogob Edo\n",
      "Hamashkorieb Hamashkoreib Ghor\n",
      "North Shewa(R4) North Shewa North\n",
      "Nahr Atbara Atbara Mara\n",
      "Al Marawi'ah Marawi Mara\n",
      "East al Gazera Ganze Gaza\n",
      "Merawi Marawi Mara\n",
      "Mt Elgon Mt. Elgon Khatlon\n",
      "Ville de Niamey Ndia Niamey\n",
      "Sheikan Shiekan Shinyanga\n",
      "Gedio Gedeo Gedo\n",
      "Chiredzi Chiredzi Rural Moyen-Chari\n",
      "En Nuhud Al Nuhud Sud\n",
      "Nandi South Nnewi South Nandi\n",
      "Burtinle Butinle Iilemi triangle\n",
      "Baw Bahr El Arab Western Bahr el Ghazal\n",
      "As Salam Shar`ab As Salam Dar es Salaam\n",
      "Belet Weyne Bale Benue\n",
      "Gwanda Gwanda Rural Nyandarua\n",
      "Kasai.1 Kpaai Kasai\n",
      "Likasi City of Likasi Laikipia\n",
      "Port-Au-Prince Port au Prince Ituri\n",
      "Kelem Wellega Kelem Kwale\n",
      "Mawza' Mawza` Gaza\n",
      "Lughaye Lughaya Bay\n",
      "Iriba Nyaribari Masaba Central Equatoria\n",
      "Al Fasher El Fasher Al Mahrah\n",
      "La Nya Pendé La Nya Lac\n",
      "Mwingi Mwingi North Migori\n",
      "Grande Riviere Du Nord Grande Riviere du Nord Nord\n",
      "Koibatek Kibra Kogi\n",
      "Croix-Des-Bouquets Bo Ouest\n",
      "Lac-Léré Lac-Lere Lac\n",
      "Valliere Vallieres Zaire\n",
      "Caynabo Caynaba Bay\n",
      "Kananga nan Haut-Katanga\n",
      "Mutare Mutare Rural Mtwara\n",
      "Mbuji-Mayi City of Mbuji-Mayi Bay\n",
      "Bindura Bindura Urban Cabinda\n",
      "Meru South Meru Meru\n",
      "Ceca La Source Cerca La Source Sud\n",
      "Kindu City of Kindu Kunduz\n",
      "Gweru Gweru Rural Meru\n",
      "Laasqoray Rorya Tabora\n",
      "Gourma-Rharous Gourma Ghor\n",
      "Ville de Zinder Gile Zinder\n",
      "Djourouf Al Ahmar Sourou Amhara\n",
      "Special Woreda Borena Nord\n",
      "Meru Central Meru Central\n",
      "Al Faw El Faw Al Jawf\n",
      "Amanat Al 'Asimah Arsi Amanat Al `Asimah\n",
      "Banadir Dandi Banaadir\n",
      "Shar'ab Ar Rawnah Shar`ab Ar Rawnah Mara\n",
      "Wedza Dedza Gedaref\n",
      "MPongwe Mpongwe Bong\n",
      "Bulo Burto Burco Borno\n",
      "Bulilima (North) Bulilima North\n",
      "Al Kamlin Kamuli Kigali\n",
      "Al Deain Doedain Ali Sabieh\n",
      "Maïné Soroa Maine Soroa Sool\n",
      "Seteet Seme Tete\n",
      "Komonjdjari Komondjari Bari\n",
      "Jebrat al Sheikh Jebrat El Sheikh Herat\n",
      "Abu Jubaiyah Juba Raymah\n",
      "Majang Marangara Mahajanga\n",
      "Buret Bureti Blue Nile\n",
      "Ad Dinder Ad Dis Zinder\n",
      "Beni San Benito Benshangul Gumuz\n",
      "Lafon Lopa/Lafon Lac\n",
      "UMP Bench Maji Unity\n",
      "North Gonder North Gondar North\n",
      "Chiengi Chienge Muchinga\n",
      "Damagaram Takaya Takaya Mara\n",
      "Southern Tigray Lira Tigray\n",
      "Kolwezi City of Kolwezi Jonglei\n",
      "Gouré Govuro Ghor\n",
      "Trans Mara Marka Mara\n",
      "KT Koch Haute-Kotto\n",
      "Gebiley Gabiley Blue Nile\n",
      "Goma City of Goma Oromia\n",
      "Mashra'ah wa Hadnan nan Kankan\n",
      "Shabelle Shebelle Middle Shabelle\n",
      "Al Gutaina El Gutaina Rutana\n",
      "Lubumbashi City of Lubumbashi Ruvuma\n",
      "Anse-A-Veau `Ans Lamu\n",
      "Gokwe South Gokwe South Urban Southern\n",
      "Ad Douiem El Douiem Ad Dali`\n",
      "Zvishavane Zvishavane Urban Kanem\n",
      "Doolo Doolow Sool\n",
      "Shar'ab As Salam Shar`ab As Salam Mara\n",
      "Al Roseires El Roseires Zaire\n",
      "Tesker Tasker Western Bahr el Ghazal\n",
      "Al Kurumik Qulansiyah wa `Abd Al Kuri Ituri\n",
      "Gothèye Gotheye Gao\n",
      "Trou Du Nord Trou du Nord Nord\n",
      "Awi/Agew Awi Uige\n",
      "Al Mahagil Mahagi Al Mahrah\n",
      "Téra Tarauni Trans Nzoia\n",
      "Wardi Hawar Wadi Hawar Bari\n",
      "Barh El Gazel Sud Barh el Gazel Sud Sud\n",
      "Ville de Tahoua Tahoua Tahoua\n",
      "Berber Berbera Santa Barbara\n",
      "Um Kadada Um Keddada Kandahar\n",
      "Tulus Tullus Retalhuleu\n",
      "Thika Thika Town Vihiga\n",
      "Bura' Bura Guera\n",
      "Shurugwi Shurugwi Rural Sud\n",
      "Kisangani City of Kisangani Tanga\n",
      "Addis Adaba Alaba Addis Ababa\n",
      "North Shewa(R3) North Shewa North\n",
      "Mangalmé Mangalme Tanga\n",
      "Bale.1 Bale Bay\n",
      "Tillabéri Tillaberi Commune Tillaberi\n",
      "Al Gadaref Gada Gedaref\n",
      "Adan Aldai `Adan\n",
      "Hareri Harari Harari\n",
      "Aguié Aguie Bangui\n",
      "South Gonder South Gondar South Kordofan\n",
      "Ghebeish Nesh Abyei\n",
      "Al Ma'afir Al Ma`afir Mara\n",
      "Eastern Tigray Lira Eastern\n",
      "Al Wazi'iyah Al Wazi`iyah Siaya\n",
      "Kajo-keji Kajo-Keji Kano\n",
      "Port De Paix Port de Paix Pwani\n",
      "Taleex Talex Woqooyi Galbeed\n",
      "Rab Dhuure Rabdhuure Central Darfur\n",
      "Busia.1 Busia Busia\n",
      "Butembo City of Butembo Kemo\n",
      "Guji Gujii Guidimaka\n",
      "Filingué Filingue Enugu\n",
      "Lulua Luuka Lualaba\n",
      "Selti Selibaby Copperbelt\n",
      "Belbedji Bielel Abyei\n",
      "Gucha Kabuchai Ahuachapan\n",
      "Kwekwe Kwekwe Urban Kwale\n",
      "Ad Dali' Ad Dali` Ad Dali`\n",
      "Teso Teso South El Progreso\n",
      "Sa'dah Sa`dah Sa`dah\n",
      "Kibale Kabale Kidal\n",
      "West Harerge West Hararge West Darfur\n",
      "Al Jabalian Jaba Al Jawf\n",
      "Kabia Mambah Kaba Kajiado\n",
      "Mole Saint Nicolas Mole Saint-Nicolas White Nile\n",
      "Addabah Sabah Assaba\n",
      "Rachuonyo Karachuonyo Oyo\n",
      "Al Geneina El Geneina Geita\n",
      "Kolwezi.1 City of Kolwezi Kwale\n",
      "Al Gash Al Hashwah Al Mahrah\n",
      "Segen Peoples' Segen Benue\n",
      "Barh El Gazel Nord Barh el Gazel Nord Nord\n",
      "Meru North Meru Meru\n",
      "Baydhaba Baydhabo Bay\n",
      "Bukavu City of Bukavu Busia\n",
      "Kuria Kuria East Ituri\n",
      "Sharq al Gazera Ganze Gaza\n",
      "Ndjamena Ndia N'Djamena\n",
      "Kantché Kantche Kano\n",
      "Chipinge Chipinge Rural Uige\n",
      "South al Gazera Ganze Gaza\n",
      "Sar-e-Pul Sah Sari Pul\n",
      "Mbeere Mbeere North Mbeya\n",
      "Nandi North Nnewi North Nandi\n",
      "Id El Ghanem Ganze Kanem\n",
      "Sud-Kivu Kiru Sud\n",
      "Keiyo Keiyo South Oyo\n",
      "Acul Du Nord Acul du Nord Nord\n",
      "Sowdari Sodari Bari\n",
      "Mayo-Lemi Mayo-Lemie Bay\n",
      "Tayeeglow Tiyeglow Bay\n",
      "Al Galabat Western El Galabat Gaza\n",
      "Abu Hamad Abu Hamed Hilmand\n",
      "Wadi Halfa Halfa Wadi Fira\n",
      "Owdweyne Oodweyne Benue\n",
      "Saint Louis Du Nord Saint-Louis du Nord Nord\n",
      "Mayo Boneye Bo Boke\n",
      "Barh El Gazel Ouest Barh el Gazel Ouest Ouest\n",
      "At Ta'izziyah At Ta`izziyah Ta'izz\n",
      "Um Al Gura Guera Guera\n",
      "Zallingi Zalingei Singida\n",
      "Western Tigray Lira Western\n",
      "Cayes Les Cayes Kayes\n",
      "Sami' Sami` Haut-Lomami\n",
      "Ad Damazin El Damazine Adamawa\n",
      "East Harerge East Hararge East Darfur\n",
      "Um Badda Um Keddada Bay\n",
      "Ad Damer Same Dhamar\n",
      "South Khartoum Khartoum Khartoum\n",
      "Mayo Binder Mayo-Binder Zinder\n",
      "Kadoma Kadoma Urban Kano\n",
      "Anse-D'Ainault `Ain Abia\n",
      "North Western Tigray Lira Western\n",
      "Al Fushqa Al Husha' Arusha\n",
      "Central Kisii Kiti Central\n",
      "Bossaso Bo Gao\n",
      "Beitbridge Beitbridge Urban Uige\n",
      "Maragua Maragwa Mara\n",
      "Marakwet Marakwet West Elgeyo-Marakwet\n",
      "Sheikh Jebrat El Sheikh Sahel\n",
      "Kabkabiya Kebkabiya Abia\n",
      "Karary Karari Kwara\n",
      "Hirat Wag Himra Hiiraan\n",
      "Ville de Maradi Maridi Mara\n",
      "Belet Xaawo Beled-Xaawo Gao\n",
      "Butere Mumias Butere Muyinga\n",
      "Nord-Kivu Kiru Nord\n",
      "Amran `Amran `Amran\n",
      "Port-Salut Port Salut Salamat\n",
      "Hwange Hwange Rural Iilemi triangle\n",
      "Bandarbeyla Bandar Beyla Mbeya\n",
      "Kas Kasese Kassala\n",
      "Barh-Kôh Barh-Koh Bari\n"
     ]
    }
   ],
   "source": [
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "\n",
    "# manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Decoding\n",
    "\n",
    "`to_ascii_escaped(s)`: Converts a Unicode string to an ASCII-safe representation using **unicode-escape**.\n",
    "\n",
    "`from_ascii_escaped(escaped)`: Converts the escaped ASCII string back into its original Unicode form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    # Using 'unicode-escape' encoding produces a bytes object,\n",
    "    # then decode it to get an ASCII string.\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def from_ascii_escaped(escaped):\n",
    "    \"\"\"\n",
    "    Convert the ASCII-escaped string back to the original Unicode string.\n",
    "    \"\"\"\n",
    "    # Encode the ASCII string to bytes, then decode using 'unicode-escape'\n",
    "    return escaped.encode('ascii').decode('unicode-escape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Province for a Given District or Province\n",
    "\n",
    "`find_province(x)`, finds the **province** corresponding to a given administrative name. It accounts for:\n",
    "- **Direct Lookups** (Exact match in known district/province lists)\n",
    "- **Fuzzy Matching** (Using ASCII-safe transformation for inconsistent text encoding)\n",
    "- **Validation Against a Predefined Mapping (`valid_matching`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matched globally\n",
    "matched = valid_matching['missing'].unique()\n",
    "\n",
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def find_province(x):\n",
    "    try:\n",
    "        # Ensure x is a Unicode string.\n",
    "        if isinstance(x, bytes):\n",
    "            x = x.decode('utf-8')\n",
    "        \n",
    "        # Direct lookup in districts or provinces.\n",
    "        if x in districts:\n",
    "            return admins[admins['district'] == x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "\n",
    "        # Convert x to an ASCII-escaped version.\n",
    "        escaped_x = to_ascii_escaped(x)\n",
    "        \n",
    "        # Check if the escaped version is in matched.\n",
    "        if escaped_x in matched:\n",
    "            v = valid_matching[valid_matching['missing'] == escaped_x]\n",
    "            if v['match'].values[0] == 'district':\n",
    "                x2 = v['district'].values[0]\n",
    "                return admins[admins['district'] == x2]['province'].values[0]\n",
    "            elif v['match'].values[0] == 'province':\n",
    "                return v['province'].values[0]\n",
    "        \n",
    "        # If no conditions are met, raise an exception.\n",
    "        raise Exception(\"No matching province found\")\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Province not found for: {} ({})\".format(x, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Admin Names with Accented Characters and Mapping to Provinces\n",
    "\n",
    "Maps `admin_names` to provinces using the `find_province(a)` function.  \n",
    "If a **direct lookup fails**, it tries to handle cases where the **admin name contains accented characters** (`é`, `è`, `ô`) ->  (encoding decoding issues resolved through directly replacing these with 'e' or 'o', leads to finding a valid match). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with: Mangalmé\n",
      "Replaced 'Mangalmé' with 'Mangalme', found province: Guera\n",
      "Error with: La Pendé\n",
      "Replaced 'La Pendé' with 'La Pende', found province: Logone Oriental\n",
      "Error with: La Nya Pendé\n",
      "Replaced 'La Nya Pendé' with 'La Nya Pende', found province: Logone Oriental\n",
      "Error with: Lac-Léré\n",
      "Replaced 'Lac-Léré' with 'Lac-Lere', found province: Mayo-Kebbi Ouest\n",
      "Error with: Barh-Kôh\n",
      "Replaced 'Barh-Kôh' with 'Barh-Koh', found province: Moyen-Chari\n",
      "Error with: Aguié\n",
      "Replaced 'Aguié' with 'Aguie', found province: Maradi\n",
      "Error with: Bankilaré\n",
      "Replaced 'Bankilaré' with 'Bankilare', found province: Tillaberi\n",
      "Error with: Filingué\n",
      "Replaced 'Filingué' with 'Filingue', found province: Tillaberi\n",
      "Error with: Gothèye\n",
      "Replaced 'Gothèye' with 'Gotheye', found province: Tillaberi\n",
      "Error with: Gouré\n",
      "Replaced 'Gouré' with 'Goure', found province: Zinder\n",
      "Error with: Illéla\n",
      "Replaced 'Illéla' with 'Illela', found province: Sokoto\n",
      "Error with: Kantché\n",
      "Replaced 'Kantché' with 'Kantche', found province: Zinder\n",
      "Error with: Maïné Soroa\n",
      "Modified name 'Maïne Soroa' not in districts.\n",
      "Error with: Téra\n",
      "Replaced 'Téra' with 'Tera', found province: Tillaberi\n",
      "Error with: Tillabéri\n",
      "Replaced 'Tillabéri' with 'Tillaberi', found province: Tillaberi\n"
     ]
    }
   ],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except Exception as e:\n",
    "        # Print the admin name that caused an error\n",
    "        print(\"Error with:\", a)\n",
    "        # Check if a contains accented characters \"é\" or \"è\"\n",
    "        if 'é' in a or 'è' in a or 'ô' in a:\n",
    "            a_modified = a.replace('é', 'e').replace('è', 'e').replace('ô', 'o')\n",
    "            # Check if the modified name is in districts\n",
    "            if a_modified in districts:\n",
    "                # Use the modified name to look up the province from admins\n",
    "                try:\n",
    "                    province = admins[admins['district'] == a_modified]['province'].values[0]\n",
    "                    admin_to_province[a] = province\n",
    "                    print(f\"Replaced '{a}' with '{a_modified}', found province: {province}\")\n",
    "                except Exception as ex:\n",
    "                    print(f\"Modified name '{a_modified}' not found in admins: {ex}\")\n",
    "            else:\n",
    "                print(f\"Modified name '{a_modified}' not in districts.\")\n",
    "        else:\n",
    "            print(f\"No accented e found in '{a}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Administrative Names to Provinces in time_series\n",
    "\n",
    "Maps `admin_name` to their respective **provinces** using a precomputed dictionary - >`admin_to_province` in `time_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series['province'] = time_series['admin_name'].apply(\n",
    "    lambda x: admin_to_province[x] if x in admin_to_province else admin_to_province.get(x.replace('ô', 'o'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series[[\"admin_name\", \"province\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⏳ Time Lagging & Feature Engineering\n",
    "\n",
    "#### 📅 **Why Use Lagging?**\n",
    "\n",
    "To predict food insecurity **for a given quarter**, we use:\n",
    "\n",
    "- **6 months of historical values** for traditional & news-based features.\n",
    "- **Province & country-level aggregations** to capture broader shocks.\n",
    "- **6 quarters of lagged IPC phase values** to model temporal dependencies.\n",
    "\n",
    "#### ⚡ **Optimized Lagging Approach**\n",
    "\n",
    "To improve computational efficiency, we:\n",
    "✔ Use `groupby()` for **fast province & country-level aggregations**.  \n",
    "✔ Merge lagged data via `merge()` instead of slow `.apply()`.  \n",
    "✔ Only keep **past data** to ensure no data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True, time_series=time_series):\n",
    "    levels = ['', '_province', '_country'] if agg else ['']\n",
    "    \n",
    "    # Work on a copy to avoid modifying the original during processing\n",
    "    working_df = time_series.copy()\n",
    "    \n",
    "    # Precompute a mapping for each feature (with its suffix) for fast lookups.\n",
    "    # For each row, its lookup key will be: admin_code + '_' + year_month.\n",
    "    lookup_maps = {}  # dict mapping f_s -> mapping dict\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f + suffix\n",
    "            # Build a mapping from key to first occurrence of f_s value.\n",
    "            # Key: admin_code + '_' + year_month\n",
    "            keys = working_df['admin_code'].astype(str) + '_' + working_df['year_month'].astype(str)\n",
    "            # If there are duplicates, the first occurrence will be used.\n",
    "            mapping = dict(zip(keys, working_df[f_s]))\n",
    "            lookup_maps[f_s] = mapping\n",
    "\n",
    "    # Prepare list to collect all new columns (as Series)\n",
    "    new_cols = {}\n",
    "    \n",
    "    # Process each feature and lag combination\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f + suffix\n",
    "            mapping = lookup_maps[f_s]\n",
    "            for t in range(start, end, diff):\n",
    "                col_name = f\"{f_s}_{t}\"\n",
    "                if col_name in time_series.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Compute lagged month and lagged year (vectorized)\n",
    "                month = working_df['month']\n",
    "                year = working_df['year']\n",
    "                l_month = ((month - 1 - t) % 12) + 1\n",
    "                l_year = np.where(month - t <= 0, year - 1, year) # If (month - t) is less than or equal to 0 (i.e., you’ve gone into the previous year), then l_year is year - 1; otherwise, it remains year.\n",
    "                \n",
    "                # Build the reference key: admin_code + '_' + \"{l_year}_{l_month}\"\n",
    "                ref_key = working_df['admin_code'].astype(str) + '_' + \\\n",
    "                          l_year.astype(str) + '_' + \\\n",
    "                          l_month.astype(str)\n",
    "                \n",
    "                # Map the reference key to the lagged feature values using our precomputed mapping.\n",
    "                # Where no match is found, use the current value from working_df[f_s].\n",
    "                lagged_values = ref_key.map(mapping)\n",
    "                lagged_values = lagged_values.fillna(working_df[f_s])\n",
    "                \n",
    "                # Store the new column in our dictionary (preserving the original index)\n",
    "                new_cols[col_name] = lagged_values\n",
    "                \n",
    "    # If any new columns were created, add them to the original time_series DataFrame.\n",
    "    if new_cols:\n",
    "        new_cols_df = pd.DataFrame(new_cols, index=working_df.index)\n",
    "        time_series = pd.concat([time_series, new_cols_df], axis=1)\n",
    "        \n",
    "    return time_series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Province & Country-Level Aggregation\n",
    "\n",
    "This function aggregates feature values at the province and country levels to capture regional trends, aiding in food insecurity prediction. The process includes:\n",
    "\n",
    "- **Grouping by year_month and level:** Data is grouped by year_month and the specified level (province or country) to calculate the mean of features, reflecting regional trends over time.\n",
    "\n",
    "- **Applying transformations efficiently:** Instead of merging aggregated data, `transform(\"mean\")` is used to directly assign the computed mean to each row, avoiding unnecessary joins and improving performance.  \n",
    "\n",
    "#### ⚡ **Efficiency Gains**\n",
    "\n",
    "- **Fast Aggregation**: Uses `groupby()` for efficient aggregation.\n",
    "- **Avoids Costly Joins**: Eliminates the need for `merge()` by using `transform()` instead, reducing computational overhead.  \n",
    "- **Memory Efficiency**: Converts the `level` column to a categorical type to reduce memory usage.\n",
    "\n",
    "This approach ensures faster processing while maintaining the quality of aggregated features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_agg_factors(features, level='province'):\n",
    "    global time_series  \n",
    "\n",
    "    # Convert 'level' column to categorical for performance\n",
    "    time_series[level] = time_series[level].astype('category')\n",
    "    \n",
    "    # Compute grouped mean values for the given features\n",
    "    # TODO : Explain these arguments\n",
    "    grouped_df = time_series.groupby(['year_month', level], observed=True, sort=False)[features].transform(\"mean\")\n",
    "\n",
    "    # Rename columns to include level\n",
    "    grouped_df = grouped_df.rename(columns={f: f\"{f}_{level}\" for f in features})\n",
    "\n",
    "    # Use pd.concat() to add all columns at once, avoiding fragmentation\n",
    "    time_series = pd.concat([time_series, grouped_df], axis=1)\n",
    "\n",
    "    return time_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gastrointestinal_0_country</th>\n",
       "      <th>terrorist_0_country</th>\n",
       "      <th>warlord_0_country</th>\n",
       "      <th>d'etat_0_country</th>\n",
       "      <th>overthrow_0_country</th>\n",
       "      <th>convoys_0_country</th>\n",
       "      <th>carbon_0_country</th>\n",
       "      <th>mayhem_0_country</th>\n",
       "      <th>dehydrated_0_country</th>\n",
       "      <th>mismanagement_0_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.196791</td>\n",
       "      <td>-0.277796</td>\n",
       "      <td>-0.080313</td>\n",
       "      <td>-0.158093</td>\n",
       "      <td>-0.091979</td>\n",
       "      <td>-0.205168</td>\n",
       "      <td>-0.351945</td>\n",
       "      <td>-0.004046</td>\n",
       "      <td>0.020729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123518</td>\n",
       "      <td>-0.169664</td>\n",
       "      <td>-0.039284</td>\n",
       "      <td>0.096598</td>\n",
       "      <td>-0.145231</td>\n",
       "      <td>-0.058545</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>-0.060053</td>\n",
       "      <td>-0.112890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194285</td>\n",
       "      <td>-0.051662</td>\n",
       "      <td>0.112230</td>\n",
       "      <td>0.271666</td>\n",
       "      <td>0.351302</td>\n",
       "      <td>0.175470</td>\n",
       "      <td>0.236345</td>\n",
       "      <td>0.159935</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.409551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073142</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>0.135643</td>\n",
       "      <td>0.204327</td>\n",
       "      <td>0.101177</td>\n",
       "      <td>-0.144836</td>\n",
       "      <td>0.222670</td>\n",
       "      <td>0.156061</td>\n",
       "      <td>0.274630</td>\n",
       "      <td>0.180825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158150</td>\n",
       "      <td>-0.068429</td>\n",
       "      <td>-0.161717</td>\n",
       "      <td>-0.187331</td>\n",
       "      <td>-0.139090</td>\n",
       "      <td>-0.142929</td>\n",
       "      <td>-0.010496</td>\n",
       "      <td>-0.081932</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_10</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>-0.085573</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>-0.040194</td>\n",
       "      <td>0.053930</td>\n",
       "      <td>-0.185165</td>\n",
       "      <td>0.172638</td>\n",
       "      <td>-0.085029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_01</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059419</td>\n",
       "      <td>-0.050372</td>\n",
       "      <td>-0.144964</td>\n",
       "      <td>-0.140235</td>\n",
       "      <td>-0.056617</td>\n",
       "      <td>-0.232453</td>\n",
       "      <td>-0.117227</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>-0.111434</td>\n",
       "      <td>-0.100282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_04</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283481</td>\n",
       "      <td>-0.311409</td>\n",
       "      <td>-0.295271</td>\n",
       "      <td>-0.370462</td>\n",
       "      <td>-0.298859</td>\n",
       "      <td>-0.246249</td>\n",
       "      <td>-0.109567</td>\n",
       "      <td>-0.168876</td>\n",
       "      <td>-0.335914</td>\n",
       "      <td>-0.276873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_07</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198956</td>\n",
       "      <td>0.232582</td>\n",
       "      <td>0.165008</td>\n",
       "      <td>0.475172</td>\n",
       "      <td>0.257077</td>\n",
       "      <td>0.246208</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.217305</td>\n",
       "      <td>0.162207</td>\n",
       "      <td>0.096265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_10</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456875</td>\n",
       "      <td>-0.102239</td>\n",
       "      <td>0.338327</td>\n",
       "      <td>0.302879</td>\n",
       "      <td>0.120221</td>\n",
       "      <td>0.354626</td>\n",
       "      <td>0.248271</td>\n",
       "      <td>0.316393</td>\n",
       "      <td>0.335178</td>\n",
       "      <td>0.232545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      country  admin_code admin_name year_month  year  month  \\\n",
       "0     30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1     33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2     36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3     39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4     42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "5     45  Afghanistan         202   Kandahar    2010_10  2010     10   \n",
       "6     48  Afghanistan         202   Kandahar    2011_01  2011      1   \n",
       "7     51  Afghanistan         202   Kandahar    2011_04  2011      4   \n",
       "8     54  Afghanistan         202   Kandahar    2011_07  2011      7   \n",
       "9     57  Afghanistan         202   Kandahar    2011_10  2011     10   \n",
       "\n",
       "   fews_ipc  fews_proj_near  ndvi_mean  ...  gastrointestinal_0_country  \\\n",
       "0       1.0             NaN   0.106035  ...                    0.009191   \n",
       "1       1.0             NaN   0.103009  ...                   -0.123518   \n",
       "2       2.0             NaN   0.109600  ...                    0.194285   \n",
       "3       2.0             NaN   0.111599  ...                   -0.073142   \n",
       "4       1.0             NaN   0.096943  ...                    0.158150   \n",
       "5       2.0             NaN   0.095377  ...                    0.014290   \n",
       "6       2.0             NaN   0.092620  ...                   -0.059419   \n",
       "7       2.0             2.0   0.131462  ...                   -0.283481   \n",
       "8       1.0             1.0   0.106885  ...                    0.198956   \n",
       "9       1.0             1.0   0.103268  ...                    0.456875   \n",
       "\n",
       "   terrorist_0_country  warlord_0_country  d'etat_0_country  \\\n",
       "0            -0.196791          -0.277796         -0.080313   \n",
       "1            -0.169664          -0.039284          0.096598   \n",
       "2            -0.051662           0.112230          0.271666   \n",
       "3            -0.122469           0.135643          0.204327   \n",
       "4            -0.068429          -0.161717         -0.187331   \n",
       "5            -0.021839           0.010606         -0.085573   \n",
       "6            -0.050372          -0.144964         -0.140235   \n",
       "7            -0.311409          -0.295271         -0.370462   \n",
       "8             0.232582           0.165008          0.475172   \n",
       "9            -0.102239           0.338327          0.302879   \n",
       "\n",
       "   overthrow_0_country  convoys_0_country  carbon_0_country  mayhem_0_country  \\\n",
       "0            -0.158093          -0.091979         -0.205168         -0.351945   \n",
       "1            -0.145231          -0.058545          0.024883          0.039075   \n",
       "2             0.351302           0.175470          0.236345          0.159935   \n",
       "3             0.101177          -0.144836          0.222670          0.156061   \n",
       "4            -0.139090          -0.142929         -0.010496         -0.081932   \n",
       "5             0.147253          -0.040194          0.053930         -0.185165   \n",
       "6            -0.056617          -0.232453         -0.117227          0.117000   \n",
       "7            -0.298859          -0.246249         -0.109567         -0.168876   \n",
       "8             0.257077           0.246208          0.089489          0.217305   \n",
       "9             0.120221           0.354626          0.248271          0.316393   \n",
       "\n",
       "   dehydrated_0_country  mismanagement_0_country  \n",
       "0             -0.004046                 0.020729  \n",
       "1             -0.060053                -0.112890  \n",
       "2              0.198416                 0.409551  \n",
       "3              0.274630                 0.180825  \n",
       "4              0.007388                 0.138598  \n",
       "5              0.172638                -0.085029  \n",
       "6             -0.111434                -0.100282  \n",
       "7             -0.335914                -0.276873  \n",
       "8              0.162207                 0.096265  \n",
       "9              0.335178                 0.232545  \n",
       "\n",
       "[10 rows x 525 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = add_agg_factors(news_factors, level='country')\n",
    "time_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = add_agg_factors(t_variant_traditional_factors, level='province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = add_agg_factors(t_variant_traditional_factors, level='country')\n",
    "t = add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "t = add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series.to_csv('ours_agg_province_features_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time lagged features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(t_variant_traditional_factors, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_csv('ours_modifed_time_series_tvariant_all_rows.csv')\n",
    "\n",
    "# raise Exception(\"Stop here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(news_factors, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3728,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series.to_csv(\"our_results_final_all_30.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mismanagement_0_country_6</th>\n",
       "      <th>mismanagement_0_country_7</th>\n",
       "      <th>mismanagement_0_country_8</th>\n",
       "      <th>fews_ipc_3</th>\n",
       "      <th>fews_ipc_6</th>\n",
       "      <th>fews_ipc_9</th>\n",
       "      <th>fews_ipc_12</th>\n",
       "      <th>fews_ipc_15</th>\n",
       "      <th>fews_ipc_18</th>\n",
       "      <th>fews_proj_near_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>0.180825</td>\n",
       "      <td>0.180825</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138598</td>\n",
       "      <td>0.138598</td>\n",
       "      <td>0.138598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      country  admin_code admin_name year_month  year  month  \\\n",
       "0     30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1     33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2     36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3     39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4     42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "\n",
       "   fews_ipc  fews_proj_near  ndvi_mean  ...  mismanagement_0_country_6  \\\n",
       "0       1.0             NaN   0.106035  ...                   0.020729   \n",
       "1       1.0             NaN   0.103009  ...                  -0.112890   \n",
       "2       2.0             NaN   0.109600  ...                   0.409551   \n",
       "3       2.0             NaN   0.111599  ...                  -0.112890   \n",
       "4       1.0             NaN   0.096943  ...                   0.138598   \n",
       "\n",
       "   mismanagement_0_country_7  mismanagement_0_country_8  fews_ipc_3  \\\n",
       "0                   0.020729                   0.020729         1.0   \n",
       "1                  -0.112890                  -0.112890         1.0   \n",
       "2                   0.409551                   0.409551         1.0   \n",
       "3                   0.180825                   0.180825         2.0   \n",
       "4                   0.138598                   0.138598         1.0   \n",
       "\n",
       "   fews_ipc_6  fews_ipc_9  fews_ipc_12  fews_ipc_15  fews_ipc_18  \\\n",
       "0         1.0         1.0          1.0          1.0          1.0   \n",
       "1         1.0         1.0          1.0          1.0          1.0   \n",
       "2         2.0         2.0          2.0          1.0          2.0   \n",
       "3         1.0         2.0          2.0          2.0          1.0   \n",
       "4         1.0         1.0          1.0          1.0          1.0   \n",
       "\n",
       "   fews_proj_near_3  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 3728 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raise Exception(\"Stop here\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns that contain a particular substring\n",
    "\n",
    "# list(filter(lambda x: 'co' in x, time_series.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find columns that begin with a particular substring\n",
    "list(filter(lambda x: x.startswith(\"coun\"), time_series.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series[[\"fews_proj_near_3\", \"fews_proj_near\", \"year\"]].to_csv(\"fews_proj_near_3.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to dlopen libcudart.so.11.0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LinearRegression, Lasso\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m root_mean_squared_error, precision_recall_curve, auc\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcudf\u001b[39;00m\n\u001b[1;32m      9\u001b[0m test_splits \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m     ((\u001b[38;5;241m2010\u001b[39m,\u001b[38;5;241m7\u001b[39m), (\u001b[38;5;241m2011\u001b[39m, \u001b[38;5;241m7\u001b[39m)), \n\u001b[1;32m     11\u001b[0m     ((\u001b[38;5;241m2011\u001b[39m,\u001b[38;5;241m7\u001b[39m), (\u001b[38;5;241m2012\u001b[39m, \u001b[38;5;241m7\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     ((\u001b[38;5;241m2019\u001b[39m,\u001b[38;5;241m2\u001b[39m), (\u001b[38;5;241m2020\u001b[39m, \u001b[38;5;241m2\u001b[39m)),\n\u001b[1;32m     20\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/__init__.py:27\u001b[0m\n\u001b[1;32m     24\u001b[0m     libcuml\u001b[38;5;241m.\u001b[39mload_library()\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m libcuml\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Base, UniversalBase\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mavailable_devices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_cuda_available\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# GPU only packages\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2019-2023, NVIDIA CORPORATION.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mavailable_devices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_cuda_available\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase_helpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseMetaClass, _tags_class_and_instance\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     20\u001b[0m     _deprecate_pos_args,\n\u001b[1;32m     21\u001b[0m     api_base_fit_transform,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     exit_internal_api,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_context_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     36\u001b[0m     in_internal_api,\n\u001b[1;32m     37\u001b[0m     set_api_output_dtype,\n\u001b[1;32m     38\u001b[0m     set_api_output_type,\n\u001b[1;32m     39\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/base_helpers.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01minspect\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Parameter, signature\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_decorators\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     21\u001b[0m     api_base_return_generic,\n\u001b[1;32m     22\u001b[0m     api_base_return_array,\n\u001b[1;32m     23\u001b[0m     api_base_return_sparse_array,\n\u001b[1;32m     24\u001b[0m     api_base_return_any,\n\u001b[1;32m     25\u001b[0m     api_return_any,\n\u001b[1;32m     26\u001b[0m     _deprecate_pos_args,\n\u001b[1;32m     27\u001b[0m )\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CumlArray\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_sparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseCumlArray\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/api_decorators.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TODO: Try to resolve circular import that makes this necessary:\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m input_utils \u001b[38;5;28;01mas\u001b[39;00m iu\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_context_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseReturnAnyCM\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi_context_managers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseReturnArrayCM\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/input_utils.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m namedtuple\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Literal\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CumlArray\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_sparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparseCumlArray\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobal_settings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalSettings\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/array.py:21\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moperator\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mglobal_settings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GlobalSettings\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m debug\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmem_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryType, MemoryTypeError\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/global_settings.py:20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthreading\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mavailable_devices\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m is_cuda_available\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DeviceType\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmem_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryType\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msafe_imports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cpu_only_import, gpu_only_import\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/device_type.py:19\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright (c) 2022-2023, NVIDIA CORPORATION.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01menum\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Enum, auto\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmem_type\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MemoryType\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mDeviceTypeError\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n\u001b[1;32m     23\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"An exception thrown to indicate bad device type selection\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/mem_type.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdevice_support\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GPU_ENABLED\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcuml\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msafe_imports\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cpu_only_import, gpu_only_import\n\u001b[0;32m---> 22\u001b[0m cudf \u001b[38;5;241m=\u001b[39m \u001b[43mgpu_only_import\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcudf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m cp \u001b[38;5;241m=\u001b[39m gpu_only_import(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcupy\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     24\u001b[0m cpx_sparse \u001b[38;5;241m=\u001b[39m gpu_only_import(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcupyx.scipy.sparse\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuml/internals/safe_imports.py:362\u001b[0m, in \u001b[0;36mgpu_only_import\u001b[0;34m(module, alt)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"A function used to import modules required only in GPU installs\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03mThis function will attempt to import a module with the given name, but it\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m    UnavailableMeta.\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m GPU_ENABLED:\n\u001b[0;32m--> 362\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m safe_import(\n\u001b[1;32m    365\u001b[0m         module,\n\u001b[1;32m    366\u001b[0m         msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not installed in non GPU-enabled installations\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    367\u001b[0m         alt\u001b[38;5;241m=\u001b[39malt,\n\u001b[1;32m    368\u001b[0m     )\n",
      "File \u001b[0;32m/home/linuxbrew/.linuxbrew/opt/python@3.10/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cudf/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcudf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgpu_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m validate_setup\n\u001b[1;32m     19\u001b[0m _setup_numba()\n\u001b[0;32m---> 20\u001b[0m \u001b[43mvalidate_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcupy\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumba\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config \u001b[38;5;28;01mas\u001b[39;00m numba_config, cuda\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cudf/utils/gpu_utils.py:96\u001b[0m, in \u001b[0;36mvalidate_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m     86\u001b[0m     minor_version \u001b[38;5;241m=\u001b[39m getDeviceAttribute(\n\u001b[1;32m     87\u001b[0m         cudaDeviceAttr\u001b[38;5;241m.\u001b[39mcudaDevAttrComputeCapabilityMinor, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnsupportedCUDAError(\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA GPU with NVIDIA Volta™ (Compute Capability 7.0) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor newer architecture is required.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected GPU 0: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected Compute Capability: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmajor_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mminor_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m     )\n\u001b[0;32m---> 96\u001b[0m cuda_runtime_version \u001b[38;5;241m=\u001b[39m \u001b[43mruntimeGetVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cuda_runtime_version \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m11000\u001b[39m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;66;03m# Require CUDA Runtime version 11.0 or greater.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m     major_version \u001b[38;5;241m=\u001b[39m cuda_runtime_version \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1000\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/rmm/_cuda/gpu.py:86\u001b[0m, in \u001b[0;36mruntimeGetVersion\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mruntimeGetVersion\u001b[39m():\n\u001b[1;32m     77\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;124;03m    Returns the version number of the local CUDA runtime.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    and status code.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     status, version \u001b[38;5;241m=\u001b[39m \u001b[43mruntime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetLocalRuntimeVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m runtime\u001b[38;5;241m.\u001b[39mcudaError_t\u001b[38;5;241m.\u001b[39mcudaSuccess:\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CUDARuntimeError(status)\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuda/bindings/runtime.pyx:25115\u001b[0m, in \u001b[0;36mcuda.bindings.runtime.getLocalRuntimeVersion\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuda/bindings/cyruntime.pyx:1106\u001b[0m, in \u001b[0;36mcuda.bindings.cyruntime.getLocalRuntimeVersion\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/world-bank-proj/world-bank-gpu-new/lib/python3.10/site-packages/cuda/bindings/_lib/cyruntime/cyruntime.pyx:2124\u001b[0m, in \u001b[0;36mcuda.bindings._lib.cyruntime.cyruntime._getLocalRuntimeVersion\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to dlopen libcudart.so.11.0"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import root_mean_squared_error, precision_recall_curve, auc\n",
    "from cuml.ensemble import RandomForestRegressor\n",
    "import cudf\n",
    "test_splits = [\n",
    "    ((2010,7), (2011, 7)), \n",
    "    ((2011,7), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)), \n",
    "    ((2013,7), (2014, 7)), \n",
    "    ((2014,7), (2015, 7)), \n",
    "    ((2015,7), (2016, 7)), \n",
    "    ((2016,7), (2017, 7)), \n",
    "    ((2017,7), (2018, 7)),\n",
    "    ((2018,7), (2019, 7)), \n",
    "    ((2019,2), (2020, 2)),\n",
    "]\n",
    "train_splits_old = [\n",
    "    ((2009,7), (2010,4)),\n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2009,7), (2011,10)),\n",
    "    ((2009,7), (2012,7)),\n",
    "    ((2009,7), (2013,7)),\n",
    "    ((2009,7), (2014,1)),\n",
    "    ((2009,7), (2015,1)),\n",
    "    ((2009,7), (2015,10)),\n",
    "    ((2009,7), (2016,10)),\n",
    "    ((2009,7), (2017,2))]\n",
    "dev_splits = [\n",
    "    ((2010,4), (2010, 7)),\n",
    "    ((2011,1), (2011, 7)),\n",
    "    ((2011,10), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)),\n",
    "    ((2013,4), (2014, 7)),\n",
    "    ((2014,1), (2015, 7)),\n",
    "    ((2015,1), (2016, 7)),\n",
    "    ((2015,10), (2017, 7)),\n",
    "    ((2016,10), (2018, 7)),\n",
    "    ((2017,2), (2019, 2)),\n",
    "]\n",
    "# train_splits = train_splits_old + dev_splits\n",
    "train_splits =  dev_splits\n",
    "\n",
    "# just like them we will evaluate three dufferent models, Random Forest, OLS and Lasso. Random Forest is a tree-based model, OLS is a linear regression model and Lasso is a linear regression model with L1 regularization\n",
    "models = {\n",
    "    # 'RF': RandomForestRegressor(max_features='sqrt', n_estimators=100, min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0)\n",
    "    'RF': RandomForestRegressor(\n",
    "        max_features='sqrt',  # Keep this\n",
    "        n_estimators=500,  # Increase trees to reduce variance\n",
    "        min_samples_split=5,  # 🚨 Fix this, should be an integer\n",
    "        min_samples_leaf=2,  # Helps prevent overfitting\n",
    "        max_depth=None,  # Allow full tree growth\n",
    "        bootstrap=True,  # Default setting, makes it more robust\n",
    "        random_state=0\n",
    "    )\n",
    "    # 'OLS': LinearRegression(),\n",
    "    # 'Lasso': Lasso(alpha=0.1)\n",
    "}\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return [f\"{f}_{t}\" for f in factors for t in range(3, 9)] + \\\n",
    "           [f\"{f}_province_{t}\" for f in factors for t in range(3, 9)] + \\\n",
    "           [f\"{f}_country_{t}\" for f in factors for t in range(3, 9)]\n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors],\n",
    "    \n",
    "    'news': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(news_factors)],\n",
    "    \n",
    "    'traditional+news': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors + \n",
    "        get_agg_lagged_features(news_factors)]\n",
    "    \n",
    "    # 'expert': time_series[['fews_proj_near_3' ] + ['year', 'month']],\n",
    "    \n",
    "    # 'expert+traditional': time_series[ ['year', 'month']+ \n",
    "    #     ['fews_proj_near_3'] +\n",
    "    #     ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "    #     get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "    #     t_invariant_traditional_factors\n",
    "    # ],\n",
    "    # 'expert+news': time_series[ ['year', 'month'] +\n",
    "    #     ['fews_proj_near_3'] +\n",
    "    #     ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "    #     get_agg_lagged_features(news_factors)\n",
    "    # ],\n",
    "    # 'expert+traditional+news': time_series[ ['year', 'month'] +\n",
    "    #     ['fews_proj_near_3'] +\n",
    "    #     ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "    #     get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "    #     t_invariant_traditional_factors +\n",
    "    #     get_agg_lagged_features(news_factors)\n",
    "    # ]\n",
    "}\n",
    "\n",
    "labels_df = time_series[['fews_ipc', 'year', 'month']]\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[\n",
    "        (((df['year'] > start[0])) | ((df['year'] == start[0]) & (df['month'] >= start[1]))) &\n",
    "        (((df['year'] < end[0])) | ((df['year'] == end[0]) & (df['month'] <= end[1])))\n",
    "    ]\n",
    "\n",
    "thresholds = {'traditional': (2.236, 3.125), \n",
    "              'news': (1.907, 2.712), \n",
    "              'traditional+news': (2.105, 3.314),\n",
    "            #   'expert': (2, 3),\n",
    "            #   'expert+news': (1.912, 2.813),\n",
    "            #   'expert+traditional': (2.241, 3.132),\n",
    "            #   'expert+traditional+news': (2.172, 3.321)\n",
    "             }\n",
    "\n",
    "def train_and_evaluate(train, dev, test, f, D):\n",
    "    results = []\n",
    "    \n",
    "    # D.to_csv(f\"D_features_{f}.csv\")\n",
    "    # print(\"The feature is: \", f)\n",
    "    # print(\"train split:\", train)\n",
    "    # print(\"Shape of D: \", D.shape)\n",
    "    # print(\"All columns \", D.columns)\n",
    "    \n",
    "\n",
    "    X_train = get_time_split(D, train[0], train[1]).drop(columns=['year', 'month']).to_numpy()# not sure how okay it is to do fillna. When me and Bilal were running this we were getting the error that cannot run the model on NaN values. First we dropped na but this was causing the shape of the X_train to be different from the y_train. So we decided to fillna with 0. - aysha & bilal\n",
    "    \n",
    "    y_train = get_time_split(labels_df, train[0], train[1]).drop(columns=['year', 'month']).to_numpy().ravel()\n",
    "    # print(\"The shape of X_train before removing nans is: \", X_train.shape)\n",
    "    # shape_before = X_train.shape\n",
    "    nan_mask = np.isnan(X_train).any(axis=1)\n",
    "    X_train = X_train[~nan_mask]\n",
    "    y_train = y_train[~nan_mask]\n",
    "    \n",
    "    \n",
    "    X_test = get_time_split(D, test[0], test[1]).drop(columns=['year', 'month']).to_numpy()\n",
    "    y_test = get_time_split(labels_df, test[0], test[1]).drop(columns=['year', 'month']).to_numpy().ravel()\n",
    "    nan_mask_test = np.isnan(X_test).any(axis=1)\n",
    "    X_test = X_test[~nan_mask_test]\n",
    "    y_test = y_test[~nan_mask_test]\n",
    "    \n",
    "    # X_train.to_csv(f\"X_train_{f}.csv\")\n",
    "    # print(\"The shape of X_train after removing nans is: \", X_train.shape)\n",
    "    # print(\"The number of nans removed: \", shape_before[0] - X_train.shape[0])\n",
    "    # print(\"fraction of nans\", (shape_before[0]-X_train.shape[0])/shape_before[0])\n",
    "    \n",
    "    # print(f\"Train is {X_train}\")\n",
    "    # print(f\"Y train is {y_train}\")\n",
    "    # print(f\"Test is {X_test}\")\n",
    "    # print(f\"Y test is {y_test}\")\n",
    "    \n",
    "    X_train = cudf.DataFrame(X_train)\n",
    "    y_train = cudf.Series(y_train)\n",
    "    X_test = cudf.DataFrame(X_test)\n",
    "    y_test = cudf.Series(y_test)\n",
    "    # convert y_test into binary classification (1 if inside threshold, else 0)\n",
    "    lower, upper = thresholds[f]\n",
    "    y_test_binary = np.where((y_test >= lower) & (y_test <= upper), 1, 0)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, preds)\n",
    "\n",
    "        # stderr = np.std(y_test - preds) / np.sqrt(len(y_test))\n",
    "        # upper_bound = np.sqrt(rmse**2 + 1.96 * stderr)\n",
    "        # lower_bound = np.sqrt(rmse**2 - 1.96 * stderr)\n",
    "\n",
    "        # precision, recall, _ = precision_recall_curve(y_test_binary, preds)\n",
    "        # aucpr = auc(recall, precision)\n",
    "\n",
    "        results.append({\n",
    "            'method': name, 'split': test, 'features': f, \n",
    "            'rmse': rmse,\n",
    "            # 'rmse': rmse, 'lower_bound': lower_bound, 'upper_bound': upper_bound,\n",
    "            # 'aucpr': aucpr\n",
    "        })\n",
    "\n",
    "        # print(f\"Method: {name}, Split: {test}, Features: {f}, AUCPR: {aucpr:.4f}\")\n",
    "        # print(f\"Method: {name}, Split: {test}, Features: {f}, RMSE: {rmse:.4f} [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
    "        print(f\"Method: {name}, Split: {test}, Features: {f}, RMSE: {rmse:.4f}\")\n",
    "        \n",
    "    #     # completely removed the part where they were doing country-wise evaluation. Do not see point - aysha\n",
    "    \n",
    "    return results\n",
    "\n",
    "# run in parallel on 4 cpu cores/decrease this if you do not want ur system to crash (speaking from experience)\n",
    "all_results = Parallel(n_jobs=4)(\n",
    "    delayed(train_and_evaluate)(train, dev, test, f, D) for train, dev, test in zip(train_splits, dev_splits, test_splits) for f, D in features.items()\n",
    ")\n",
    "\n",
    "\n",
    "# all_results = []\n",
    "# for train, dev, test in zip(train_splits, dev_splits, test_splits):\n",
    "#     for f, D in features.items():\n",
    "#         # print(f\"Running for {f}\")\n",
    "        \n",
    "#         # print(f\"Train: {train}, Dev: {dev}, Test: {test}\")\n",
    "#         # # print(f\"Features: {D.columns}\")\n",
    "#         # print(f\"{D.shape}\")\n",
    "#         # print(f\"{D}\")\n",
    "        \n",
    "#         all_results.append(train_and_evaluate(train, dev, test, f, D))\n",
    "\n",
    "\n",
    "fig_3a = pd.DataFrame([res for sublist in all_results for res in sublist])\n",
    "fig_3a.to_csv('fig_3a.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'method'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mfig_3a\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mby\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmethod\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeatures\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mrmse\u001b[39m\u001b[33m'\u001b[39m].mean()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/world-bank-proj/world-bank/lib/python3.13/site-packages/pandas/core/frame.py:9183\u001b[39m, in \u001b[36mDataFrame.groupby\u001b[39m\u001b[34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   9180\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   9181\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mYou have to supply one of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mby\u001b[39m\u001b[33m'\u001b[39m\u001b[33m and \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m9183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   9184\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   9185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9186\u001b[39m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9187\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9189\u001b[39m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9190\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   9193\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/world-bank-proj/world-bank/lib/python3.13/site-packages/pandas/core/groupby/groupby.py:1329\u001b[39m, in \u001b[36mGroupBy.__init__\u001b[39m\u001b[34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[39m\n\u001b[32m   1326\u001b[39m \u001b[38;5;28mself\u001b[39m.dropna = dropna\n\u001b[32m   1328\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1329\u001b[39m     grouper, exclusions, obj = \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib.no_default:\n\u001b[32m   1340\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping._passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper.groupings):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/world-bank-proj/world-bank/lib/python3.13/site-packages/pandas/core/groupby/grouper.py:1043\u001b[39m, in \u001b[36mget_grouper\u001b[39m\u001b[34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[39m\n\u001b[32m   1041\u001b[39m         in_axis, level, gpr = \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1042\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1043\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[32m   1044\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr.key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[32m   1046\u001b[39m     exclusions.add(gpr.key)\n",
      "\u001b[31mKeyError\u001b[39m: 'method'"
     ]
    }
   ],
   "source": [
    "fig_3a.groupby(by=['method', 'features'])['rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the train and the test dataset are the same:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.099734\n",
    "        traditional         0.027667\n",
    "        traditional+news    0.096902\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "**If we use their provided train-test split:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.400070\n",
    "        traditional         0.134550\n",
    "        traditional+news    0.390469\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "\n",
    "**If we use dev-test split:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.388210\n",
    "        traditional         0.132620\n",
    "        traditional+news    0.364279\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "**If we use train+dev-test split:**\n",
    "```\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world-bank-gpu-new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
