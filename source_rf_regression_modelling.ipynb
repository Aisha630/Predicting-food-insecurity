{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download time series from link in GitHub repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust filepath\n",
    "time_series = pd.read_csv('./data/time_series_with_causes_zscore_full.csv', nrows=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'index', 'country', 'admin_code', 'admin_name',\n",
       "       'centx', 'centy', 'year_month', 'year', 'month', 'fews_ipc',\n",
       "       'fews_ha', 'fews_proj_near', 'fews_proj_near_ha', 'fews_proj_med',\n",
       "       'fews_proj_med_ha', 'ndvi_mean', 'ndvi_anom', 'rain_mean',\n",
       "       'rain_anom', 'et_mean', 'et_anom', 'acled_count',\n",
       "       'acled_fatalities', 'p_staple_food', 'area', 'cropland_pct', 'pop',\n",
       "       'ruggedness_mean', 'pasture_pct', 'change_fews', 'land seizures_0',\n",
       "       'land seizures_1', 'land seizures_2', 'slashed export_0',\n",
       "       'slashed export_1', 'slashed export_2', 'price rise_0',\n",
       "       'price rise_1', 'price rise_2', 'mass hunger_0', 'mass hunger_1',\n",
       "       'mass hunger_2', 'cyclone_0', 'cyclone_1', 'cyclone_2',\n",
       "       'failed crops_0', 'failed crops_1', 'failed crops_2',\n",
       "       'disruption to farming_0', 'disruption to farming_1',\n",
       "       'disruption to farming_2', 'massive starvation_0',\n",
       "       'massive starvation_1', 'massive starvation_2',\n",
       "       'abnormally low rainfall_0', 'abnormally low rainfall_1',\n",
       "       'abnormally low rainfall_2', 'withheld relief_0',\n",
       "       'withheld relief_1', 'withheld relief_2', 'international alarm_0',\n",
       "       'international alarm_1', 'international alarm_2',\n",
       "       'reduced national output_0', 'reduced national output_1',\n",
       "       'reduced national output_2', 'oppressive regimes_0',\n",
       "       'oppressive regimes_1', 'oppressive regimes_2', 'pests_0',\n",
       "       'pests_1', 'pests_2', 'continued deterioration_0',\n",
       "       'continued deterioration_1', 'continued deterioration_2',\n",
       "       'forests destroyed_0', 'forests destroyed_1',\n",
       "       'forests destroyed_2', 'man-made disaster_0',\n",
       "       'man-made disaster_1', 'man-made disaster_2', 'food insecurity_0',\n",
       "       'food insecurity_1', 'food insecurity_2',\n",
       "       'harvests are devastated_0', 'harvests are devastated_1',\n",
       "       'harvests are devastated_2', 'humanitarian situation_0',\n",
       "       'humanitarian situation_1', 'humanitarian situation_2',\n",
       "       'economic impoverishment_0', 'economic impoverishment_1',\n",
       "       'economic impoverishment_2', 'clan battle_0', 'clan battle_1',\n",
       "       'clan battle_2', 'population crisis_0', 'population crisis_1',\n",
       "       'population crisis_2', 'aid appeal_0', 'aid appeal_1',\n",
       "       'aid appeal_2', 'weather extremes_0', 'weather extremes_1',\n",
       "       'weather extremes_2', 'anti-western policies_0',\n",
       "       'anti-western policies_1', 'anti-western policies_2',\n",
       "       'rinderpest_0', 'rinderpest_1', 'rinderpest_2',\n",
       "       'inadequate rainfall_0', 'inadequate rainfall_1',\n",
       "       'inadequate rainfall_2', 'lack of authority_0',\n",
       "       'lack of authority_1', 'lack of authority_2', 'acute hunger_0',\n",
       "       'acute hunger_1', 'acute hunger_2', 'foreign troops_0',\n",
       "       'foreign troops_1', 'foreign troops_2',\n",
       "       'increased external debt_0', 'increased external debt_1',\n",
       "       'increased external debt_2', 'drought_0', 'drought_1', 'drought_2',\n",
       "       'conflict_0', 'conflict_1', 'conflict_2', 'failed rains_0',\n",
       "       'failed rains_1', 'failed rains_2', 'makeshift camps_0',\n",
       "       'makeshift camps_1', 'makeshift camps_2', 'civilians uprooted_0',\n",
       "       'civilians uprooted_1', 'civilians uprooted_2', 'dysfunction_0',\n",
       "       'dysfunction_1', 'dysfunction_2', 'foreign aid_0', 'foreign aid_1',\n",
       "       'foreign aid_2', 'violent suppression_0', 'violent suppression_1',\n",
       "       'violent suppression_2', 'military dictatorship_0',\n",
       "       'military dictatorship_1', 'military dictatorship_2',\n",
       "       'climatic hazards_0', 'climatic hazards_1', 'climatic hazards_2',\n",
       "       'migration_0', 'migration_1', 'migration_2', 'land grab_0',\n",
       "       'land grab_1', 'land grab_2', 'terrorism_0', 'terrorism_1',\n",
       "       'terrorism_2', 'bombing campaign_0', 'bombing campaign_1',\n",
       "       'bombing campaign_2', 'collapsing economy_0',\n",
       "       'collapsing economy_1', 'collapsing economy_2', 'military junta_0',\n",
       "       'military junta_1', 'military junta_2', 'climate change_0',\n",
       "       'climate change_1', 'climate change_2', 'rising inflation_0',\n",
       "       'rising inflation_1', 'rising inflation_2',\n",
       "       'international terrorists_0', 'international terrorists_1',\n",
       "       'international terrorists_2', 'cycle of poverty_0',\n",
       "       'cycle of poverty_1', 'cycle of poverty_2', 'bad harvests_0',\n",
       "       'bad harvests_1', 'bad harvests_2', 'destructive pattern_0',\n",
       "       'destructive pattern_1', 'destructive pattern_2',\n",
       "       'price of food_0', 'price of food_1', 'price of food_2',\n",
       "       'corrupt government_0', 'corrupt government_1',\n",
       "       'corrupt government_2', 'militia groups_0', 'militia groups_1',\n",
       "       'militia groups_2', 'poor soil quality_0', 'poor soil quality_1',\n",
       "       'poor soil quality_2', 'cattle plague_0', 'cattle plague_1',\n",
       "       'cattle plague_2', 'food assistance_0', 'food assistance_1',\n",
       "       'food assistance_2', 'continued strife_0', 'continued strife_1',\n",
       "       'continued strife_2', 'ecological crisis_0', 'ecological crisis_1',\n",
       "       'ecological crisis_2', 'hunger crises_0', 'hunger crises_1',\n",
       "       'hunger crises_2', 'rising food prices_0', 'rising food prices_1',\n",
       "       'rising food prices_2', 'restricted humanitarian access_0',\n",
       "       'restricted humanitarian access_1',\n",
       "       'restricted humanitarian access_2', 'water availability_0',\n",
       "       'water availability_1', 'water availability_2', 'alarming level_0',\n",
       "       'alarming level_1', 'alarming level_2', 'police torture_0',\n",
       "       'police torture_1', 'police torture_2', 'potato blight_0',\n",
       "       'potato blight_1', 'potato blight_2', 'the offensive_0',\n",
       "       'the offensive_1', 'the offensive_2', 'land invasions_0',\n",
       "       'land invasions_1', 'land invasions_2', 'clan warfare_0',\n",
       "       'clan warfare_1', 'clan warfare_2', 'stolen food aid_0',\n",
       "       'stolen food aid_1', 'stolen food aid_2',\n",
       "       'politically engineered_0', 'politically engineered_1',\n",
       "       'politically engineered_2', 'scanty rainfall_0',\n",
       "       'scanty rainfall_1', 'scanty rainfall_2',\n",
       "       'water distribution shortages_0', 'water distribution shortages_1',\n",
       "       'water distribution shortages_2', 'cattle death_0',\n",
       "       'cattle death_1', 'cattle death_2', 'asylum seekers_0',\n",
       "       'asylum seekers_1', 'asylum seekers_2', 'major offensive_0',\n",
       "       'major offensive_1', 'major offensive_2',\n",
       "       'without international aid_0', 'without international aid_1',\n",
       "       'without international aid_2', 'prolonged dry spell_0',\n",
       "       'prolonged dry spell_1', 'prolonged dry spell_2', 'rise_0',\n",
       "       'rise_1', 'rise_2', 'restricted relief flights_0',\n",
       "       'restricted relief flights_1', 'restricted relief flights_2',\n",
       "       'civil strife_0', 'civil strife_1', 'civil strife_2',\n",
       "       'aid workers died_0', 'aid workers died_1', 'aid workers died_2',\n",
       "       'rival warlords_0', 'rival warlords_1', 'rival warlords_2',\n",
       "       'land reform_0', 'land reform_1', 'land reform_2',\n",
       "       'lack of roads_0', 'lack of roads_1', 'lack of roads_2',\n",
       "       'pushing peasants off_0', 'pushing peasants off_1',\n",
       "       'pushing peasants off_2', 'locusts_0', 'locusts_1', 'locusts_2',\n",
       "       'gangs of bandits_0', 'gangs of bandits_1', 'gangs of bandits_2',\n",
       "       'repression_0', 'repression_1', 'repression_2',\n",
       "       'humanitarian disaster_0', 'humanitarian disaster_1',\n",
       "       'humanitarian disaster_2', 'years of warfare_0',\n",
       "       'years of warfare_1', 'years of warfare_2', 'floods_0', 'floods_1',\n",
       "       'floods_2', 'unable to sow_0', 'unable to sow_1',\n",
       "       'unable to sow_2', 'transport bottleneck_0',\n",
       "       'transport bottleneck_1', 'transport bottleneck_2', 'pirates_0',\n",
       "       'pirates_1', 'pirates_2', 'reduced imports_0', 'reduced imports_1',\n",
       "       'reduced imports_2', 'apathy_0', 'apathy_1', 'apathy_2', 'coup_0',\n",
       "       'coup_1', 'coup_2', 'epidemics_0', 'epidemics_1', 'epidemics_2',\n",
       "       'siege_0', 'siege_1', 'siege_2', 'power struggle_0',\n",
       "       'power struggle_1', 'power struggle_2', 'livestock had died_0',\n",
       "       'livestock had died_1', 'livestock had died_2', 'blockade_0',\n",
       "       'blockade_1', 'blockade_2', 'burning houses_0', 'burning houses_1',\n",
       "       'burning houses_2', 'brain drain_0', 'brain drain_1',\n",
       "       'brain drain_2', 'severe rains_0', 'severe rains_1',\n",
       "       'severe rains_2', 'infrastructure damage_0',\n",
       "       'infrastructure damage_1', 'infrastructure damage_2',\n",
       "       'land degradation_0', 'land degradation_1', 'land degradation_2',\n",
       "       'human rights abuses_0', 'human rights abuses_1',\n",
       "       'human rights abuses_2', 'lack of cultivation_0',\n",
       "       'lack of cultivation_1', 'lack of cultivation_2',\n",
       "       'harvest decline_0', 'harvest decline_1', 'harvest decline_2',\n",
       "       'flee_0', 'flee_1', 'flee_2', 'economic crisis_0',\n",
       "       'economic crisis_1', 'economic crisis_2', 'greenhouse gases_0',\n",
       "       'greenhouse gases_1', 'greenhouse gases_2', 'prolonged fighting_0',\n",
       "       'prolonged fighting_1', 'prolonged fighting_2', 'tragedy_0',\n",
       "       'tragedy_1', 'tragedy_2', 'slave trade_0', 'slave trade_1',\n",
       "       'slave trade_2', 'environmental degradation_0',\n",
       "       'environmental degradation_1', 'environmental degradation_2',\n",
       "       'infant mortality_0', 'infant mortality_1', 'infant mortality_2',\n",
       "       'catastrophe_0', 'catastrophe_1', 'catastrophe_2',\n",
       "       'wreaked havoc_0', 'wreaked havoc_1', 'wreaked havoc_2',\n",
       "       'internal strife_0', 'internal strife_1', 'internal strife_2',\n",
       "       'malnourished_0', 'malnourished_1', 'malnourished_2',\n",
       "       'secession_0', 'secession_1', 'secession_2', 'natural disaster_0',\n",
       "       'natural disaster_1', 'natural disaster_2',\n",
       "       'life-threatening hunger_0', 'life-threatening hunger_1',\n",
       "       'life-threatening hunger_2', 'air attack_0', 'air attack_1',\n",
       "       'air attack_2', 'corruption_0', 'corruption_1', 'corruption_2',\n",
       "       'call for donations_0', 'call for donations_1',\n",
       "       'call for donations_2', 'collapse of government_0',\n",
       "       'collapse of government_1', 'collapse of government_2',\n",
       "       'international intervention_0', 'international intervention_1',\n",
       "       'international intervention_2', 'refugees_0', 'refugees_1',\n",
       "       'refugees_2', 'disrupted trade_0', 'disrupted trade_1',\n",
       "       'disrupted trade_2', 'lack of agricultural infrastructure_0',\n",
       "       'lack of agricultural infrastructure_1',\n",
       "       'lack of agricultural infrastructure_2', 'rebel insurgency_0',\n",
       "       'rebel insurgency_1', 'rebel insurgency_2', 'brutal government_0',\n",
       "       'brutal government_1', 'brutal government_2', 'looting_0',\n",
       "       'looting_1', 'looting_2', 'displaced_0', 'displaced_1',\n",
       "       'displaced_2', 'food crisis_0', 'food crisis_1', 'food crisis_2',\n",
       "       'lack of rains_0', 'lack of rains_1', 'lack of rains_2',\n",
       "       'lack of alternatives_0', 'lack of alternatives_1',\n",
       "       'lack of alternatives_2', 'regimes were toppled_0',\n",
       "       'regimes were toppled_1', 'regimes were toppled_2',\n",
       "       'jihadist groups_0', 'jihadist groups_1', 'jihadist groups_2',\n",
       "       'toll on livestock_0', 'toll on livestock_1',\n",
       "       'toll on livestock_2', 'shortage of rains_0',\n",
       "       'shortage of rains_1', 'shortage of rains_2',\n",
       "       'devastated the economy_0', 'devastated the economy_1',\n",
       "       'devastated the economy_2', 'self reliance_0', 'self reliance_1',\n",
       "       'self reliance_2', 'cholera outbreak_0', 'cholera outbreak_1',\n",
       "       'cholera outbreak_2', 'international embargo_0',\n",
       "       'international embargo_1', 'international embargo_2', 'farmland_0',\n",
       "       'farmland_1', 'farmland_2', 'totalitarian_0', 'totalitarian_1',\n",
       "       'totalitarian_2', 'authoritarian_0', 'authoritarian_1',\n",
       "       'authoritarian_2', 'dictators_0', 'dictators_1', 'dictators_2',\n",
       "       'clans_0', 'clans_1', 'clans_2', 'gastrointestinal_0',\n",
       "       'gastrointestinal_1', 'gastrointestinal_2', 'terrorist_0',\n",
       "       'terrorist_1', 'terrorist_2', 'warlord_0', 'warlord_1',\n",
       "       'warlord_2', \"d'etat_0\", \"d'etat_1\", \"d'etat_2\", 'overthrow_0',\n",
       "       'overthrow_1', 'overthrow_2', 'convoys_0', 'convoys_1',\n",
       "       'convoys_2', 'carbon_0', 'carbon_1', 'carbon_2', 'mayhem_0',\n",
       "       'mayhem_1', 'mayhem_2', 'dehydrated_0', 'dehydrated_1',\n",
       "       'dehydrated_2', 'mismanagement_0', 'mismanagement_1',\n",
       "       'mismanagement_2'], dtype=object)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = ['ndvi_mean', 'ndvi_anom', 'rain_mean', 'rain_anom', 'et_mean', 'et_anom', \n",
    "                                    'acled_count', 'acled_fatalities', 'p_staple_food']\n",
    "t_invariant_traditional_factors = ['area', 'cropland_pct', 'pop', 'ruggedness_mean', 'pasture_pct']\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'land seizures_0'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Unnamed: 0\", \"centx\", \"centy\", 'change_fews', 'fews_ha', 'fews_proj_med', 'fews_proj_med_ha', 'fews_proj_near_ha'] + [col for col in time_series.columns if col.endswith(('_1', '_2', '_3'))]\n",
    "time_series.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of time_series: (30, 190)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of time_series: {time_series.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lagged(x, f, t):\n",
    "    admin_code = x['admin_code']\n",
    "    year = x['year']\n",
    "    month = x['month']\n",
    "    l_month = ((month-1-t)%12)+1\n",
    "    l_year = year\n",
    "    if month-t<=0:\n",
    "        l_year -= 1\n",
    "    ts=time_series[time_series['admin_code']==admin_code]\n",
    "    lagged_year_month = '{}_{}'.format(l_year, l_month)\n",
    "    if lagged_year_month in ts['year_month'].values:\n",
    "        ts = ts[ts['year_month']==lagged_year_month]\n",
    "        return ts[f].values[0]\n",
    "    else:\n",
    "        return x[f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True):\n",
    "    if agg:\n",
    "        levels = ['', '_province', '_country']\n",
    "    else:\n",
    "        levels = ['']\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f+suffix\n",
    "            for t in range(start,end,diff):\n",
    "                if '{}_{}'.format(f_s,t) in time_series:\n",
    "                    continue\n",
    "                time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Admin level mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust filepath (file also in GitHub repository)\n",
    "admins = pd.read_csv('./data/famine-country-province-district-years-CS.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(admins.country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "districts in time_series:  1\n",
      "provinces in time_series:  1\n",
      "countries in time_series:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"districts in time_series: \", len([d for d in districts if d in admin_names]))\n",
    "print(\"provinces in time_series: \", len([p for p in provinces if p in admin_names]))\n",
    "print(\"countries in time_series: \", len([c for c in countries if c in admin_names]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts = sorted(districts, key=str) # this has sari pul\n",
    "# districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4113 474 39\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "#manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust filepath (file also in GitHub repository)\n",
    "# After validating the matches, the names are logged in this csv file\n",
    "valid_matching = pd.read_csv('./data/matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched = valid_matching['missing'].unique()\n",
    "matched = [m.encode('utf-8').decode(\"unicode_escape\") for m in matched]\n",
    "missing_admin_names = [m.encode('ascii', 'backslashreplace').decode(\"unicode_escape\") for m in missing_admin_names]\n",
    "print(len(missing_admin_names), len(matched))\n",
    "set(missing_admin_names).difference(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched ['Port-Au-Prince', 'Teso', 'Tanganyka', 'Tayeeglow', 'Kadoma', \"Ad Dali'\", 'MPongwe', 'Saint-Raphael', 'Butembo', 'Um Kadada', 'Shabelle', 'Lughaye', 'Beitbridge', 'Bulo Burto', 'Trou Du Nord', 'Addabah', 'Muranga', 'Guji', 'Awi/Agew', 'Amran', 'Chipinge', 'Djourouf Al Ahmar', 'Port-Salut', 'Chiengi', 'Gweru', \"Bura'\", 'Agnuak', 'Bandarbeyla', 'Mbuji-Mayi', 'Sud-Kivu', 'Sheikh', 'Addis Adaba', 'Baydhaba', 'Lubumbashi', 'La PendÃ©', 'Adan', 'Acul Du Nord', 'Kananga', 'Bale.1', 'Lac-LÃ©rÃ©', 'Kelem Wellega', 'Kibale', 'North Shewa(R4)', 'Ceca La Source', 'Adan Yabaal', 'South Gonder', 'Gwanda', 'Gedio', 'East al Gazera', 'Damagaram Takaya', 'Abu Hamad', \"Shar'ab Ar Rawnah\", 'Gucha', 'Kabia', 'Ad Dinder', 'Maragua', 'Al Faw', 'Iriba', 'Eastern Tigray', 'Gonave', 'Ndjamena', 'Al Gadaref', 'North Shewa(R3)', 'Abu Jubaiyah', 'Nandi North', 'Koibatek', 'Banadir', 'En Nuhud', 'Chegutu', 'Nyala.1', 'Buret', \"At Ta'izziyah\", 'Kas', 'Sheikan', 'GothÃ¨ye', 'Hirat', 'Galdogob', \"Mawza'\", 'Mayo Boneye', 'Taleex', 'Mole Saint Nicolas', 'Khartoum Bahri', 'Tulus', 'Hareri', 'Bukavu', 'IllÃ©la', 'GourÃ©', 'Wadi Halfa', 'Kisangani', 'Butere Mumias', 'Mt Elgon', 'Ville de Tahoua', 'Southern Tigray', 'Mayo Binder', 'MangalmÃ©', 'Belbedji', 'Barh-KÃ´h', 'Barh El Gazel Ouest', 'Sharq al Gazera', 'Kuria', 'North Gonder', 'North al Gazera', 'Port De Paix', 'Western Tigray', 'Al Rahd', 'Mwingi', 'Mangwe (South)', 'Gebiley', 'Meru North', 'Majang', 'Ad Douiem', \"Al Ma'afir\", 'UMP', 'Barh El Gazel Nord', 'South Khartoum', \"Mashra'ah wa Hadnan\", 'Thika', 'Grande Riviere Du Nord', 'Ville de Niamey', 'Shurugwi', 'Komonjdjari', 'Ghebeish', 'Kwekwe', 'Nandi South', 'Meru Central', 'Goma', 'As Salam', 'Anse-A-Veau', 'Merawi', 'Busia.1', \"Shar'ab As Salam\", 'Al Jabalian', 'Nahr Atbara', 'Mutare', 'Selti', 'Valliere', 'Zvishavane', 'Berber', 'Tesker', 'Kolwezi', 'Laasqoray', 'Ad Damazin', \"Al Marawi'ah\", 'Rachuonyo', 'Croix-Des-Bouquets', 'Owdweyne', 'Ville de Zinder', 'Karary', 'Al Gash', \"Sa'dah\", 'Marakwet', 'North Western Tigray', 'Sowdari', 'Bindura', \"Segen Peoples'\", 'Al Kurumik', 'Saint Louis Du Nord', 'Al Gutaina', 'Burtinle', 'Belet Weyne', 'Meru South', 'Um Badda', 'Sharg En Nile', 'Al Mahagil', 'AguiÃ©', 'Al Kamlin', 'Wardi Hawar', 'La Nya PendÃ©', 'Wedza', 'Baw', 'Al Fushqa', 'Nord-Kivu', 'Lafon', 'Id El Ghanem', 'Bossaso', 'Al Roseires', 'Caynabo', 'Mwene-Ditu', 'Kolwezi.1', 'South al Gazera', 'Kindu', 'Likasi', 'Al Galabat', 'Hwange', 'Gourma-Rharous', 'Ad Damer', 'East Harerge', 'Ville de Maradi', 'Rab Dhuure', 'Mayo-Lemi', 'BankilarÃ©', 'Al Deain', 'MaÃ¯nÃ© Soroa', 'Barh El Gazel Sud', \"Sami'\", 'Cayes', 'Central Kisii', \"Al Wazi'iyah\", 'Mbeere', 'Seteet', 'TÃ©ra', 'Doolo', 'Beni', 'Um Al Gura', 'KT', 'Trans Mara', 'Al Geneina', 'Al Fasher', 'Lulua', 'Kabkabiya', 'KantchÃ©', 'Siti', 'Zallingi', 'Belet Xaawo', 'Special Woreda', 'Keiyo', 'West Harerge', 'Hamashkorieb', 'Chiredzi', 'FilinguÃ©', 'TillabÃ©ri', \"Amanat Al 'Asimah\", 'Kasai.1', 'Jebrat al Sheikh', 'Gokwe South', 'Kajo-keji', 'Sar-e-Pul', 'Bulilima (North)', 'Balleyara', \"Anse-D'Ainault\"]\n",
      "...........\n",
      "missing []\n"
     ]
    }
   ],
   "source": [
    "print(\"matched\", matched)\n",
    "\n",
    "print(\"...........\")\n",
    "print(\"missing\", missing_admin_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_province(x):\n",
    "    try:\n",
    "        if x in districts:\n",
    "            return admins[admins['district']==x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "        elif x.decode(\"unicode_escape\").encode('ascii', 'backslashreplace') in matched:\n",
    "            x = x.decode(\"unicode_escape\").encode('ascii', 'backslashreplace')\n",
    "            v = valid_matching[valid_matching['missing']==x]\n",
    "            if v['match'].values[0]=='district':\n",
    "                x = v['district'].values[0]\n",
    "                return admins[admins['district']==x]['province'].values[0]\n",
    "            elif v['match'].values[0]=='province':\n",
    "                return v['province'].values[0]\n",
    "    except:\n",
    "        raise Exception(\"Province not found for: {}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except:\n",
    "        print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series['province'] = time_series['admin_name'].apply(lambda x: admin_to_province[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add province and country aggregate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_agg_factors(features, level='province'):\n",
    "    grouped_df = time_series.groupby(['year_month', level])[features].mean() \n",
    "    # WARN: we added the [features] part as the original code was not working without it as it was trying to aggregate non-numeric colums as well\n",
    "    # for f in features:\n",
    "    #     time_series['{}_{}'.format(f, level)] = time_series.apply(lambda x: grouped_df.ix[x['year_month'], x[level]][f], axis=1)\n",
    "    \n",
    "    # WARN: The above code used older pandas syntax, which is now deprecated. The new code is as follows:\n",
    "    \n",
    "    for f in features:\n",
    "        time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
    "            lambda x: grouped_df.loc[x['year_month'], x[level]][f] if (x['year_month'], x[level]) in grouped_df.index else None,\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n"
     ]
    }
   ],
   "source": [
    "add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
      "/tmp/ipykernel_3740014/2610775785.py:10: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f, level)] = time_series.apply(\n"
     ]
    }
   ],
   "source": [
    "add_agg_factors(news_factors, level='country')\n",
    "add_agg_factors(t_variant_traditional_factors, level='province')\n",
    "add_agg_factors(t_variant_traditional_factors, level='country')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series.to_csv('theirs_agg_province_features_full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/tmp/ipykernel_3740014/190912860.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n"
     ]
    }
   ],
   "source": [
    "add_time_lagged(t_variant_traditional_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_csv('./their_modified_time_series_only_tvariant_30.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_time_lagged(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save data for Fig 3A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['fews_ipc_3', 'fews_ipc_6', 'fews_ipc_9', 'fews_ipc_12', 'fews_ipc_15', 'fews_ipc_18'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[180]\u001b[39m\u001b[32m, line 55\u001b[39m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_agg_lagged_features\u001b[39m(factors):\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(f, t) \u001b[38;5;28;01mfor\u001b[39;00m f, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(factors, \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m9\u001b[39m))] + [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_province_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(f, t) \u001b[38;5;28;01mfor\u001b[39;00m f, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(factors, \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m9\u001b[39m))] + [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_country_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(f, t) \u001b[38;5;28;01mfor\u001b[39;00m f, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(factors, \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m9\u001b[39m))]\n\u001b[32m     54\u001b[39m features = {\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtraditional\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mtime_series\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[33;43m'\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfews_ipc\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m21\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mget_agg_lagged_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_variant_traditional_factors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_invariant_traditional_factors\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m, \n\u001b[32m     60\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mnews\u001b[39m\u001b[33m'\u001b[39m: time_series[\n\u001b[32m     61\u001b[39m         [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[33m'\u001b[39m\u001b[33mfews_ipc\u001b[39m\u001b[33m'\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m21\u001b[39m,\u001b[32m3\u001b[39m)] +\n\u001b[32m     62\u001b[39m         get_agg_lagged_features(news_factors)\n\u001b[32m     63\u001b[39m     ], \n\u001b[32m     64\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtraditional+news\u001b[39m\u001b[33m'\u001b[39m: time_series[\n\u001b[32m     65\u001b[39m         [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[33m'\u001b[39m\u001b[33mfews_ipc\u001b[39m\u001b[33m'\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m21\u001b[39m,\u001b[32m3\u001b[39m)] +\n\u001b[32m     66\u001b[39m         get_agg_lagged_features(t_variant_traditional_factors) + \n\u001b[32m     67\u001b[39m         t_invariant_traditional_factors +\n\u001b[32m     68\u001b[39m         get_agg_lagged_features(news_factors)\n\u001b[32m     69\u001b[39m     ],\n\u001b[32m     70\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexpert\u001b[39m\u001b[33m'\u001b[39m: time_series[\u001b[33m'\u001b[39m\u001b[33mfews_proj_near_3\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     71\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexpert+traditional\u001b[39m\u001b[33m'\u001b[39m: time_series[\n\u001b[32m     72\u001b[39m         [\u001b[33m'\u001b[39m\u001b[33mfews_proj_near_3\u001b[39m\u001b[33m'\u001b[39m] +\n\u001b[32m     73\u001b[39m         [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[33m'\u001b[39m\u001b[33mfews_ipc\u001b[39m\u001b[33m'\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m21\u001b[39m,\u001b[32m3\u001b[39m)] + \n\u001b[32m     74\u001b[39m         get_agg_lagged_features(t_variant_traditional_factors) + \n\u001b[32m     75\u001b[39m         t_invariant_traditional_factors\n\u001b[32m     76\u001b[39m     ],\n\u001b[32m     77\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexpert+news\u001b[39m\u001b[33m'\u001b[39m: time_series[\n\u001b[32m     78\u001b[39m         [\u001b[33m'\u001b[39m\u001b[33mfews_proj_near_3\u001b[39m\u001b[33m'\u001b[39m] +\n\u001b[32m     79\u001b[39m         [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[33m'\u001b[39m\u001b[33mfews_ipc\u001b[39m\u001b[33m'\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m21\u001b[39m,\u001b[32m3\u001b[39m)] +\n\u001b[32m     80\u001b[39m         get_agg_lagged_features(news_factors)\n\u001b[32m     81\u001b[39m     ],\n\u001b[32m     82\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mexpert+traditional+news\u001b[39m\u001b[33m'\u001b[39m: time_series[\n\u001b[32m     83\u001b[39m         [\u001b[33m'\u001b[39m\u001b[33mfews_proj_near_3\u001b[39m\u001b[33m'\u001b[39m] +\n\u001b[32m     84\u001b[39m         [\u001b[33m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m'\u001b[39m.format(\u001b[33m'\u001b[39m\u001b[33mfews_ipc\u001b[39m\u001b[33m'\u001b[39m, t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m,\u001b[32m21\u001b[39m,\u001b[32m3\u001b[39m)] +\n\u001b[32m     85\u001b[39m         get_agg_lagged_features(t_variant_traditional_factors) + \n\u001b[32m     86\u001b[39m         t_invariant_traditional_factors +\n\u001b[32m     87\u001b[39m         get_agg_lagged_features(news_factors)\n\u001b[32m     88\u001b[39m     ]\n\u001b[32m     89\u001b[39m }\n\u001b[32m     91\u001b[39m labels_df = time_series[\u001b[33m'\u001b[39m\u001b[33mfews_ipc\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_time_split\u001b[39m(df, start, end):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/world-bank-proj/world-bank/lib/python3.13/site-packages/pandas/core/frame.py:4108\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4106\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4107\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4108\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4110\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/world-bank-proj/world-bank/lib/python3.13/site-packages/pandas/core/indexes/base.py:6200\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6197\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6198\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6200\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6202\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6203\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6204\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/world-bank-proj/world-bank/lib/python3.13/site-packages/pandas/core/indexes/base.py:6252\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6249\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6251\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6252\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['fews_ipc_3', 'fews_ipc_6', 'fews_ipc_9', 'fews_ipc_12', 'fews_ipc_15', 'fews_ipc_18'] not in index\""
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "test_splits = [\n",
    "    ((2010,7), (2011, 7)), \n",
    "    ((2011,7), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)), \n",
    "    ((2013,7), (2014, 7)), \n",
    "    ((2014,7), (2015, 7)), \n",
    "    ((2015,7), (2016, 7)), \n",
    "    ((2016,7), (2017, 7)), \n",
    "    ((2017,7), (2018, 7)),\n",
    "    ((2018,7), (2019, 7)), \n",
    "    ((2019,2), (2020, 2)),\n",
    "]\n",
    "train_splits = [\n",
    "    ((2009,7), (2010,4)),\n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2009,7), (2011,10)),\n",
    "    ((2009,7), (2012,7)),\n",
    "    ((2009,7), (2013,7)),\n",
    "    ((2009,7), (2014,1)),\n",
    "    ((2009,7), (2015,1)),\n",
    "    ((2009,7), (2015,10)),\n",
    "    ((2009,7), (2016,10)),\n",
    "    ((2009,7), (2017,2))]\n",
    "dev_splits = [\n",
    "    ((2010,4), (2010, 7)),\n",
    "    ((2011,1), (2011, 7)),\n",
    "    ((2011,10), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)),\n",
    "    ((2013,4), (2014, 7)),\n",
    "    ((2014,1), (2015, 7)),\n",
    "    ((2015,1), (2016, 7)),\n",
    "    ((2015,10), (2017, 7)),\n",
    "    ((2016,10), (2018, 7)),\n",
    "    ((2017,2), (2019, 2)),\n",
    "]\n",
    "rf = RandomForestRegressor(max_features='auto', n_estimators=100, \n",
    "                             min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0)\n",
    "ols = LinearRegression()\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return ['{}_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + ['{}_province_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + ['{}_country_{}'.format(f, t) for f, t in zip(factors, range(3,9))]\n",
    "        \n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ], \n",
    "    'news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ], \n",
    "    'traditional+news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert': time_series['fews_proj_near_3'],\n",
    "    'expert+traditional': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ],\n",
    "    'expert+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert+traditional+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ]\n",
    "}\n",
    "\n",
    "labels_df = time_series['fews_ipc']\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[df['year'] >= start[0] & df['month'] >= start[1] & df['year'] <= end[0] & df['month'] <= end[1]]\n",
    "\n",
    "\n",
    "fig_3a = pd.DataFrame(columns=['method', 'split', 'features', 'country', 'rmse', 'lower_bound', 'upper_bound'])\n",
    "fig_3b = pd.DataFrame(columns=['method', 'split', 'features', 'aucpr'])\n",
    "fig_3c = pd.DataFrame(columns=['method', 'split', 'features', 'recall_at_80p'])\n",
    "\n",
    "thresholds = {'traditional': (2.236, 3.125), \n",
    "              'news': (1.907, 2.712), \n",
    "              'traditional+news': (2.105, 3.314),\n",
    "              'expert': (2, 3),\n",
    "              'expert+news': (1.912, 2.813),\n",
    "              'expert+traditional': (2.241, 3.132),\n",
    "              'expert+traditional+news': (2.172, 3.321)\n",
    "             }\n",
    "\n",
    "for train, dev, test in zip(train_splits, dev_splits, test_splits):\n",
    "    for f, D in features.items():\n",
    "        X = get_time_split(D, train[0], train[1])\n",
    "        y = get_time_split(labels_df, test[0], test[1])\n",
    "        X_test = get_time_split(D, test[0], test[1])\n",
    "        for name, regr in zip(['RF', 'OLS', 'Lasso'], [rf, ols, lasso]):\n",
    "            regr.fit(X, y)\n",
    "            preds = regr.predict(X_test)\n",
    "            labels = get_time_split(labels_df, test[0], test[1])\n",
    "            rmse = mean_squared_error(labels, preds, squared=False)\n",
    "            stderr = diebold_mariano(preds, labels)\n",
    "            upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "            lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "            precision, recall, thresholds = precision_recall_curve(labels, preds)\n",
    "            auc_precision_recall = auc(recall, precision)\n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], 'country': ['all'],\n",
    "                                           'rmse': [rmse], 'lower_bound': [lower_bound], 'upper_bound': [upper_bound]},\n",
    "                                          orient='columns')\n",
    "            fig_3a = pd.concat([fig_3a, _row], axis=0)\n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], \n",
    "                                           'aucpr': [auc_precision_recall]},\n",
    "                                          orient='columns')\n",
    "            fig_3b = pd.concat([fig_3b, _row], axis=0)\n",
    "            print (\"Method: {}, Split: {}, Features: {}, AUCPR: {}\".format(name, test, f, auc_precision_recall))\n",
    "            print (\"Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(name, test, f, rmse, lower_bound, upper_bound))\n",
    "            \n",
    "            recall_at_80p = 0\n",
    "            for p_t, p_t_add_3, p_t_min_3 in zip(preds, preds[3:] + [1,1,1], preds[:-3]+[5,5,5]):\n",
    "                u_b = thresholds[f]['upper_bound']\n",
    "                l_b = thresholds[f]['lower_bound']\n",
    "                if p_t >= u_b and p_t_add_3 >= u_b and p_t_min_3 <= l_b:\n",
    "                    recall_at_80p += 1\n",
    "            \n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], \n",
    "                                           'recall_at_80p': [recall_at_80p]},\n",
    "                                          orient='columns')\n",
    "            fig_3c = pd.concat([fig_3c, _row], axis=0)\n",
    "            \n",
    "            # for country in time_series['country'].unique():\n",
    "            #     c_id = X_test[X_test['country']==country]\n",
    "            #     labels_c = labels[c_id]\n",
    "            #     preds_c = preds[c_id]\n",
    "            #     rmse = mean_squared_error(labels_c, preds_c, squared=False)\n",
    "            #     stderr = diebold_mariano(preds_c, labels_c)\n",
    "            #     upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "            #     lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "            #     _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], 'country': [country],\n",
    "            #                                'rmse': [rmse], 'lower_bound': [lower_bound], 'upper_bound': [upper_bound]},\n",
    "            #                               orient='columns')\n",
    "            #     fig_3a = pd.concat([fig_3a, _row], axis=0)\n",
    "            #     print (\"Country: {}, Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(country, name, test, f, rmse, lower_bound, upper_bound))\n",
    "\n",
    "# fig_3a.to_csv('fig_3a.csv')\n",
    "fig_3b.to_csv('fig_3b.csv')\n",
    "fig_3c.to_csv('fig_3c.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world-bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
