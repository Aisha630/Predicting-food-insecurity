{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 **Re-Implementation of \"Predicting Food Crises Using News Streams\"**\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 **Objective**\n",
    "\n",
    "This notebook aims to **reproduce and analyze** the methodology presented in the paper:\n",
    "\n",
    "📄 **Paper:** [Predicting food crises using news streams](https://www.science.org/doi/10.1126/sciadv.abm3449)  \n",
    "📊 **Dataset:** [Harvard Dataverse Repository](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CJDWUW)  \n",
    "📜 **Original Code & Methods:** [GitHub - Regression Modeling (Step 5)](https://github.com/philippzi98/food_insecurity_predictions_nlp/blob/main/Step%205%20-%20Regression%20Modelling/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🛠 **Methodology**\n",
    "\n",
    "This implementation follows the **key steps** outlined in the paper to predict **food insecurity crises** using a combination of:\n",
    "1️⃣ **Traditional Risk Factors** (conflict, climate, food prices, etc.)  \n",
    "2️⃣ **News-Based Indicators** (text feature frequencies from news articles)  \n",
    "3️⃣ **Lagging & Aggregation** (temporal dependencies at district, province, and country levels)  \n",
    "4️⃣ **Machine Learning Models** (Random Forest, OLS, Lasso)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔗 **Reference Materials**\n",
    "\n",
    "📄 **Supplementary Material:** Available in `supplemental_material_from_paper.pdf`  \n",
    "📊 **Datasets Used:**\n",
    "\n",
    "- `time_series_with_causes_zscore_full.csv` (Main dataset with time-series features)\n",
    "- `famine-country-province-district-years-CS.csv` (Food insecurity classification)\n",
    "- `matching_districts.csv` (Geographical standardization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚🔧 Import Libraries\n",
    "\n",
    "In this notebook, we will use uv to manage our Python environment and packages efficiently. uv is a modern and fast package manager that simplifies virtual environment creation, and dependency installation. We will create a virtual environment, install necessary libraries, and ensure our environment stays consistent across different setups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncoment the below cell to install `uv` if you have not already. You can also install it trhiugh `pip` by running `!pip install uv` but this will be within your current python environment and not globally.\n",
    "\n",
    "# !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# !uv venv world-bank\n",
    "# !source world-bank/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import editdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have the data downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 Load and Clean Data\n",
    "\n",
    "**Understanding the Time-Series Dataset & Column Selection**\n",
    "\n",
    "This dataset contains **district-level time-series data** on food insecurity risk factors, including:\n",
    "\n",
    "- **📅 Temporal Information:** `year`, `month`, `year_month`\n",
    "- **📍 Geographical Identifiers:** `admin_code`, `admin_name`, `province`, `country`\n",
    "- **🌍 Traditional Risk Factors:** Climate (`rain_mean`, `ndvi_mean`), conflict (`acled_count`), food prices (`p_staple_food`)\n",
    "- **📰 News-Based Indicators:** Proportions of news articles mentioning crisis-related keywords (`conflict_0`, `famine_0`, etc.)\n",
    "- **📉 Food Insecurity Label:** `fews_ipc` (Integrated Phase Classification)\n",
    "\n",
    "🔥 **Columns We Will Drop & Why**\n",
    "✔ **Redundant Aggregations:** `_1`, `_2` columns (province & country-level values) since we will recompute aggregations from scratch anyways.  \n",
    "✔ **Unnamed/Index Columns:** `Unnamed: 0` as it is unnecessary. It is just a duplicate of default index.\n",
    "✔ **Unnecessary Identifiers:** If `admin_code` and `admin_name`, after matching these to `matching_districts.csv`, we can drop them.\n",
    "\n",
    "---\n",
    "\n",
    "> ⚠️ **NOTE:**  \n",
    "> For a detailed explanation of the dataset and features, refer to the [`explore_time_series.ipynb`](./explore_time_series.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = pd.read_csv('./data/time_series_with_causes_zscore_full.csv', nrows=15)\n",
    "admins = pd.read_csv('./data/famine-country-province-district-years-CS.csv')\n",
    "valid_matching = pd.read_csv('./data/matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'abnormally low rainfall_0',\n",
       " 'abnormally low rainfall_1',\n",
       " 'abnormally low rainfall_2',\n",
       " 'acled_count',\n",
       " 'acled_fatalities',\n",
       " 'acute hunger_0',\n",
       " 'acute hunger_1',\n",
       " 'acute hunger_2',\n",
       " 'admin_code',\n",
       " 'admin_name',\n",
       " 'aid appeal_0',\n",
       " 'aid appeal_1',\n",
       " 'aid appeal_2',\n",
       " 'aid workers died_0',\n",
       " 'aid workers died_1',\n",
       " 'aid workers died_2',\n",
       " 'air attack_0',\n",
       " 'air attack_1',\n",
       " 'air attack_2',\n",
       " 'alarming level_0',\n",
       " 'alarming level_1',\n",
       " 'alarming level_2',\n",
       " 'anti-western policies_0',\n",
       " 'anti-western policies_1',\n",
       " 'anti-western policies_2',\n",
       " 'apathy_0',\n",
       " 'apathy_1',\n",
       " 'apathy_2',\n",
       " 'area',\n",
       " 'asylum seekers_0',\n",
       " 'asylum seekers_1',\n",
       " 'asylum seekers_2',\n",
       " 'authoritarian_0',\n",
       " 'authoritarian_1',\n",
       " 'authoritarian_2',\n",
       " 'bad harvests_0',\n",
       " 'bad harvests_1',\n",
       " 'bad harvests_2',\n",
       " 'blockade_0',\n",
       " 'blockade_1',\n",
       " 'blockade_2',\n",
       " 'bombing campaign_0',\n",
       " 'bombing campaign_1',\n",
       " 'bombing campaign_2',\n",
       " 'brain drain_0',\n",
       " 'brain drain_1',\n",
       " 'brain drain_2',\n",
       " 'brutal government_0',\n",
       " 'brutal government_1',\n",
       " 'brutal government_2',\n",
       " 'burning houses_0',\n",
       " 'burning houses_1',\n",
       " 'burning houses_2',\n",
       " 'call for donations_0',\n",
       " 'call for donations_1',\n",
       " 'call for donations_2',\n",
       " 'carbon_0',\n",
       " 'carbon_1',\n",
       " 'carbon_2',\n",
       " 'catastrophe_0',\n",
       " 'catastrophe_1',\n",
       " 'catastrophe_2',\n",
       " 'cattle death_0',\n",
       " 'cattle death_1',\n",
       " 'cattle death_2',\n",
       " 'cattle plague_0',\n",
       " 'cattle plague_1',\n",
       " 'cattle plague_2',\n",
       " 'centx',\n",
       " 'centy',\n",
       " 'change_fews',\n",
       " 'cholera outbreak_0',\n",
       " 'cholera outbreak_1',\n",
       " 'cholera outbreak_2',\n",
       " 'civil strife_0',\n",
       " 'civil strife_1',\n",
       " 'civil strife_2',\n",
       " 'civilians uprooted_0',\n",
       " 'civilians uprooted_1',\n",
       " 'civilians uprooted_2',\n",
       " 'clan battle_0',\n",
       " 'clan battle_1',\n",
       " 'clan battle_2',\n",
       " 'clan warfare_0',\n",
       " 'clan warfare_1',\n",
       " 'clan warfare_2',\n",
       " 'clans_0',\n",
       " 'clans_1',\n",
       " 'clans_2',\n",
       " 'climate change_0',\n",
       " 'climate change_1',\n",
       " 'climate change_2',\n",
       " 'climatic hazards_0',\n",
       " 'climatic hazards_1',\n",
       " 'climatic hazards_2',\n",
       " 'collapse of government_0',\n",
       " 'collapse of government_1',\n",
       " 'collapse of government_2',\n",
       " 'collapsing economy_0',\n",
       " 'collapsing economy_1',\n",
       " 'collapsing economy_2',\n",
       " 'conflict_0',\n",
       " 'conflict_1',\n",
       " 'conflict_2',\n",
       " 'continued deterioration_0',\n",
       " 'continued deterioration_1',\n",
       " 'continued deterioration_2',\n",
       " 'continued strife_0',\n",
       " 'continued strife_1',\n",
       " 'continued strife_2',\n",
       " 'convoys_0',\n",
       " 'convoys_1',\n",
       " 'convoys_2',\n",
       " 'corrupt government_0',\n",
       " 'corrupt government_1',\n",
       " 'corrupt government_2',\n",
       " 'corruption_0',\n",
       " 'corruption_1',\n",
       " 'corruption_2',\n",
       " 'country',\n",
       " 'coup_0',\n",
       " 'coup_1',\n",
       " 'coup_2',\n",
       " 'cropland_pct',\n",
       " 'cycle of poverty_0',\n",
       " 'cycle of poverty_1',\n",
       " 'cycle of poverty_2',\n",
       " 'cyclone_0',\n",
       " 'cyclone_1',\n",
       " 'cyclone_2',\n",
       " \"d'etat_0\",\n",
       " \"d'etat_1\",\n",
       " \"d'etat_2\",\n",
       " 'dehydrated_0',\n",
       " 'dehydrated_1',\n",
       " 'dehydrated_2',\n",
       " 'destructive pattern_0',\n",
       " 'destructive pattern_1',\n",
       " 'destructive pattern_2',\n",
       " 'devastated the economy_0',\n",
       " 'devastated the economy_1',\n",
       " 'devastated the economy_2',\n",
       " 'dictators_0',\n",
       " 'dictators_1',\n",
       " 'dictators_2',\n",
       " 'displaced_0',\n",
       " 'displaced_1',\n",
       " 'displaced_2',\n",
       " 'disrupted trade_0',\n",
       " 'disrupted trade_1',\n",
       " 'disrupted trade_2',\n",
       " 'disruption to farming_0',\n",
       " 'disruption to farming_1',\n",
       " 'disruption to farming_2',\n",
       " 'drought_0',\n",
       " 'drought_1',\n",
       " 'drought_2',\n",
       " 'dysfunction_0',\n",
       " 'dysfunction_1',\n",
       " 'dysfunction_2',\n",
       " 'ecological crisis_0',\n",
       " 'ecological crisis_1',\n",
       " 'ecological crisis_2',\n",
       " 'economic crisis_0',\n",
       " 'economic crisis_1',\n",
       " 'economic crisis_2',\n",
       " 'economic impoverishment_0',\n",
       " 'economic impoverishment_1',\n",
       " 'economic impoverishment_2',\n",
       " 'environmental degradation_0',\n",
       " 'environmental degradation_1',\n",
       " 'environmental degradation_2',\n",
       " 'epidemics_0',\n",
       " 'epidemics_1',\n",
       " 'epidemics_2',\n",
       " 'et_anom',\n",
       " 'et_mean',\n",
       " 'failed crops_0',\n",
       " 'failed crops_1',\n",
       " 'failed crops_2',\n",
       " 'failed rains_0',\n",
       " 'failed rains_1',\n",
       " 'failed rains_2',\n",
       " 'farmland_0',\n",
       " 'farmland_1',\n",
       " 'farmland_2',\n",
       " 'fews_ha',\n",
       " 'fews_ipc',\n",
       " 'fews_proj_med',\n",
       " 'fews_proj_med_ha',\n",
       " 'fews_proj_near',\n",
       " 'fews_proj_near_ha',\n",
       " 'flee_0',\n",
       " 'flee_1',\n",
       " 'flee_2',\n",
       " 'floods_0',\n",
       " 'floods_1',\n",
       " 'floods_2',\n",
       " 'food assistance_0',\n",
       " 'food assistance_1',\n",
       " 'food assistance_2',\n",
       " 'food crisis_0',\n",
       " 'food crisis_1',\n",
       " 'food crisis_2',\n",
       " 'food insecurity_0',\n",
       " 'food insecurity_1',\n",
       " 'food insecurity_2',\n",
       " 'foreign aid_0',\n",
       " 'foreign aid_1',\n",
       " 'foreign aid_2',\n",
       " 'foreign troops_0',\n",
       " 'foreign troops_1',\n",
       " 'foreign troops_2',\n",
       " 'forests destroyed_0',\n",
       " 'forests destroyed_1',\n",
       " 'forests destroyed_2',\n",
       " 'gangs of bandits_0',\n",
       " 'gangs of bandits_1',\n",
       " 'gangs of bandits_2',\n",
       " 'gastrointestinal_0',\n",
       " 'gastrointestinal_1',\n",
       " 'gastrointestinal_2',\n",
       " 'greenhouse gases_0',\n",
       " 'greenhouse gases_1',\n",
       " 'greenhouse gases_2',\n",
       " 'harvest decline_0',\n",
       " 'harvest decline_1',\n",
       " 'harvest decline_2',\n",
       " 'harvests are devastated_0',\n",
       " 'harvests are devastated_1',\n",
       " 'harvests are devastated_2',\n",
       " 'human rights abuses_0',\n",
       " 'human rights abuses_1',\n",
       " 'human rights abuses_2',\n",
       " 'humanitarian disaster_0',\n",
       " 'humanitarian disaster_1',\n",
       " 'humanitarian disaster_2',\n",
       " 'humanitarian situation_0',\n",
       " 'humanitarian situation_1',\n",
       " 'humanitarian situation_2',\n",
       " 'hunger crises_0',\n",
       " 'hunger crises_1',\n",
       " 'hunger crises_2',\n",
       " 'inadequate rainfall_0',\n",
       " 'inadequate rainfall_1',\n",
       " 'inadequate rainfall_2',\n",
       " 'increased external debt_0',\n",
       " 'increased external debt_1',\n",
       " 'increased external debt_2',\n",
       " 'index',\n",
       " 'infant mortality_0',\n",
       " 'infant mortality_1',\n",
       " 'infant mortality_2',\n",
       " 'infrastructure damage_0',\n",
       " 'infrastructure damage_1',\n",
       " 'infrastructure damage_2',\n",
       " 'internal strife_0',\n",
       " 'internal strife_1',\n",
       " 'internal strife_2',\n",
       " 'international alarm_0',\n",
       " 'international alarm_1',\n",
       " 'international alarm_2',\n",
       " 'international embargo_0',\n",
       " 'international embargo_1',\n",
       " 'international embargo_2',\n",
       " 'international intervention_0',\n",
       " 'international intervention_1',\n",
       " 'international intervention_2',\n",
       " 'international terrorists_0',\n",
       " 'international terrorists_1',\n",
       " 'international terrorists_2',\n",
       " 'jihadist groups_0',\n",
       " 'jihadist groups_1',\n",
       " 'jihadist groups_2',\n",
       " 'lack of agricultural infrastructure_0',\n",
       " 'lack of agricultural infrastructure_1',\n",
       " 'lack of agricultural infrastructure_2',\n",
       " 'lack of alternatives_0',\n",
       " 'lack of alternatives_1',\n",
       " 'lack of alternatives_2',\n",
       " 'lack of authority_0',\n",
       " 'lack of authority_1',\n",
       " 'lack of authority_2',\n",
       " 'lack of cultivation_0',\n",
       " 'lack of cultivation_1',\n",
       " 'lack of cultivation_2',\n",
       " 'lack of rains_0',\n",
       " 'lack of rains_1',\n",
       " 'lack of rains_2',\n",
       " 'lack of roads_0',\n",
       " 'lack of roads_1',\n",
       " 'lack of roads_2',\n",
       " 'land degradation_0',\n",
       " 'land degradation_1',\n",
       " 'land degradation_2',\n",
       " 'land grab_0',\n",
       " 'land grab_1',\n",
       " 'land grab_2',\n",
       " 'land invasions_0',\n",
       " 'land invasions_1',\n",
       " 'land invasions_2',\n",
       " 'land reform_0',\n",
       " 'land reform_1',\n",
       " 'land reform_2',\n",
       " 'land seizures_0',\n",
       " 'land seizures_1',\n",
       " 'land seizures_2',\n",
       " 'life-threatening hunger_0',\n",
       " 'life-threatening hunger_1',\n",
       " 'life-threatening hunger_2',\n",
       " 'livestock had died_0',\n",
       " 'livestock had died_1',\n",
       " 'livestock had died_2',\n",
       " 'locusts_0',\n",
       " 'locusts_1',\n",
       " 'locusts_2',\n",
       " 'looting_0',\n",
       " 'looting_1',\n",
       " 'looting_2',\n",
       " 'major offensive_0',\n",
       " 'major offensive_1',\n",
       " 'major offensive_2',\n",
       " 'makeshift camps_0',\n",
       " 'makeshift camps_1',\n",
       " 'makeshift camps_2',\n",
       " 'malnourished_0',\n",
       " 'malnourished_1',\n",
       " 'malnourished_2',\n",
       " 'man-made disaster_0',\n",
       " 'man-made disaster_1',\n",
       " 'man-made disaster_2',\n",
       " 'mass hunger_0',\n",
       " 'mass hunger_1',\n",
       " 'mass hunger_2',\n",
       " 'massive starvation_0',\n",
       " 'massive starvation_1',\n",
       " 'massive starvation_2',\n",
       " 'mayhem_0',\n",
       " 'mayhem_1',\n",
       " 'mayhem_2',\n",
       " 'migration_0',\n",
       " 'migration_1',\n",
       " 'migration_2',\n",
       " 'military dictatorship_0',\n",
       " 'military dictatorship_1',\n",
       " 'military dictatorship_2',\n",
       " 'military junta_0',\n",
       " 'military junta_1',\n",
       " 'military junta_2',\n",
       " 'militia groups_0',\n",
       " 'militia groups_1',\n",
       " 'militia groups_2',\n",
       " 'mismanagement_0',\n",
       " 'mismanagement_1',\n",
       " 'mismanagement_2',\n",
       " 'month',\n",
       " 'natural disaster_0',\n",
       " 'natural disaster_1',\n",
       " 'natural disaster_2',\n",
       " 'ndvi_anom',\n",
       " 'ndvi_mean',\n",
       " 'oppressive regimes_0',\n",
       " 'oppressive regimes_1',\n",
       " 'oppressive regimes_2',\n",
       " 'overthrow_0',\n",
       " 'overthrow_1',\n",
       " 'overthrow_2',\n",
       " 'p_staple_food',\n",
       " 'pasture_pct',\n",
       " 'pests_0',\n",
       " 'pests_1',\n",
       " 'pests_2',\n",
       " 'pirates_0',\n",
       " 'pirates_1',\n",
       " 'pirates_2',\n",
       " 'police torture_0',\n",
       " 'police torture_1',\n",
       " 'police torture_2',\n",
       " 'politically engineered_0',\n",
       " 'politically engineered_1',\n",
       " 'politically engineered_2',\n",
       " 'poor soil quality_0',\n",
       " 'poor soil quality_1',\n",
       " 'poor soil quality_2',\n",
       " 'pop',\n",
       " 'population crisis_0',\n",
       " 'population crisis_1',\n",
       " 'population crisis_2',\n",
       " 'potato blight_0',\n",
       " 'potato blight_1',\n",
       " 'potato blight_2',\n",
       " 'power struggle_0',\n",
       " 'power struggle_1',\n",
       " 'power struggle_2',\n",
       " 'price of food_0',\n",
       " 'price of food_1',\n",
       " 'price of food_2',\n",
       " 'price rise_0',\n",
       " 'price rise_1',\n",
       " 'price rise_2',\n",
       " 'prolonged dry spell_0',\n",
       " 'prolonged dry spell_1',\n",
       " 'prolonged dry spell_2',\n",
       " 'prolonged fighting_0',\n",
       " 'prolonged fighting_1',\n",
       " 'prolonged fighting_2',\n",
       " 'pushing peasants off_0',\n",
       " 'pushing peasants off_1',\n",
       " 'pushing peasants off_2',\n",
       " 'rain_anom',\n",
       " 'rain_mean',\n",
       " 'rebel insurgency_0',\n",
       " 'rebel insurgency_1',\n",
       " 'rebel insurgency_2',\n",
       " 'reduced imports_0',\n",
       " 'reduced imports_1',\n",
       " 'reduced imports_2',\n",
       " 'reduced national output_0',\n",
       " 'reduced national output_1',\n",
       " 'reduced national output_2',\n",
       " 'refugees_0',\n",
       " 'refugees_1',\n",
       " 'refugees_2',\n",
       " 'regimes were toppled_0',\n",
       " 'regimes were toppled_1',\n",
       " 'regimes were toppled_2',\n",
       " 'repression_0',\n",
       " 'repression_1',\n",
       " 'repression_2',\n",
       " 'restricted humanitarian access_0',\n",
       " 'restricted humanitarian access_1',\n",
       " 'restricted humanitarian access_2',\n",
       " 'restricted relief flights_0',\n",
       " 'restricted relief flights_1',\n",
       " 'restricted relief flights_2',\n",
       " 'rinderpest_0',\n",
       " 'rinderpest_1',\n",
       " 'rinderpest_2',\n",
       " 'rise_0',\n",
       " 'rise_1',\n",
       " 'rise_2',\n",
       " 'rising food prices_0',\n",
       " 'rising food prices_1',\n",
       " 'rising food prices_2',\n",
       " 'rising inflation_0',\n",
       " 'rising inflation_1',\n",
       " 'rising inflation_2',\n",
       " 'rival warlords_0',\n",
       " 'rival warlords_1',\n",
       " 'rival warlords_2',\n",
       " 'ruggedness_mean',\n",
       " 'scanty rainfall_0',\n",
       " 'scanty rainfall_1',\n",
       " 'scanty rainfall_2',\n",
       " 'secession_0',\n",
       " 'secession_1',\n",
       " 'secession_2',\n",
       " 'self reliance_0',\n",
       " 'self reliance_1',\n",
       " 'self reliance_2',\n",
       " 'severe rains_0',\n",
       " 'severe rains_1',\n",
       " 'severe rains_2',\n",
       " 'shortage of rains_0',\n",
       " 'shortage of rains_1',\n",
       " 'shortage of rains_2',\n",
       " 'siege_0',\n",
       " 'siege_1',\n",
       " 'siege_2',\n",
       " 'slashed export_0',\n",
       " 'slashed export_1',\n",
       " 'slashed export_2',\n",
       " 'slave trade_0',\n",
       " 'slave trade_1',\n",
       " 'slave trade_2',\n",
       " 'stolen food aid_0',\n",
       " 'stolen food aid_1',\n",
       " 'stolen food aid_2',\n",
       " 'terrorism_0',\n",
       " 'terrorism_1',\n",
       " 'terrorism_2',\n",
       " 'terrorist_0',\n",
       " 'terrorist_1',\n",
       " 'terrorist_2',\n",
       " 'the offensive_0',\n",
       " 'the offensive_1',\n",
       " 'the offensive_2',\n",
       " 'toll on livestock_0',\n",
       " 'toll on livestock_1',\n",
       " 'toll on livestock_2',\n",
       " 'totalitarian_0',\n",
       " 'totalitarian_1',\n",
       " 'totalitarian_2',\n",
       " 'tragedy_0',\n",
       " 'tragedy_1',\n",
       " 'tragedy_2',\n",
       " 'transport bottleneck_0',\n",
       " 'transport bottleneck_1',\n",
       " 'transport bottleneck_2',\n",
       " 'unable to sow_0',\n",
       " 'unable to sow_1',\n",
       " 'unable to sow_2',\n",
       " 'violent suppression_0',\n",
       " 'violent suppression_1',\n",
       " 'violent suppression_2',\n",
       " 'warlord_0',\n",
       " 'warlord_1',\n",
       " 'warlord_2',\n",
       " 'water availability_0',\n",
       " 'water availability_1',\n",
       " 'water availability_2',\n",
       " 'water distribution shortages_0',\n",
       " 'water distribution shortages_1',\n",
       " 'water distribution shortages_2',\n",
       " 'weather extremes_0',\n",
       " 'weather extremes_1',\n",
       " 'weather extremes_2',\n",
       " 'withheld relief_0',\n",
       " 'withheld relief_1',\n",
       " 'withheld relief_2',\n",
       " 'without international aid_0',\n",
       " 'without international aid_1',\n",
       " 'without international aid_2',\n",
       " 'wreaked havoc_0',\n",
       " 'wreaked havoc_1',\n",
       " 'wreaked havoc_2',\n",
       " 'year',\n",
       " 'year_month',\n",
       " 'years of warfare_0',\n",
       " 'years of warfare_1',\n",
       " 'years of warfare_2']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>centx</th>\n",
       "      <th>centy</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon_2</th>\n",
       "      <th>mayhem_0</th>\n",
       "      <th>mayhem_1</th>\n",
       "      <th>mayhem_2</th>\n",
       "      <th>dehydrated_0</th>\n",
       "      <th>dehydrated_1</th>\n",
       "      <th>dehydrated_2</th>\n",
       "      <th>mismanagement_0</th>\n",
       "      <th>mismanagement_1</th>\n",
       "      <th>mismanagement_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>-0.171000</td>\n",
       "      <td>-0.833000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>1.284667</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>-0.427667</td>\n",
       "      <td>0.668333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660812</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.520247</td>\n",
       "      <td>-0.782913</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.612254</td>\n",
       "      <td>-0.926921</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>-0.625133</td>\n",
       "      <td>-0.452467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.844333</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>-0.689667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>-0.471333</td>\n",
       "      <td>0.955333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326927</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>0.164790</td>\n",
       "      <td>-0.905210</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-0.810600</td>\n",
       "      <td>-0.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.085146</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.867913</td>\n",
       "      <td>-0.770247</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.974587</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>-0.709800</td>\n",
       "      <td>-0.622800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index      country  admin_code admin_name      centx  \\\n",
       "0           0     30  Afghanistan         202   Kandahar  65.709343   \n",
       "1           1     33  Afghanistan         202   Kandahar  65.709343   \n",
       "2           2     36  Afghanistan         202   Kandahar  65.709343   \n",
       "3           3     39  Afghanistan         202   Kandahar  65.709343   \n",
       "4           4     42  Afghanistan         202   Kandahar  65.709343   \n",
       "\n",
       "       centy year_month  year  month  ...  carbon_2  mayhem_0  mayhem_1  \\\n",
       "0  31.043618    2009_07  2009      7  ...  1.053000  0.667000 -0.171000   \n",
       "1  31.043618    2009_10  2009     10  ... -0.660812 -0.636580 -0.520247   \n",
       "2  31.043618    2010_01  2010      1  ... -0.134333  1.447667 -0.844333   \n",
       "3  31.043618    2010_04  2010      4  ... -0.326927 -0.594877  0.164790   \n",
       "4  31.043618    2010_07  2010      7  ... -1.085146 -0.709913 -0.867913   \n",
       "\n",
       "   mayhem_2  dehydrated_0  dehydrated_1  dehydrated_2  mismanagement_0  \\\n",
       "0 -0.833000      0.173667      0.168000      1.284667        -0.073000   \n",
       "1 -0.782913     -0.671587     -0.612254     -0.926921        -0.510467   \n",
       "2  0.778667     -0.676000     -0.689667      0.293333         0.530333   \n",
       "3 -0.905210     -0.620540      0.165794      0.045794        -1.011600   \n",
       "4 -0.770247     -0.787921     -0.974587     -0.946921        -0.611133   \n",
       "\n",
       "   mismanagement_1  mismanagement_2  \n",
       "0        -0.427667         0.668333  \n",
       "1        -0.625133        -0.452467  \n",
       "2        -0.471333         0.955333  \n",
       "3        -0.810600        -0.205600  \n",
       "4        -0.709800        -0.622800  \n",
       "\n",
       "[5 rows x 532 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = ['rain_mean']\n",
    "t_invariant_traditional_factors = ['area', 'pasture_pct']\n",
    "\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'land seizures_0'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count BEFORE dropping:  532\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count BEFORE dropping: \", len(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Unnamed: 0\", \"centx\", \"centy\", 'change_fews', 'fews_ha', 'fews_proj_med', 'fews_proj_med_ha', 'fews_proj_near_ha'] + [col for col in time_series.columns if col.endswith(('_1', '_2', '_3'))]\n",
    "time_series.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential extra columns ['et_mean', 'year', 'fews_proj_near', 'country', 'acled_fatalities', 'month', 'ndvi_mean', 'acled_count', 'rain_anom', 'year_month', 'et_anom', 'admin_name', 'pop', 'ndvi_anom', 'p_staple_food', 'ruggedness_mean', 'admin_code', 'cropland_pct', 'fews_ipc', 'index']\n"
     ]
    }
   ],
   "source": [
    "potential_extra_cols = set(time_series.columns.values) - set(t_variant_traditional_factors) - set(t_invariant_traditional_factors) - set(news_factors)\n",
    "potential_extra_cols = [col for col in potential_extra_cols if not col.endswith(('_1', '_2', '_3'))]\n",
    "print(\"Potential extra columns\", potential_extra_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count after dropping:  190\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count after dropping: \", len(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌍 Admin Level Mapping: Standardizing Geographical Identifiers\n",
    "\n",
    "In this section, we will **map and standardize** the `admin_code` and `admin_name` fields to their corresponding **district, province, and country names**. This step is **crucial** for ensuring **consistency** across different datasets and enabling **accurate aggregations** at multiple administrative levels.\n",
    "\n",
    "🛠 **Why is Admin Level Mapping Important?**\n",
    "✅ Different datasets may use **slightly different spellings or formats** for district names.  \n",
    "✅ Some district names might be **missing or misspelled**, requiring standardization.  \n",
    "✅ We need to **match and align** district names across various sources before aggregating at **province and country levels**.  \n",
    "✅ Proper mapping allows us to **merge datasets correctly** without losing information.  \n",
    "\n",
    "📌 **Steps in Admin Mapping**\n",
    "1️⃣ **Load the `matching_districts.csv` file**, which provides the mapping between different district name variations.  \n",
    "2️⃣ **Identify missing or unmatched `admin_name` values** and find their closest matches using fuzzy matching techniques.  \n",
    "3️⃣ **Ensure that each `admin_code` uniquely maps to one `district`, `province`, and `country`.**  \n",
    "4️⃣ **Replace inconsistent names** in the dataset with their standardized versions.  \n",
    "5️⃣ **Aggregate data at the `province` and `country` levels** after ensuring all districts are correctly mapped.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(admins.country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'country', 'district', 'year', 'month', 'CS',\n",
       "       'province'], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admins.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4113 474 39\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy String Matching for Missing Names\n",
    "\n",
    "The function uses **fuzzy string matching** to find the best approximate matches for missing administrative names (e.g., districts and provinces). \n",
    "\n",
    "- Finds the **best matching district/province** for each missing name.\n",
    "- Uses **fuzzy string matching** to calculate the similarity between missing names and known names.\n",
    "- Returns a dictionary that maps each missing name to its closest match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "\n",
    "# manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Decoding\n",
    "\n",
    "`to_ascii_escaped(s)`: Converts a Unicode string to an ASCII-safe representation using **unicode-escape**.\n",
    "\n",
    "`from_ascii_escaped(escaped)`: Converts the escaped ASCII string back into its original Unicode form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    # Using 'unicode-escape' encoding produces a bytes object,\n",
    "    # then decode it to get an ASCII string.\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def from_ascii_escaped(escaped):\n",
    "    \"\"\"\n",
    "    Convert the ASCII-escaped string back to the original Unicode string.\n",
    "    \"\"\"\n",
    "    # Encode the ASCII string to bytes, then decode using 'unicode-escape'\n",
    "    return escaped.encode('ascii').decode('unicode-escape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Province for a Given District or Province\n",
    "\n",
    "`find_province(x)`, finds the **province** corresponding to a given administrative name. It accounts for:\n",
    "- **Direct Lookups** (Exact match in known district/province lists)\n",
    "- **Fuzzy Matching** (Using ASCII-safe transformation for inconsistent text encoding)\n",
    "- **Validation Against a Predefined Mapping (`valid_matching`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matched globally\n",
    "matched = valid_matching['missing'].unique()\n",
    "\n",
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def find_province(x):\n",
    "    try:\n",
    "        # Ensure x is a Unicode string.\n",
    "        if isinstance(x, bytes):\n",
    "            x = x.decode('utf-8')\n",
    "        \n",
    "        # Direct lookup in districts or provinces.\n",
    "        if x in districts:\n",
    "            return admins[admins['district'] == x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "\n",
    "        # Convert x to an ASCII-escaped version.\n",
    "        escaped_x = to_ascii_escaped(x)\n",
    "        \n",
    "        # Check if the escaped version is in matched.\n",
    "        if escaped_x in matched:\n",
    "            v = valid_matching[valid_matching['missing'] == escaped_x]\n",
    "            if v['match'].values[0] == 'district':\n",
    "                x2 = v['district'].values[0]\n",
    "                return admins[admins['district'] == x2]['province'].values[0]\n",
    "            elif v['match'].values[0] == 'province':\n",
    "                return v['province'].values[0]\n",
    "        \n",
    "        # If no conditions are met, raise an exception.\n",
    "        raise Exception(\"No matching province found\")\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Province not found for: {} ({})\".format(x, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Admin Names with Accented Characters and Mapping to Provinces\n",
    "\n",
    "Maps `admin_names` to provinces using the `find_province(a)` function.  \n",
    "If a **direct lookup fails**, it tries to handle cases where the **admin name contains accented characters** (`é`, `è`, `ô`) ->  (encoding decoding issues resolved through directly replacing these with 'e' or 'o', leads to finding a valid match). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except Exception as e:\n",
    "        # Print the admin name that caused an error\n",
    "        print(\"Error with:\", a)\n",
    "        # Check if a contains accented characters \"é\" or \"è\"\n",
    "        if 'é' in a or 'è' in a or 'ô' in a:\n",
    "            a_modified = a.replace('é', 'e').replace('è', 'e').replace('ô', 'o')\n",
    "            # Check if the modified name is in districts\n",
    "            if a_modified in districts:\n",
    "                # Use the modified name to look up the province from admins\n",
    "                try:\n",
    "                    province = admins[admins['district'] == a_modified]['province'].values[0]\n",
    "                    admin_to_province[a] = province\n",
    "                    print(f\"Replaced '{a}' with '{a_modified}', found province: {province}\")\n",
    "                except Exception as ex:\n",
    "                    print(f\"Modified name '{a_modified}' not found in admins: {ex}\")\n",
    "            else:\n",
    "                print(f\"Modified name '{a_modified}' not in districts.\")\n",
    "        else:\n",
    "            print(f\"No accented e found in '{a}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Administrative Names to Provinces in time_series\n",
    "\n",
    "Maps `admin_name` to their respective **provinces** using a precomputed dictionary - >`admin_to_province` in `time_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series['province'] = time_series['admin_name'].apply(\n",
    "    lambda x: admin_to_province[x] if x in admin_to_province else admin_to_province.get(x.replace('ô', 'o'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admin_name</th>\n",
       "      <th>province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Kandahar</td>\n",
       "      <td>Kandahar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admin_name  province\n",
       "0    Kandahar  Kandahar\n",
       "1    Kandahar  Kandahar\n",
       "2    Kandahar  Kandahar\n",
       "3    Kandahar  Kandahar\n",
       "4    Kandahar  Kandahar\n",
       "5    Kandahar  Kandahar\n",
       "6    Kandahar  Kandahar\n",
       "7    Kandahar  Kandahar\n",
       "8    Kandahar  Kandahar\n",
       "9    Kandahar  Kandahar\n",
       "10   Kandahar  Kandahar\n",
       "11   Kandahar  Kandahar\n",
       "12   Kandahar  Kandahar\n",
       "13   Kandahar  Kandahar\n",
       "14   Kandahar  Kandahar"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series[[\"admin_name\", \"province\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⏳ Time Lagging & Feature Engineering\n",
    "\n",
    "#### 📅 **Why Use Lagging?**\n",
    "\n",
    "To predict food insecurity **for a given quarter**, we use:\n",
    "\n",
    "- **6 months of historical values** for traditional & news-based features.\n",
    "- **Province & country-level aggregations** to capture broader shocks.\n",
    "- **6 quarters of lagged IPC phase values** to model temporal dependencies.\n",
    "\n",
    "#### ⚡ **Optimized Lagging Approach**\n",
    "\n",
    "To improve computational efficiency, we:\n",
    "✔ Use `groupby()` for **fast province & country-level aggregations**.  \n",
    "✔ Merge lagged data via `merge()` instead of slow `.apply()`.  \n",
    "✔ Only keep **past data** to ensure no data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def get_lagged(x, f, t, ts_dict):\n",
    "    admin_code = x['admin_code']\n",
    "    year, month = x['year'], x['month']\n",
    "\n",
    "    # Compute lagged year and month\n",
    "    l_month = ((month - 1 - t) % 12) + 1\n",
    "    l_year = year - 1 if month - t <= 0 else year\n",
    "    lagged_year_month = f\"{l_year}_{l_month}\"\n",
    "\n",
    "    # Retrieve pre-filtered DataFrame\n",
    "    ts = ts_dict.get(admin_code)\n",
    "\n",
    "    # Ensure ts is a dictionary and extract only the requested feature\n",
    "    if ts is not None and lagged_year_month in ts:\n",
    "        lagged_values = ts[lagged_year_month]  # This might be a dictionary\n",
    "        if isinstance(lagged_values, dict):\n",
    "            return lagged_values.get(f, x[f])  # Extract only `f`\n",
    "        return lagged_values  # Directly return value if not a dict\n",
    "\n",
    "    return x[f]  # Fallback to original value\n",
    "\n",
    "\n",
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True):\n",
    "    levels = ['', '_province', '_country'] if agg else ['']\n",
    "\n",
    "    # Convert 'year_month' to index and precompute admin_code groupings\n",
    "    ts_dict = {ac: df.set_index('year_month')[features].to_dict(orient=\"index\")\n",
    "               for ac, df in time_series.groupby('admin_code')}\n",
    "\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f + suffix\n",
    "            for t in range(start, end, diff):\n",
    "                lagged_col = f\"{f_s}_{t}\"\n",
    "\n",
    "                if lagged_col in time_series.columns:\n",
    "                    continue\n",
    "\n",
    "                # Use list comprehension for better performance\n",
    "                time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
    "\n",
    "    return time_series  # Return modified DataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Province & Country-Level Aggregation\n",
    "\n",
    "This function aggregates feature values at the province and country levels to capture regional trends, aiding in food insecurity prediction. The process includes:\n",
    "\n",
    "- **Grouping by year_month and level:** Data is grouped by year_month and the specified level (province or country) to calculate the mean of features, reflecting regional trends over time.\n",
    "\n",
    "- **Applying transformations efficiently:** Instead of merging aggregated data, `transform(\"mean\")` is used to directly assign the computed mean to each row, avoiding unnecessary joins and improving performance.  \n",
    "\n",
    "#### ⚡ **Efficiency Gains**\n",
    "\n",
    "- **Fast Aggregation**: Uses `groupby()` for efficient aggregation.\n",
    "- **Avoids Costly Joins**: Eliminates the need for `merge()` by using `transform()` instead, reducing computational overhead.  \n",
    "- **Memory Efficiency**: Converts the `level` column to a categorical type to reduce memory usage.\n",
    "\n",
    "This approach ensures faster processing while maintaining the quality of aggregated features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_agg_factors(features, level='province'):\n",
    "    global time_series  \n",
    "\n",
    "    # Convert 'level' column to categorical for performance\n",
    "    time_series[level] = time_series[level].astype('category')\n",
    "    \n",
    "    # Compute grouped mean values for the given features\n",
    "    grouped_df = time_series.groupby(['year_month', level], observed=True, sort=False)[features].transform(\"mean\")\n",
    "\n",
    "    # Rename columns to include level\n",
    "    grouped_df = grouped_df.rename(columns={f: f\"{f}_{level}\" for f in features})\n",
    "\n",
    "    # Use pd.concat() to add all columns at once, avoiding fragmentation\n",
    "    time_series = pd.concat([time_series, grouped_df], axis=1)\n",
    "\n",
    "    return time_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gastrointestinal_0_province</th>\n",
       "      <th>terrorist_0_province</th>\n",
       "      <th>warlord_0_province</th>\n",
       "      <th>d'etat_0_province</th>\n",
       "      <th>overthrow_0_province</th>\n",
       "      <th>convoys_0_province</th>\n",
       "      <th>carbon_0_province</th>\n",
       "      <th>mayhem_0_province</th>\n",
       "      <th>dehydrated_0_province</th>\n",
       "      <th>mismanagement_0_province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>-0.284333</td>\n",
       "      <td>-0.668667</td>\n",
       "      <td>0.647333</td>\n",
       "      <td>-0.891333</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>1.265333</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>-0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545727</td>\n",
       "      <td>-1.037016</td>\n",
       "      <td>-0.811291</td>\n",
       "      <td>-0.850261</td>\n",
       "      <td>-0.948892</td>\n",
       "      <td>-0.728972</td>\n",
       "      <td>-0.765146</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.510467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.506333</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>1.595667</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>-0.868333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>0.530333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793970</td>\n",
       "      <td>-0.722159</td>\n",
       "      <td>-0.130521</td>\n",
       "      <td>0.047630</td>\n",
       "      <td>0.362613</td>\n",
       "      <td>0.480986</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>-1.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509394</td>\n",
       "      <td>-0.694350</td>\n",
       "      <td>-1.215958</td>\n",
       "      <td>-0.865261</td>\n",
       "      <td>-1.119225</td>\n",
       "      <td>-1.060638</td>\n",
       "      <td>-0.673479</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.611133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_10</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.691000</td>\n",
       "      <td>1.168667</td>\n",
       "      <td>-0.279333</td>\n",
       "      <td>-0.296667</td>\n",
       "      <td>1.651333</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>1.156667</td>\n",
       "      <td>1.202667</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_01</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.916000</td>\n",
       "      <td>0.334333</td>\n",
       "      <td>-0.847000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>1.328667</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.357667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_04</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098364</td>\n",
       "      <td>-0.792159</td>\n",
       "      <td>-0.083854</td>\n",
       "      <td>-0.229370</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.181986</td>\n",
       "      <td>-0.413594</td>\n",
       "      <td>0.278123</td>\n",
       "      <td>-0.235540</td>\n",
       "      <td>-0.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_07</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820667</td>\n",
       "      <td>-0.696000</td>\n",
       "      <td>-0.588667</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>1.049667</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.057000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>1.217667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_10</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>-0.851667</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>1.056333</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>-0.213000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382333</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.325667</td>\n",
       "      <td>-0.527000</td>\n",
       "      <td>-0.789000</td>\n",
       "      <td>-0.174333</td>\n",
       "      <td>-0.387667</td>\n",
       "      <td>-0.696333</td>\n",
       "      <td>0.993667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_04</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.437000</td>\n",
       "      <td>-0.224000</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>-0.343667</td>\n",
       "      <td>-0.690333</td>\n",
       "      <td>-0.267000</td>\n",
       "      <td>-0.291333</td>\n",
       "      <td>-0.553333</td>\n",
       "      <td>1.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_07</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.893667</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>0.063667</td>\n",
       "      <td>-0.807333</td>\n",
       "      <td>-0.633667</td>\n",
       "      <td>-0.818667</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>1.122000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.184000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_10</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.883000</td>\n",
       "      <td>1.068000</td>\n",
       "      <td>-0.714333</td>\n",
       "      <td>1.443000</td>\n",
       "      <td>1.471333</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.344667</td>\n",
       "      <td>-0.665667</td>\n",
       "      <td>-0.436667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2013_01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>...</td>\n",
       "      <td>0.671333</td>\n",
       "      <td>-0.805333</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>1.416000</td>\n",
       "      <td>1.163000</td>\n",
       "      <td>-0.271000</td>\n",
       "      <td>1.477000</td>\n",
       "      <td>-0.470333</td>\n",
       "      <td>-0.641667</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 358 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      country  admin_code admin_name year_month  year  month  \\\n",
       "0      30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1      33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2      36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3      39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4      42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "5      45  Afghanistan         202   Kandahar    2010_10  2010     10   \n",
       "6      48  Afghanistan         202   Kandahar    2011_01  2011      1   \n",
       "7      51  Afghanistan         202   Kandahar    2011_04  2011      4   \n",
       "8      54  Afghanistan         202   Kandahar    2011_07  2011      7   \n",
       "9      57  Afghanistan         202   Kandahar    2011_10  2011     10   \n",
       "10     60  Afghanistan         202   Kandahar    2012_01  2012      1   \n",
       "11     63  Afghanistan         202   Kandahar    2012_04  2012      4   \n",
       "12     66  Afghanistan         202   Kandahar    2012_07  2012      7   \n",
       "13     69  Afghanistan         202   Kandahar    2012_10  2012     10   \n",
       "14     72  Afghanistan         202   Kandahar    2013_01  2013      1   \n",
       "\n",
       "    fews_ipc  fews_proj_near  ndvi_mean  ...  gastrointestinal_0_province  \\\n",
       "0        1.0             NaN   0.106035  ...                    -0.192000   \n",
       "1        1.0             NaN   0.103009  ...                    -0.545727   \n",
       "2        2.0             NaN   0.109600  ...                     1.506333   \n",
       "3        2.0             NaN   0.111599  ...                    -0.793970   \n",
       "4        1.0             NaN   0.096943  ...                    -0.509394   \n",
       "5        2.0             NaN   0.095377  ...                    -0.691000   \n",
       "6        2.0             NaN   0.092620  ...                    -0.916000   \n",
       "7        2.0             2.0   0.131462  ...                     0.098364   \n",
       "8        1.0             1.0   0.106885  ...                    -0.820667   \n",
       "9        1.0             1.0   0.103268  ...                     0.339000   \n",
       "10       1.0             1.0   0.094107  ...                     0.382333   \n",
       "11       1.0             1.0   0.116692  ...                    -0.437000   \n",
       "12       1.0             1.0   0.104068  ...                     0.893667   \n",
       "13       1.0             1.0   0.101172  ...                    -0.883000   \n",
       "14       1.0             1.0   0.095679  ...                     0.671333   \n",
       "\n",
       "    terrorist_0_province  warlord_0_province  d'etat_0_province  \\\n",
       "0              -0.284333           -0.668667           0.647333   \n",
       "1              -1.037016           -0.811291          -0.850261   \n",
       "2               0.455000            1.595667           0.571667   \n",
       "3              -0.722159           -0.130521           0.047630   \n",
       "4              -0.694350           -1.215958          -0.865261   \n",
       "5               1.168667           -0.279333          -0.296667   \n",
       "6               0.334333           -0.847000           1.270000   \n",
       "7              -0.792159           -0.083854          -0.229370   \n",
       "8              -0.696000           -0.588667           0.714000   \n",
       "9              -0.851667            0.421000           1.312000   \n",
       "10              0.717000            0.562667           0.325667   \n",
       "11             -0.224000            0.404000           0.706000   \n",
       "12              0.169333            0.063667          -0.807333   \n",
       "13              1.068000           -0.714333           1.443000   \n",
       "14             -0.805333            0.564333           1.416000   \n",
       "\n",
       "    overthrow_0_province  convoys_0_province  carbon_0_province  \\\n",
       "0              -0.891333            0.112667           1.265333   \n",
       "1              -0.948892           -0.728972          -0.765146   \n",
       "2               0.279000           -0.868333           0.058333   \n",
       "3               0.362613            0.480986           0.026073   \n",
       "4              -1.119225           -1.060638          -0.673479   \n",
       "5               1.651333           -0.356000           1.156667   \n",
       "6               0.744333            1.328667          -0.705000   \n",
       "7               0.050279            0.181986          -0.413594   \n",
       "8               1.049667           -0.590000          -0.759667   \n",
       "9               0.010667            1.056333           1.055333   \n",
       "10             -0.527000           -0.789000          -0.174333   \n",
       "11             -0.343667           -0.690333          -0.267000   \n",
       "12             -0.633667           -0.818667           0.846667   \n",
       "13              1.471333            0.113000           1.133333   \n",
       "14              1.163000           -0.271000           1.477000   \n",
       "\n",
       "    mayhem_0_province  dehydrated_0_province  mismanagement_0_province  \n",
       "0            0.667000               0.173667                 -0.073000  \n",
       "1           -0.636580              -0.671587                 -0.510467  \n",
       "2            1.447667              -0.676000                  0.530333  \n",
       "3           -0.594877              -0.620540                 -1.011600  \n",
       "4           -0.709913              -0.787921                 -0.611133  \n",
       "5            1.202667               0.446667                  0.696667  \n",
       "6            0.738000               0.358000                  0.357667  \n",
       "7            0.278123              -0.235540                 -0.817600  \n",
       "8           -0.057000               0.993333                  1.217667  \n",
       "9            0.844000               0.652000                 -0.213000  \n",
       "10          -0.387667              -0.696333                  0.993667  \n",
       "11          -0.291333              -0.553333                  1.016667  \n",
       "12           1.122000               0.224000                  0.184000  \n",
       "13           0.344667              -0.665667                 -0.436667  \n",
       "14          -0.470333              -0.641667                  0.950000  \n",
       "\n",
       "[15 rows x 358 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gastrointestinal_0_country</th>\n",
       "      <th>terrorist_0_country</th>\n",
       "      <th>warlord_0_country</th>\n",
       "      <th>d'etat_0_country</th>\n",
       "      <th>overthrow_0_country</th>\n",
       "      <th>convoys_0_country</th>\n",
       "      <th>carbon_0_country</th>\n",
       "      <th>mayhem_0_country</th>\n",
       "      <th>dehydrated_0_country</th>\n",
       "      <th>mismanagement_0_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.192000</td>\n",
       "      <td>-0.284333</td>\n",
       "      <td>-0.668667</td>\n",
       "      <td>0.647333</td>\n",
       "      <td>-0.891333</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>1.265333</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>-0.073000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.545727</td>\n",
       "      <td>-1.037016</td>\n",
       "      <td>-0.811291</td>\n",
       "      <td>-0.850261</td>\n",
       "      <td>-0.948892</td>\n",
       "      <td>-0.728972</td>\n",
       "      <td>-0.765146</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.510467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>1.506333</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>1.595667</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>-0.868333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>0.530333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.793970</td>\n",
       "      <td>-0.722159</td>\n",
       "      <td>-0.130521</td>\n",
       "      <td>0.047630</td>\n",
       "      <td>0.362613</td>\n",
       "      <td>0.480986</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>-1.011600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.509394</td>\n",
       "      <td>-0.694350</td>\n",
       "      <td>-1.215958</td>\n",
       "      <td>-0.865261</td>\n",
       "      <td>-1.119225</td>\n",
       "      <td>-1.060638</td>\n",
       "      <td>-0.673479</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.611133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_10</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.691000</td>\n",
       "      <td>1.168667</td>\n",
       "      <td>-0.279333</td>\n",
       "      <td>-0.296667</td>\n",
       "      <td>1.651333</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>1.156667</td>\n",
       "      <td>1.202667</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.696667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_01</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.916000</td>\n",
       "      <td>0.334333</td>\n",
       "      <td>-0.847000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>1.328667</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.357667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_04</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098364</td>\n",
       "      <td>-0.792159</td>\n",
       "      <td>-0.083854</td>\n",
       "      <td>-0.229370</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.181986</td>\n",
       "      <td>-0.413594</td>\n",
       "      <td>0.278123</td>\n",
       "      <td>-0.235540</td>\n",
       "      <td>-0.817600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_07</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.820667</td>\n",
       "      <td>-0.696000</td>\n",
       "      <td>-0.588667</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>1.049667</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.057000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>1.217667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_10</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.339000</td>\n",
       "      <td>-0.851667</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>1.056333</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>-0.213000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      country  admin_code admin_name year_month  year  month  \\\n",
       "0     30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1     33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2     36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3     39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4     42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "5     45  Afghanistan         202   Kandahar    2010_10  2010     10   \n",
       "6     48  Afghanistan         202   Kandahar    2011_01  2011      1   \n",
       "7     51  Afghanistan         202   Kandahar    2011_04  2011      4   \n",
       "8     54  Afghanistan         202   Kandahar    2011_07  2011      7   \n",
       "9     57  Afghanistan         202   Kandahar    2011_10  2011     10   \n",
       "\n",
       "   fews_ipc  fews_proj_near  ndvi_mean  ...  gastrointestinal_0_country  \\\n",
       "0       1.0             NaN   0.106035  ...                   -0.192000   \n",
       "1       1.0             NaN   0.103009  ...                   -0.545727   \n",
       "2       2.0             NaN   0.109600  ...                    1.506333   \n",
       "3       2.0             NaN   0.111599  ...                   -0.793970   \n",
       "4       1.0             NaN   0.096943  ...                   -0.509394   \n",
       "5       2.0             NaN   0.095377  ...                   -0.691000   \n",
       "6       2.0             NaN   0.092620  ...                   -0.916000   \n",
       "7       2.0             2.0   0.131462  ...                    0.098364   \n",
       "8       1.0             1.0   0.106885  ...                   -0.820667   \n",
       "9       1.0             1.0   0.103268  ...                    0.339000   \n",
       "\n",
       "   terrorist_0_country  warlord_0_country  d'etat_0_country  \\\n",
       "0            -0.284333          -0.668667          0.647333   \n",
       "1            -1.037016          -0.811291         -0.850261   \n",
       "2             0.455000           1.595667          0.571667   \n",
       "3            -0.722159          -0.130521          0.047630   \n",
       "4            -0.694350          -1.215958         -0.865261   \n",
       "5             1.168667          -0.279333         -0.296667   \n",
       "6             0.334333          -0.847000          1.270000   \n",
       "7            -0.792159          -0.083854         -0.229370   \n",
       "8            -0.696000          -0.588667          0.714000   \n",
       "9            -0.851667           0.421000          1.312000   \n",
       "\n",
       "   overthrow_0_country  convoys_0_country  carbon_0_country  mayhem_0_country  \\\n",
       "0            -0.891333           0.112667          1.265333          0.667000   \n",
       "1            -0.948892          -0.728972         -0.765146         -0.636580   \n",
       "2             0.279000          -0.868333          0.058333          1.447667   \n",
       "3             0.362613           0.480986          0.026073         -0.594877   \n",
       "4            -1.119225          -1.060638         -0.673479         -0.709913   \n",
       "5             1.651333          -0.356000          1.156667          1.202667   \n",
       "6             0.744333           1.328667         -0.705000          0.738000   \n",
       "7             0.050279           0.181986         -0.413594          0.278123   \n",
       "8             1.049667          -0.590000         -0.759667         -0.057000   \n",
       "9             0.010667           1.056333          1.055333          0.844000   \n",
       "\n",
       "   dehydrated_0_country  mismanagement_0_country  \n",
       "0              0.173667                -0.073000  \n",
       "1             -0.671587                -0.510467  \n",
       "2             -0.676000                 0.530333  \n",
       "3             -0.620540                -1.011600  \n",
       "4             -0.787921                -0.611133  \n",
       "5              0.446667                 0.696667  \n",
       "6              0.358000                 0.357667  \n",
       "7             -0.235540                -0.817600  \n",
       "8              0.993333                 1.217667  \n",
       "9              0.652000                -0.213000  \n",
       "\n",
       "[10 rows x 525 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_agg_factors(news_factors, level='country')\n",
    "time_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>terrorist_0_country</th>\n",
       "      <th>warlord_0_country</th>\n",
       "      <th>d'etat_0_country</th>\n",
       "      <th>overthrow_0_country</th>\n",
       "      <th>convoys_0_country</th>\n",
       "      <th>carbon_0_country</th>\n",
       "      <th>mayhem_0_country</th>\n",
       "      <th>dehydrated_0_country</th>\n",
       "      <th>mismanagement_0_country</th>\n",
       "      <th>rain_mean_province</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284333</td>\n",
       "      <td>-0.668667</td>\n",
       "      <td>0.647333</td>\n",
       "      <td>-0.891333</td>\n",
       "      <td>0.112667</td>\n",
       "      <td>1.265333</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>0.353588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.037016</td>\n",
       "      <td>-0.811291</td>\n",
       "      <td>-0.850261</td>\n",
       "      <td>-0.948892</td>\n",
       "      <td>-0.728972</td>\n",
       "      <td>-0.765146</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>0.409304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455000</td>\n",
       "      <td>1.595667</td>\n",
       "      <td>0.571667</td>\n",
       "      <td>0.279000</td>\n",
       "      <td>-0.868333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>3.894158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.722159</td>\n",
       "      <td>-0.130521</td>\n",
       "      <td>0.047630</td>\n",
       "      <td>0.362613</td>\n",
       "      <td>0.480986</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>1.609664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.694350</td>\n",
       "      <td>-1.215958</td>\n",
       "      <td>-0.865261</td>\n",
       "      <td>-1.119225</td>\n",
       "      <td>-1.060638</td>\n",
       "      <td>-0.673479</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>0.393834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_10</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095377</td>\n",
       "      <td>...</td>\n",
       "      <td>1.168667</td>\n",
       "      <td>-0.279333</td>\n",
       "      <td>-0.296667</td>\n",
       "      <td>1.651333</td>\n",
       "      <td>-0.356000</td>\n",
       "      <td>1.156667</td>\n",
       "      <td>1.202667</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.625036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_01</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.334333</td>\n",
       "      <td>-0.847000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>1.328667</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.357667</td>\n",
       "      <td>3.142909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_04</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.792159</td>\n",
       "      <td>-0.083854</td>\n",
       "      <td>-0.229370</td>\n",
       "      <td>0.050279</td>\n",
       "      <td>0.181986</td>\n",
       "      <td>-0.413594</td>\n",
       "      <td>0.278123</td>\n",
       "      <td>-0.235540</td>\n",
       "      <td>-0.817600</td>\n",
       "      <td>4.219678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_07</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.696000</td>\n",
       "      <td>-0.588667</td>\n",
       "      <td>0.714000</td>\n",
       "      <td>1.049667</td>\n",
       "      <td>-0.590000</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.057000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>1.217667</td>\n",
       "      <td>0.367243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_10</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.851667</td>\n",
       "      <td>0.421000</td>\n",
       "      <td>1.312000</td>\n",
       "      <td>0.010667</td>\n",
       "      <td>1.056333</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.848252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>0.562667</td>\n",
       "      <td>0.325667</td>\n",
       "      <td>-0.527000</td>\n",
       "      <td>-0.789000</td>\n",
       "      <td>-0.174333</td>\n",
       "      <td>-0.387667</td>\n",
       "      <td>-0.696333</td>\n",
       "      <td>0.993667</td>\n",
       "      <td>6.606683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_04</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224000</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.706000</td>\n",
       "      <td>-0.343667</td>\n",
       "      <td>-0.690333</td>\n",
       "      <td>-0.267000</td>\n",
       "      <td>-0.291333</td>\n",
       "      <td>-0.553333</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>2.908423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_07</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169333</td>\n",
       "      <td>0.063667</td>\n",
       "      <td>-0.807333</td>\n",
       "      <td>-0.633667</td>\n",
       "      <td>-0.818667</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>1.122000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.363717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_10</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.068000</td>\n",
       "      <td>-0.714333</td>\n",
       "      <td>1.443000</td>\n",
       "      <td>1.471333</td>\n",
       "      <td>0.113000</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.344667</td>\n",
       "      <td>-0.665667</td>\n",
       "      <td>-0.436667</td>\n",
       "      <td>0.452095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2013_01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.805333</td>\n",
       "      <td>0.564333</td>\n",
       "      <td>1.416000</td>\n",
       "      <td>1.163000</td>\n",
       "      <td>-0.271000</td>\n",
       "      <td>1.477000</td>\n",
       "      <td>-0.470333</td>\n",
       "      <td>-0.641667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.836539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 526 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      country  admin_code admin_name year_month  year  month  \\\n",
       "0      30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1      33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2      36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3      39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4      42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "5      45  Afghanistan         202   Kandahar    2010_10  2010     10   \n",
       "6      48  Afghanistan         202   Kandahar    2011_01  2011      1   \n",
       "7      51  Afghanistan         202   Kandahar    2011_04  2011      4   \n",
       "8      54  Afghanistan         202   Kandahar    2011_07  2011      7   \n",
       "9      57  Afghanistan         202   Kandahar    2011_10  2011     10   \n",
       "10     60  Afghanistan         202   Kandahar    2012_01  2012      1   \n",
       "11     63  Afghanistan         202   Kandahar    2012_04  2012      4   \n",
       "12     66  Afghanistan         202   Kandahar    2012_07  2012      7   \n",
       "13     69  Afghanistan         202   Kandahar    2012_10  2012     10   \n",
       "14     72  Afghanistan         202   Kandahar    2013_01  2013      1   \n",
       "\n",
       "    fews_ipc  fews_proj_near  ndvi_mean  ...  terrorist_0_country  \\\n",
       "0        1.0             NaN   0.106035  ...            -0.284333   \n",
       "1        1.0             NaN   0.103009  ...            -1.037016   \n",
       "2        2.0             NaN   0.109600  ...             0.455000   \n",
       "3        2.0             NaN   0.111599  ...            -0.722159   \n",
       "4        1.0             NaN   0.096943  ...            -0.694350   \n",
       "5        2.0             NaN   0.095377  ...             1.168667   \n",
       "6        2.0             NaN   0.092620  ...             0.334333   \n",
       "7        2.0             2.0   0.131462  ...            -0.792159   \n",
       "8        1.0             1.0   0.106885  ...            -0.696000   \n",
       "9        1.0             1.0   0.103268  ...            -0.851667   \n",
       "10       1.0             1.0   0.094107  ...             0.717000   \n",
       "11       1.0             1.0   0.116692  ...            -0.224000   \n",
       "12       1.0             1.0   0.104068  ...             0.169333   \n",
       "13       1.0             1.0   0.101172  ...             1.068000   \n",
       "14       1.0             1.0   0.095679  ...            -0.805333   \n",
       "\n",
       "    warlord_0_country  d'etat_0_country  overthrow_0_country  \\\n",
       "0           -0.668667          0.647333            -0.891333   \n",
       "1           -0.811291         -0.850261            -0.948892   \n",
       "2            1.595667          0.571667             0.279000   \n",
       "3           -0.130521          0.047630             0.362613   \n",
       "4           -1.215958         -0.865261            -1.119225   \n",
       "5           -0.279333         -0.296667             1.651333   \n",
       "6           -0.847000          1.270000             0.744333   \n",
       "7           -0.083854         -0.229370             0.050279   \n",
       "8           -0.588667          0.714000             1.049667   \n",
       "9            0.421000          1.312000             0.010667   \n",
       "10           0.562667          0.325667            -0.527000   \n",
       "11           0.404000          0.706000            -0.343667   \n",
       "12           0.063667         -0.807333            -0.633667   \n",
       "13          -0.714333          1.443000             1.471333   \n",
       "14           0.564333          1.416000             1.163000   \n",
       "\n",
       "    convoys_0_country  carbon_0_country  mayhem_0_country  \\\n",
       "0            0.112667          1.265333          0.667000   \n",
       "1           -0.728972         -0.765146         -0.636580   \n",
       "2           -0.868333          0.058333          1.447667   \n",
       "3            0.480986          0.026073         -0.594877   \n",
       "4           -1.060638         -0.673479         -0.709913   \n",
       "5           -0.356000          1.156667          1.202667   \n",
       "6            1.328667         -0.705000          0.738000   \n",
       "7            0.181986         -0.413594          0.278123   \n",
       "8           -0.590000         -0.759667         -0.057000   \n",
       "9            1.056333          1.055333          0.844000   \n",
       "10          -0.789000         -0.174333         -0.387667   \n",
       "11          -0.690333         -0.267000         -0.291333   \n",
       "12          -0.818667          0.846667          1.122000   \n",
       "13           0.113000          1.133333          0.344667   \n",
       "14          -0.271000          1.477000         -0.470333   \n",
       "\n",
       "    dehydrated_0_country  mismanagement_0_country  rain_mean_province  \n",
       "0               0.173667                -0.073000            0.353588  \n",
       "1              -0.671587                -0.510467            0.409304  \n",
       "2              -0.676000                 0.530333            3.894158  \n",
       "3              -0.620540                -1.011600            1.609664  \n",
       "4              -0.787921                -0.611133            0.393834  \n",
       "5               0.446667                 0.696667            0.625036  \n",
       "6               0.358000                 0.357667            3.142909  \n",
       "7              -0.235540                -0.817600            4.219678  \n",
       "8               0.993333                 1.217667            0.367243  \n",
       "9               0.652000                -0.213000            0.848252  \n",
       "10             -0.696333                 0.993667            6.606683  \n",
       "11             -0.553333                 1.016667            2.908423  \n",
       "12              0.224000                 0.184000            0.363717  \n",
       "13             -0.665667                -0.436667            0.452095  \n",
       "14             -0.641667                 0.950000            2.836539  \n",
       "\n",
       "[15 rows x 526 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_agg_factors(t_variant_traditional_factors, level='province')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon_0_country</th>\n",
       "      <th>mayhem_0_country</th>\n",
       "      <th>dehydrated_0_country</th>\n",
       "      <th>mismanagement_0_country</th>\n",
       "      <th>rain_mean_province</th>\n",
       "      <th>rain_mean_country</th>\n",
       "      <th>area_province</th>\n",
       "      <th>pasture_pct_province</th>\n",
       "      <th>area_country</th>\n",
       "      <th>pasture_pct_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>1.265333</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>0.353588</td>\n",
       "      <td>0.353588</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.765146</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>0.409304</td>\n",
       "      <td>0.409304</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>3.894158</td>\n",
       "      <td>3.894158</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026073</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>1.609664</td>\n",
       "      <td>1.609664</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.673479</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>0.393834</td>\n",
       "      <td>0.393834</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_10</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095377</td>\n",
       "      <td>...</td>\n",
       "      <td>1.156667</td>\n",
       "      <td>1.202667</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.696667</td>\n",
       "      <td>0.625036</td>\n",
       "      <td>0.625036</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_01</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.705000</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.357667</td>\n",
       "      <td>3.142909</td>\n",
       "      <td>3.142909</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_04</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.413594</td>\n",
       "      <td>0.278123</td>\n",
       "      <td>-0.235540</td>\n",
       "      <td>-0.817600</td>\n",
       "      <td>4.219678</td>\n",
       "      <td>4.219678</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_07</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.759667</td>\n",
       "      <td>-0.057000</td>\n",
       "      <td>0.993333</td>\n",
       "      <td>1.217667</td>\n",
       "      <td>0.367243</td>\n",
       "      <td>0.367243</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_10</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>...</td>\n",
       "      <td>1.055333</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>-0.213000</td>\n",
       "      <td>0.848252</td>\n",
       "      <td>0.848252</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>60</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_01</td>\n",
       "      <td>2012</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.094107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.174333</td>\n",
       "      <td>-0.387667</td>\n",
       "      <td>-0.696333</td>\n",
       "      <td>0.993667</td>\n",
       "      <td>6.606683</td>\n",
       "      <td>6.606683</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>63</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_04</td>\n",
       "      <td>2012</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.116692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.267000</td>\n",
       "      <td>-0.291333</td>\n",
       "      <td>-0.553333</td>\n",
       "      <td>1.016667</td>\n",
       "      <td>2.908423</td>\n",
       "      <td>2.908423</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>66</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_07</td>\n",
       "      <td>2012</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.104068</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>1.122000</td>\n",
       "      <td>0.224000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.363717</td>\n",
       "      <td>0.363717</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>69</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2012_10</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.101172</td>\n",
       "      <td>...</td>\n",
       "      <td>1.133333</td>\n",
       "      <td>0.344667</td>\n",
       "      <td>-0.665667</td>\n",
       "      <td>-0.436667</td>\n",
       "      <td>0.452095</td>\n",
       "      <td>0.452095</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>72</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2013_01</td>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.095679</td>\n",
       "      <td>...</td>\n",
       "      <td>1.477000</td>\n",
       "      <td>-0.470333</td>\n",
       "      <td>-0.641667</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2.836539</td>\n",
       "      <td>2.836539</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "      <td>54174.53381</td>\n",
       "      <td>16.246279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15 rows × 531 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index      country  admin_code admin_name year_month  year  month  \\\n",
       "0      30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1      33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2      36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3      39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4      42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "5      45  Afghanistan         202   Kandahar    2010_10  2010     10   \n",
       "6      48  Afghanistan         202   Kandahar    2011_01  2011      1   \n",
       "7      51  Afghanistan         202   Kandahar    2011_04  2011      4   \n",
       "8      54  Afghanistan         202   Kandahar    2011_07  2011      7   \n",
       "9      57  Afghanistan         202   Kandahar    2011_10  2011     10   \n",
       "10     60  Afghanistan         202   Kandahar    2012_01  2012      1   \n",
       "11     63  Afghanistan         202   Kandahar    2012_04  2012      4   \n",
       "12     66  Afghanistan         202   Kandahar    2012_07  2012      7   \n",
       "13     69  Afghanistan         202   Kandahar    2012_10  2012     10   \n",
       "14     72  Afghanistan         202   Kandahar    2013_01  2013      1   \n",
       "\n",
       "    fews_ipc  fews_proj_near  ndvi_mean  ...  carbon_0_country  \\\n",
       "0        1.0             NaN   0.106035  ...          1.265333   \n",
       "1        1.0             NaN   0.103009  ...         -0.765146   \n",
       "2        2.0             NaN   0.109600  ...          0.058333   \n",
       "3        2.0             NaN   0.111599  ...          0.026073   \n",
       "4        1.0             NaN   0.096943  ...         -0.673479   \n",
       "5        2.0             NaN   0.095377  ...          1.156667   \n",
       "6        2.0             NaN   0.092620  ...         -0.705000   \n",
       "7        2.0             2.0   0.131462  ...         -0.413594   \n",
       "8        1.0             1.0   0.106885  ...         -0.759667   \n",
       "9        1.0             1.0   0.103268  ...          1.055333   \n",
       "10       1.0             1.0   0.094107  ...         -0.174333   \n",
       "11       1.0             1.0   0.116692  ...         -0.267000   \n",
       "12       1.0             1.0   0.104068  ...          0.846667   \n",
       "13       1.0             1.0   0.101172  ...          1.133333   \n",
       "14       1.0             1.0   0.095679  ...          1.477000   \n",
       "\n",
       "    mayhem_0_country  dehydrated_0_country  mismanagement_0_country  \\\n",
       "0           0.667000              0.173667                -0.073000   \n",
       "1          -0.636580             -0.671587                -0.510467   \n",
       "2           1.447667             -0.676000                 0.530333   \n",
       "3          -0.594877             -0.620540                -1.011600   \n",
       "4          -0.709913             -0.787921                -0.611133   \n",
       "5           1.202667              0.446667                 0.696667   \n",
       "6           0.738000              0.358000                 0.357667   \n",
       "7           0.278123             -0.235540                -0.817600   \n",
       "8          -0.057000              0.993333                 1.217667   \n",
       "9           0.844000              0.652000                -0.213000   \n",
       "10         -0.387667             -0.696333                 0.993667   \n",
       "11         -0.291333             -0.553333                 1.016667   \n",
       "12          1.122000              0.224000                 0.184000   \n",
       "13          0.344667             -0.665667                -0.436667   \n",
       "14         -0.470333             -0.641667                 0.950000   \n",
       "\n",
       "    rain_mean_province  rain_mean_country  area_province  \\\n",
       "0             0.353588           0.353588    54174.53381   \n",
       "1             0.409304           0.409304    54174.53381   \n",
       "2             3.894158           3.894158    54174.53381   \n",
       "3             1.609664           1.609664    54174.53381   \n",
       "4             0.393834           0.393834    54174.53381   \n",
       "5             0.625036           0.625036    54174.53381   \n",
       "6             3.142909           3.142909    54174.53381   \n",
       "7             4.219678           4.219678    54174.53381   \n",
       "8             0.367243           0.367243    54174.53381   \n",
       "9             0.848252           0.848252    54174.53381   \n",
       "10            6.606683           6.606683    54174.53381   \n",
       "11            2.908423           2.908423    54174.53381   \n",
       "12            0.363717           0.363717    54174.53381   \n",
       "13            0.452095           0.452095    54174.53381   \n",
       "14            2.836539           2.836539    54174.53381   \n",
       "\n",
       "    pasture_pct_province  area_country  pasture_pct_country  \n",
       "0              16.246279   54174.53381            16.246279  \n",
       "1              16.246279   54174.53381            16.246279  \n",
       "2              16.246279   54174.53381            16.246279  \n",
       "3              16.246279   54174.53381            16.246279  \n",
       "4              16.246279   54174.53381            16.246279  \n",
       "5              16.246279   54174.53381            16.246279  \n",
       "6              16.246279   54174.53381            16.246279  \n",
       "7              16.246279   54174.53381            16.246279  \n",
       "8              16.246279   54174.53381            16.246279  \n",
       "9              16.246279   54174.53381            16.246279  \n",
       "10             16.246279   54174.53381            16.246279  \n",
       "11             16.246279   54174.53381            16.246279  \n",
       "12             16.246279   54174.53381            16.246279  \n",
       "13             16.246279   54174.53381            16.246279  \n",
       "14             16.246279   54174.53381            16.246279  \n",
       "\n",
       "[15 rows x 531 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_agg_factors(t_variant_traditional_factors, level='country')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_csv('agg_province_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time lagged features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(t_variant_traditional_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "time_series = add_time_lagged(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "time_series = add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/2950079185.py:43: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series[lagged_col] = [get_lagged(row, f_s, t, ts_dict) for _, row in time_series.iterrows()]\n"
     ]
    }
   ],
   "source": [
    "time_series = add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3562,)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_csv(\"our_results2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mismanagement_0_country_6</th>\n",
       "      <th>mismanagement_0_country_7</th>\n",
       "      <th>mismanagement_0_country_8</th>\n",
       "      <th>fews_ipc_3</th>\n",
       "      <th>fews_ipc_6</th>\n",
       "      <th>fews_ipc_9</th>\n",
       "      <th>fews_ipc_12</th>\n",
       "      <th>fews_ipc_15</th>\n",
       "      <th>fews_ipc_18</th>\n",
       "      <th>fews_proj_near_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      country  admin_code admin_name year_month  year  month  \\\n",
       "0     30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1     33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2     36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3     39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4     42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "\n",
       "   fews_ipc  fews_proj_near  ndvi_mean  ...  mismanagement_0_country_6  \\\n",
       "0       1.0             NaN   0.106035  ...                  -0.073000   \n",
       "1       1.0             NaN   0.103009  ...                  -0.510467   \n",
       "2       2.0             NaN   0.109600  ...                   0.530333   \n",
       "3       2.0             NaN   0.111599  ...                  -1.011600   \n",
       "4       1.0             NaN   0.096943  ...                  -0.611133   \n",
       "\n",
       "   mismanagement_0_country_7  mismanagement_0_country_8  fews_ipc_3  \\\n",
       "0                  -0.073000                  -0.073000         1.0   \n",
       "1                  -0.510467                  -0.510467         1.0   \n",
       "2                   0.530333                   0.530333         1.0   \n",
       "3                  -1.011600                  -1.011600         2.0   \n",
       "4                  -0.611133                  -0.611133         1.0   \n",
       "\n",
       "   fews_ipc_6  fews_ipc_9  fews_ipc_12  fews_ipc_15  fews_ipc_18  \\\n",
       "0         1.0         1.0          1.0          1.0          1.0   \n",
       "1         1.0         1.0          1.0          1.0          1.0   \n",
       "2         2.0         2.0          2.0          1.0          2.0   \n",
       "3         1.0         2.0          2.0          2.0          1.0   \n",
       "4         1.0         1.0          1.0          1.0          1.0   \n",
       "\n",
       "   fews_proj_near_3  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 3562 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country',\n",
       " 'admin_code',\n",
       " 'acled_count',\n",
       " 'continued deterioration_0',\n",
       " 'economic impoverishment_0',\n",
       " 'conflict_0',\n",
       " 'collapsing economy_0',\n",
       " 'corrupt government_0',\n",
       " 'continued strife_0',\n",
       " 'ecological crisis_0',\n",
       " 'coup_0',\n",
       " 'economic crisis_0',\n",
       " 'corruption_0',\n",
       " 'collapse of government_0',\n",
       " 'devastated the economy_0',\n",
       " 'convoys_0',\n",
       " 'continued deterioration_0_province',\n",
       " 'economic impoverishment_0_province',\n",
       " 'conflict_0_province',\n",
       " 'collapsing economy_0_province',\n",
       " 'corrupt government_0_province',\n",
       " 'continued strife_0_province',\n",
       " 'ecological crisis_0_province',\n",
       " 'coup_0_province',\n",
       " 'economic crisis_0_province',\n",
       " 'corruption_0_province',\n",
       " 'collapse of government_0_province',\n",
       " 'devastated the economy_0_province',\n",
       " 'convoys_0_province',\n",
       " 'land seizures_0_country',\n",
       " 'slashed export_0_country',\n",
       " 'price rise_0_country',\n",
       " 'mass hunger_0_country',\n",
       " 'cyclone_0_country',\n",
       " 'failed crops_0_country',\n",
       " 'disruption to farming_0_country',\n",
       " 'massive starvation_0_country',\n",
       " 'abnormally low rainfall_0_country',\n",
       " 'withheld relief_0_country',\n",
       " 'international alarm_0_country',\n",
       " 'reduced national output_0_country',\n",
       " 'oppressive regimes_0_country',\n",
       " 'pests_0_country',\n",
       " 'continued deterioration_0_country',\n",
       " 'forests destroyed_0_country',\n",
       " 'man-made disaster_0_country',\n",
       " 'food insecurity_0_country',\n",
       " 'harvests are devastated_0_country',\n",
       " 'humanitarian situation_0_country',\n",
       " 'economic impoverishment_0_country',\n",
       " 'clan battle_0_country',\n",
       " 'population crisis_0_country',\n",
       " 'aid appeal_0_country',\n",
       " 'weather extremes_0_country',\n",
       " 'anti-western policies_0_country',\n",
       " 'rinderpest_0_country',\n",
       " 'inadequate rainfall_0_country',\n",
       " 'lack of authority_0_country',\n",
       " 'acute hunger_0_country',\n",
       " 'foreign troops_0_country',\n",
       " 'increased external debt_0_country',\n",
       " 'drought_0_country',\n",
       " 'conflict_0_country',\n",
       " 'failed rains_0_country',\n",
       " 'makeshift camps_0_country',\n",
       " 'civilians uprooted_0_country',\n",
       " 'dysfunction_0_country',\n",
       " 'foreign aid_0_country',\n",
       " 'violent suppression_0_country',\n",
       " 'military dictatorship_0_country',\n",
       " 'climatic hazards_0_country',\n",
       " 'migration_0_country',\n",
       " 'land grab_0_country',\n",
       " 'terrorism_0_country',\n",
       " 'bombing campaign_0_country',\n",
       " 'collapsing economy_0_country',\n",
       " 'military junta_0_country',\n",
       " 'climate change_0_country',\n",
       " 'rising inflation_0_country',\n",
       " 'international terrorists_0_country',\n",
       " 'cycle of poverty_0_country',\n",
       " 'bad harvests_0_country',\n",
       " 'destructive pattern_0_country',\n",
       " 'price of food_0_country',\n",
       " 'corrupt government_0_country',\n",
       " 'militia groups_0_country',\n",
       " 'poor soil quality_0_country',\n",
       " 'cattle plague_0_country',\n",
       " 'food assistance_0_country',\n",
       " 'continued strife_0_country',\n",
       " 'ecological crisis_0_country',\n",
       " 'hunger crises_0_country',\n",
       " 'rising food prices_0_country',\n",
       " 'restricted humanitarian access_0_country',\n",
       " 'water availability_0_country',\n",
       " 'alarming level_0_country',\n",
       " 'police torture_0_country',\n",
       " 'potato blight_0_country',\n",
       " 'the offensive_0_country',\n",
       " 'land invasions_0_country',\n",
       " 'clan warfare_0_country',\n",
       " 'stolen food aid_0_country',\n",
       " 'politically engineered_0_country',\n",
       " 'scanty rainfall_0_country',\n",
       " 'water distribution shortages_0_country',\n",
       " 'cattle death_0_country',\n",
       " 'asylum seekers_0_country',\n",
       " 'major offensive_0_country',\n",
       " 'without international aid_0_country',\n",
       " 'prolonged dry spell_0_country',\n",
       " 'rise_0_country',\n",
       " 'restricted relief flights_0_country',\n",
       " 'civil strife_0_country',\n",
       " 'aid workers died_0_country',\n",
       " 'rival warlords_0_country',\n",
       " 'land reform_0_country',\n",
       " 'lack of roads_0_country',\n",
       " 'pushing peasants off_0_country',\n",
       " 'locusts_0_country',\n",
       " 'gangs of bandits_0_country',\n",
       " 'repression_0_country',\n",
       " 'humanitarian disaster_0_country',\n",
       " 'years of warfare_0_country',\n",
       " 'floods_0_country',\n",
       " 'unable to sow_0_country',\n",
       " 'transport bottleneck_0_country',\n",
       " 'pirates_0_country',\n",
       " 'reduced imports_0_country',\n",
       " 'apathy_0_country',\n",
       " 'coup_0_country',\n",
       " 'epidemics_0_country',\n",
       " 'siege_0_country',\n",
       " 'power struggle_0_country',\n",
       " 'livestock had died_0_country',\n",
       " 'blockade_0_country',\n",
       " 'burning houses_0_country',\n",
       " 'brain drain_0_country',\n",
       " 'severe rains_0_country',\n",
       " 'infrastructure damage_0_country',\n",
       " 'land degradation_0_country',\n",
       " 'human rights abuses_0_country',\n",
       " 'lack of cultivation_0_country',\n",
       " 'harvest decline_0_country',\n",
       " 'flee_0_country',\n",
       " 'economic crisis_0_country',\n",
       " 'greenhouse gases_0_country',\n",
       " 'prolonged fighting_0_country',\n",
       " 'tragedy_0_country',\n",
       " 'slave trade_0_country',\n",
       " 'environmental degradation_0_country',\n",
       " 'infant mortality_0_country',\n",
       " 'catastrophe_0_country',\n",
       " 'wreaked havoc_0_country',\n",
       " 'internal strife_0_country',\n",
       " 'malnourished_0_country',\n",
       " 'secession_0_country',\n",
       " 'natural disaster_0_country',\n",
       " 'life-threatening hunger_0_country',\n",
       " 'air attack_0_country',\n",
       " 'corruption_0_country',\n",
       " 'call for donations_0_country',\n",
       " 'collapse of government_0_country',\n",
       " 'international intervention_0_country',\n",
       " 'refugees_0_country',\n",
       " 'disrupted trade_0_country',\n",
       " 'lack of agricultural infrastructure_0_country',\n",
       " 'rebel insurgency_0_country',\n",
       " 'brutal government_0_country',\n",
       " 'looting_0_country',\n",
       " 'displaced_0_country',\n",
       " 'food crisis_0_country',\n",
       " 'lack of rains_0_country',\n",
       " 'lack of alternatives_0_country',\n",
       " 'regimes were toppled_0_country',\n",
       " 'jihadist groups_0_country',\n",
       " 'toll on livestock_0_country',\n",
       " 'shortage of rains_0_country',\n",
       " 'devastated the economy_0_country',\n",
       " 'self reliance_0_country',\n",
       " 'cholera outbreak_0_country',\n",
       " 'international embargo_0_country',\n",
       " 'farmland_0_country',\n",
       " 'totalitarian_0_country',\n",
       " 'authoritarian_0_country',\n",
       " 'dictators_0_country',\n",
       " 'clans_0_country',\n",
       " 'gastrointestinal_0_country',\n",
       " 'terrorist_0_country',\n",
       " 'warlord_0_country',\n",
       " \"d'etat_0_country\",\n",
       " 'overthrow_0_country',\n",
       " 'convoys_0_country',\n",
       " 'carbon_0_country',\n",
       " 'mayhem_0_country',\n",
       " 'dehydrated_0_country',\n",
       " 'mismanagement_0_country',\n",
       " 'rain_mean_country',\n",
       " 'area_country',\n",
       " 'pasture_pct_country',\n",
       " 'rain_mean_country_3',\n",
       " 'rain_mean_country_4',\n",
       " 'rain_mean_country_5',\n",
       " 'rain_mean_country_6',\n",
       " 'rain_mean_country_7',\n",
       " 'rain_mean_country_8',\n",
       " 'continued deterioration_0_3',\n",
       " 'continued deterioration_0_4',\n",
       " 'continued deterioration_0_5',\n",
       " 'continued deterioration_0_6',\n",
       " 'continued deterioration_0_7',\n",
       " 'continued deterioration_0_8',\n",
       " 'economic impoverishment_0_3',\n",
       " 'economic impoverishment_0_4',\n",
       " 'economic impoverishment_0_5',\n",
       " 'economic impoverishment_0_6',\n",
       " 'economic impoverishment_0_7',\n",
       " 'economic impoverishment_0_8',\n",
       " 'conflict_0_3',\n",
       " 'conflict_0_4',\n",
       " 'conflict_0_5',\n",
       " 'conflict_0_6',\n",
       " 'conflict_0_7',\n",
       " 'conflict_0_8',\n",
       " 'collapsing economy_0_3',\n",
       " 'collapsing economy_0_4',\n",
       " 'collapsing economy_0_5',\n",
       " 'collapsing economy_0_6',\n",
       " 'collapsing economy_0_7',\n",
       " 'collapsing economy_0_8',\n",
       " 'corrupt government_0_3',\n",
       " 'corrupt government_0_4',\n",
       " 'corrupt government_0_5',\n",
       " 'corrupt government_0_6',\n",
       " 'corrupt government_0_7',\n",
       " 'corrupt government_0_8',\n",
       " 'continued strife_0_3',\n",
       " 'continued strife_0_4',\n",
       " 'continued strife_0_5',\n",
       " 'continued strife_0_6',\n",
       " 'continued strife_0_7',\n",
       " 'continued strife_0_8',\n",
       " 'ecological crisis_0_3',\n",
       " 'ecological crisis_0_4',\n",
       " 'ecological crisis_0_5',\n",
       " 'ecological crisis_0_6',\n",
       " 'ecological crisis_0_7',\n",
       " 'ecological crisis_0_8',\n",
       " 'coup_0_3',\n",
       " 'coup_0_4',\n",
       " 'coup_0_5',\n",
       " 'coup_0_6',\n",
       " 'coup_0_7',\n",
       " 'coup_0_8',\n",
       " 'economic crisis_0_3',\n",
       " 'economic crisis_0_4',\n",
       " 'economic crisis_0_5',\n",
       " 'economic crisis_0_6',\n",
       " 'economic crisis_0_7',\n",
       " 'economic crisis_0_8',\n",
       " 'corruption_0_3',\n",
       " 'corruption_0_4',\n",
       " 'corruption_0_5',\n",
       " 'corruption_0_6',\n",
       " 'corruption_0_7',\n",
       " 'corruption_0_8',\n",
       " 'collapse of government_0_3',\n",
       " 'collapse of government_0_4',\n",
       " 'collapse of government_0_5',\n",
       " 'collapse of government_0_6',\n",
       " 'collapse of government_0_7',\n",
       " 'collapse of government_0_8',\n",
       " 'devastated the economy_0_3',\n",
       " 'devastated the economy_0_4',\n",
       " 'devastated the economy_0_5',\n",
       " 'devastated the economy_0_6',\n",
       " 'devastated the economy_0_7',\n",
       " 'devastated the economy_0_8',\n",
       " 'convoys_0_3',\n",
       " 'convoys_0_4',\n",
       " 'convoys_0_5',\n",
       " 'convoys_0_6',\n",
       " 'convoys_0_7',\n",
       " 'convoys_0_8',\n",
       " 'continued deterioration_0_province_3',\n",
       " 'continued deterioration_0_province_4',\n",
       " 'continued deterioration_0_province_5',\n",
       " 'continued deterioration_0_province_6',\n",
       " 'continued deterioration_0_province_7',\n",
       " 'continued deterioration_0_province_8',\n",
       " 'economic impoverishment_0_province_3',\n",
       " 'economic impoverishment_0_province_4',\n",
       " 'economic impoverishment_0_province_5',\n",
       " 'economic impoverishment_0_province_6',\n",
       " 'economic impoverishment_0_province_7',\n",
       " 'economic impoverishment_0_province_8',\n",
       " 'conflict_0_province_3',\n",
       " 'conflict_0_province_4',\n",
       " 'conflict_0_province_5',\n",
       " 'conflict_0_province_6',\n",
       " 'conflict_0_province_7',\n",
       " 'conflict_0_province_8',\n",
       " 'collapsing economy_0_province_3',\n",
       " 'collapsing economy_0_province_4',\n",
       " 'collapsing economy_0_province_5',\n",
       " 'collapsing economy_0_province_6',\n",
       " 'collapsing economy_0_province_7',\n",
       " 'collapsing economy_0_province_8',\n",
       " 'corrupt government_0_province_3',\n",
       " 'corrupt government_0_province_4',\n",
       " 'corrupt government_0_province_5',\n",
       " 'corrupt government_0_province_6',\n",
       " 'corrupt government_0_province_7',\n",
       " 'corrupt government_0_province_8',\n",
       " 'continued strife_0_province_3',\n",
       " 'continued strife_0_province_4',\n",
       " 'continued strife_0_province_5',\n",
       " 'continued strife_0_province_6',\n",
       " 'continued strife_0_province_7',\n",
       " 'continued strife_0_province_8',\n",
       " 'ecological crisis_0_province_3',\n",
       " 'ecological crisis_0_province_4',\n",
       " 'ecological crisis_0_province_5',\n",
       " 'ecological crisis_0_province_6',\n",
       " 'ecological crisis_0_province_7',\n",
       " 'ecological crisis_0_province_8',\n",
       " 'coup_0_province_3',\n",
       " 'coup_0_province_4',\n",
       " 'coup_0_province_5',\n",
       " 'coup_0_province_6',\n",
       " 'coup_0_province_7',\n",
       " 'coup_0_province_8',\n",
       " 'economic crisis_0_province_3',\n",
       " 'economic crisis_0_province_4',\n",
       " 'economic crisis_0_province_5',\n",
       " 'economic crisis_0_province_6',\n",
       " 'economic crisis_0_province_7',\n",
       " 'economic crisis_0_province_8',\n",
       " 'corruption_0_province_3',\n",
       " 'corruption_0_province_4',\n",
       " 'corruption_0_province_5',\n",
       " 'corruption_0_province_6',\n",
       " 'corruption_0_province_7',\n",
       " 'corruption_0_province_8',\n",
       " 'collapse of government_0_province_3',\n",
       " 'collapse of government_0_province_4',\n",
       " 'collapse of government_0_province_5',\n",
       " 'collapse of government_0_province_6',\n",
       " 'collapse of government_0_province_7',\n",
       " 'collapse of government_0_province_8',\n",
       " 'devastated the economy_0_province_3',\n",
       " 'devastated the economy_0_province_4',\n",
       " 'devastated the economy_0_province_5',\n",
       " 'devastated the economy_0_province_6',\n",
       " 'devastated the economy_0_province_7',\n",
       " 'devastated the economy_0_province_8',\n",
       " 'convoys_0_province_3',\n",
       " 'convoys_0_province_4',\n",
       " 'convoys_0_province_5',\n",
       " 'convoys_0_province_6',\n",
       " 'convoys_0_province_7',\n",
       " 'convoys_0_province_8',\n",
       " 'land seizures_0_country_3',\n",
       " 'land seizures_0_country_4',\n",
       " 'land seizures_0_country_5',\n",
       " 'land seizures_0_country_6',\n",
       " 'land seizures_0_country_7',\n",
       " 'land seizures_0_country_8',\n",
       " 'slashed export_0_country_3',\n",
       " 'slashed export_0_country_4',\n",
       " 'slashed export_0_country_5',\n",
       " 'slashed export_0_country_6',\n",
       " 'slashed export_0_country_7',\n",
       " 'slashed export_0_country_8',\n",
       " 'price rise_0_country_3',\n",
       " 'price rise_0_country_4',\n",
       " 'price rise_0_country_5',\n",
       " 'price rise_0_country_6',\n",
       " 'price rise_0_country_7',\n",
       " 'price rise_0_country_8',\n",
       " 'mass hunger_0_country_3',\n",
       " 'mass hunger_0_country_4',\n",
       " 'mass hunger_0_country_5',\n",
       " 'mass hunger_0_country_6',\n",
       " 'mass hunger_0_country_7',\n",
       " 'mass hunger_0_country_8',\n",
       " 'cyclone_0_country_3',\n",
       " 'cyclone_0_country_4',\n",
       " 'cyclone_0_country_5',\n",
       " 'cyclone_0_country_6',\n",
       " 'cyclone_0_country_7',\n",
       " 'cyclone_0_country_8',\n",
       " 'failed crops_0_country_3',\n",
       " 'failed crops_0_country_4',\n",
       " 'failed crops_0_country_5',\n",
       " 'failed crops_0_country_6',\n",
       " 'failed crops_0_country_7',\n",
       " 'failed crops_0_country_8',\n",
       " 'disruption to farming_0_country_3',\n",
       " 'disruption to farming_0_country_4',\n",
       " 'disruption to farming_0_country_5',\n",
       " 'disruption to farming_0_country_6',\n",
       " 'disruption to farming_0_country_7',\n",
       " 'disruption to farming_0_country_8',\n",
       " 'massive starvation_0_country_3',\n",
       " 'massive starvation_0_country_4',\n",
       " 'massive starvation_0_country_5',\n",
       " 'massive starvation_0_country_6',\n",
       " 'massive starvation_0_country_7',\n",
       " 'massive starvation_0_country_8',\n",
       " 'abnormally low rainfall_0_country_3',\n",
       " 'abnormally low rainfall_0_country_4',\n",
       " 'abnormally low rainfall_0_country_5',\n",
       " 'abnormally low rainfall_0_country_6',\n",
       " 'abnormally low rainfall_0_country_7',\n",
       " 'abnormally low rainfall_0_country_8',\n",
       " 'withheld relief_0_country_3',\n",
       " 'withheld relief_0_country_4',\n",
       " 'withheld relief_0_country_5',\n",
       " 'withheld relief_0_country_6',\n",
       " 'withheld relief_0_country_7',\n",
       " 'withheld relief_0_country_8',\n",
       " 'international alarm_0_country_3',\n",
       " 'international alarm_0_country_4',\n",
       " 'international alarm_0_country_5',\n",
       " 'international alarm_0_country_6',\n",
       " 'international alarm_0_country_7',\n",
       " 'international alarm_0_country_8',\n",
       " 'reduced national output_0_country_3',\n",
       " 'reduced national output_0_country_4',\n",
       " 'reduced national output_0_country_5',\n",
       " 'reduced national output_0_country_6',\n",
       " 'reduced national output_0_country_7',\n",
       " 'reduced national output_0_country_8',\n",
       " 'oppressive regimes_0_country_3',\n",
       " 'oppressive regimes_0_country_4',\n",
       " 'oppressive regimes_0_country_5',\n",
       " 'oppressive regimes_0_country_6',\n",
       " 'oppressive regimes_0_country_7',\n",
       " 'oppressive regimes_0_country_8',\n",
       " 'pests_0_country_3',\n",
       " 'pests_0_country_4',\n",
       " 'pests_0_country_5',\n",
       " 'pests_0_country_6',\n",
       " 'pests_0_country_7',\n",
       " 'pests_0_country_8',\n",
       " 'continued deterioration_0_country_3',\n",
       " 'continued deterioration_0_country_4',\n",
       " 'continued deterioration_0_country_5',\n",
       " 'continued deterioration_0_country_6',\n",
       " 'continued deterioration_0_country_7',\n",
       " 'continued deterioration_0_country_8',\n",
       " 'forests destroyed_0_country_3',\n",
       " 'forests destroyed_0_country_4',\n",
       " 'forests destroyed_0_country_5',\n",
       " 'forests destroyed_0_country_6',\n",
       " 'forests destroyed_0_country_7',\n",
       " 'forests destroyed_0_country_8',\n",
       " 'man-made disaster_0_country_3',\n",
       " 'man-made disaster_0_country_4',\n",
       " 'man-made disaster_0_country_5',\n",
       " 'man-made disaster_0_country_6',\n",
       " 'man-made disaster_0_country_7',\n",
       " 'man-made disaster_0_country_8',\n",
       " 'food insecurity_0_country_3',\n",
       " 'food insecurity_0_country_4',\n",
       " 'food insecurity_0_country_5',\n",
       " 'food insecurity_0_country_6',\n",
       " 'food insecurity_0_country_7',\n",
       " 'food insecurity_0_country_8',\n",
       " 'harvests are devastated_0_country_3',\n",
       " 'harvests are devastated_0_country_4',\n",
       " 'harvests are devastated_0_country_5',\n",
       " 'harvests are devastated_0_country_6',\n",
       " 'harvests are devastated_0_country_7',\n",
       " 'harvests are devastated_0_country_8',\n",
       " 'humanitarian situation_0_country_3',\n",
       " 'humanitarian situation_0_country_4',\n",
       " 'humanitarian situation_0_country_5',\n",
       " 'humanitarian situation_0_country_6',\n",
       " 'humanitarian situation_0_country_7',\n",
       " 'humanitarian situation_0_country_8',\n",
       " 'economic impoverishment_0_country_3',\n",
       " 'economic impoverishment_0_country_4',\n",
       " 'economic impoverishment_0_country_5',\n",
       " 'economic impoverishment_0_country_6',\n",
       " 'economic impoverishment_0_country_7',\n",
       " 'economic impoverishment_0_country_8',\n",
       " 'clan battle_0_country_3',\n",
       " 'clan battle_0_country_4',\n",
       " 'clan battle_0_country_5',\n",
       " 'clan battle_0_country_6',\n",
       " 'clan battle_0_country_7',\n",
       " 'clan battle_0_country_8',\n",
       " 'population crisis_0_country_3',\n",
       " 'population crisis_0_country_4',\n",
       " 'population crisis_0_country_5',\n",
       " 'population crisis_0_country_6',\n",
       " 'population crisis_0_country_7',\n",
       " 'population crisis_0_country_8',\n",
       " 'aid appeal_0_country_3',\n",
       " 'aid appeal_0_country_4',\n",
       " 'aid appeal_0_country_5',\n",
       " 'aid appeal_0_country_6',\n",
       " 'aid appeal_0_country_7',\n",
       " 'aid appeal_0_country_8',\n",
       " 'weather extremes_0_country_3',\n",
       " 'weather extremes_0_country_4',\n",
       " 'weather extremes_0_country_5',\n",
       " 'weather extremes_0_country_6',\n",
       " 'weather extremes_0_country_7',\n",
       " 'weather extremes_0_country_8',\n",
       " 'anti-western policies_0_country_3',\n",
       " 'anti-western policies_0_country_4',\n",
       " 'anti-western policies_0_country_5',\n",
       " 'anti-western policies_0_country_6',\n",
       " 'anti-western policies_0_country_7',\n",
       " 'anti-western policies_0_country_8',\n",
       " 'rinderpest_0_country_3',\n",
       " 'rinderpest_0_country_4',\n",
       " 'rinderpest_0_country_5',\n",
       " 'rinderpest_0_country_6',\n",
       " 'rinderpest_0_country_7',\n",
       " 'rinderpest_0_country_8',\n",
       " 'inadequate rainfall_0_country_3',\n",
       " 'inadequate rainfall_0_country_4',\n",
       " 'inadequate rainfall_0_country_5',\n",
       " 'inadequate rainfall_0_country_6',\n",
       " 'inadequate rainfall_0_country_7',\n",
       " 'inadequate rainfall_0_country_8',\n",
       " 'lack of authority_0_country_3',\n",
       " 'lack of authority_0_country_4',\n",
       " 'lack of authority_0_country_5',\n",
       " 'lack of authority_0_country_6',\n",
       " 'lack of authority_0_country_7',\n",
       " 'lack of authority_0_country_8',\n",
       " 'acute hunger_0_country_3',\n",
       " 'acute hunger_0_country_4',\n",
       " 'acute hunger_0_country_5',\n",
       " 'acute hunger_0_country_6',\n",
       " 'acute hunger_0_country_7',\n",
       " 'acute hunger_0_country_8',\n",
       " 'foreign troops_0_country_3',\n",
       " 'foreign troops_0_country_4',\n",
       " 'foreign troops_0_country_5',\n",
       " 'foreign troops_0_country_6',\n",
       " 'foreign troops_0_country_7',\n",
       " 'foreign troops_0_country_8',\n",
       " 'increased external debt_0_country_3',\n",
       " 'increased external debt_0_country_4',\n",
       " 'increased external debt_0_country_5',\n",
       " 'increased external debt_0_country_6',\n",
       " 'increased external debt_0_country_7',\n",
       " 'increased external debt_0_country_8',\n",
       " 'drought_0_country_3',\n",
       " 'drought_0_country_4',\n",
       " 'drought_0_country_5',\n",
       " 'drought_0_country_6',\n",
       " 'drought_0_country_7',\n",
       " 'drought_0_country_8',\n",
       " 'conflict_0_country_3',\n",
       " 'conflict_0_country_4',\n",
       " 'conflict_0_country_5',\n",
       " 'conflict_0_country_6',\n",
       " 'conflict_0_country_7',\n",
       " 'conflict_0_country_8',\n",
       " 'failed rains_0_country_3',\n",
       " 'failed rains_0_country_4',\n",
       " 'failed rains_0_country_5',\n",
       " 'failed rains_0_country_6',\n",
       " 'failed rains_0_country_7',\n",
       " 'failed rains_0_country_8',\n",
       " 'makeshift camps_0_country_3',\n",
       " 'makeshift camps_0_country_4',\n",
       " 'makeshift camps_0_country_5',\n",
       " 'makeshift camps_0_country_6',\n",
       " 'makeshift camps_0_country_7',\n",
       " 'makeshift camps_0_country_8',\n",
       " 'civilians uprooted_0_country_3',\n",
       " 'civilians uprooted_0_country_4',\n",
       " 'civilians uprooted_0_country_5',\n",
       " 'civilians uprooted_0_country_6',\n",
       " 'civilians uprooted_0_country_7',\n",
       " 'civilians uprooted_0_country_8',\n",
       " 'dysfunction_0_country_3',\n",
       " 'dysfunction_0_country_4',\n",
       " 'dysfunction_0_country_5',\n",
       " 'dysfunction_0_country_6',\n",
       " 'dysfunction_0_country_7',\n",
       " 'dysfunction_0_country_8',\n",
       " 'foreign aid_0_country_3',\n",
       " 'foreign aid_0_country_4',\n",
       " 'foreign aid_0_country_5',\n",
       " 'foreign aid_0_country_6',\n",
       " 'foreign aid_0_country_7',\n",
       " 'foreign aid_0_country_8',\n",
       " 'violent suppression_0_country_3',\n",
       " 'violent suppression_0_country_4',\n",
       " 'violent suppression_0_country_5',\n",
       " 'violent suppression_0_country_6',\n",
       " 'violent suppression_0_country_7',\n",
       " 'violent suppression_0_country_8',\n",
       " 'military dictatorship_0_country_3',\n",
       " 'military dictatorship_0_country_4',\n",
       " 'military dictatorship_0_country_5',\n",
       " 'military dictatorship_0_country_6',\n",
       " 'military dictatorship_0_country_7',\n",
       " 'military dictatorship_0_country_8',\n",
       " 'climatic hazards_0_country_3',\n",
       " 'climatic hazards_0_country_4',\n",
       " 'climatic hazards_0_country_5',\n",
       " 'climatic hazards_0_country_6',\n",
       " 'climatic hazards_0_country_7',\n",
       " 'climatic hazards_0_country_8',\n",
       " 'migration_0_country_3',\n",
       " 'migration_0_country_4',\n",
       " 'migration_0_country_5',\n",
       " 'migration_0_country_6',\n",
       " 'migration_0_country_7',\n",
       " 'migration_0_country_8',\n",
       " 'land grab_0_country_3',\n",
       " 'land grab_0_country_4',\n",
       " 'land grab_0_country_5',\n",
       " 'land grab_0_country_6',\n",
       " 'land grab_0_country_7',\n",
       " 'land grab_0_country_8',\n",
       " 'terrorism_0_country_3',\n",
       " 'terrorism_0_country_4',\n",
       " 'terrorism_0_country_5',\n",
       " 'terrorism_0_country_6',\n",
       " 'terrorism_0_country_7',\n",
       " 'terrorism_0_country_8',\n",
       " 'bombing campaign_0_country_3',\n",
       " 'bombing campaign_0_country_4',\n",
       " 'bombing campaign_0_country_5',\n",
       " 'bombing campaign_0_country_6',\n",
       " 'bombing campaign_0_country_7',\n",
       " 'bombing campaign_0_country_8',\n",
       " 'collapsing economy_0_country_3',\n",
       " 'collapsing economy_0_country_4',\n",
       " 'collapsing economy_0_country_5',\n",
       " 'collapsing economy_0_country_6',\n",
       " 'collapsing economy_0_country_7',\n",
       " 'collapsing economy_0_country_8',\n",
       " 'military junta_0_country_3',\n",
       " 'military junta_0_country_4',\n",
       " 'military junta_0_country_5',\n",
       " 'military junta_0_country_6',\n",
       " 'military junta_0_country_7',\n",
       " 'military junta_0_country_8',\n",
       " 'climate change_0_country_3',\n",
       " 'climate change_0_country_4',\n",
       " 'climate change_0_country_5',\n",
       " 'climate change_0_country_6',\n",
       " 'climate change_0_country_7',\n",
       " 'climate change_0_country_8',\n",
       " 'rising inflation_0_country_3',\n",
       " 'rising inflation_0_country_4',\n",
       " 'rising inflation_0_country_5',\n",
       " 'rising inflation_0_country_6',\n",
       " 'rising inflation_0_country_7',\n",
       " 'rising inflation_0_country_8',\n",
       " 'international terrorists_0_country_3',\n",
       " 'international terrorists_0_country_4',\n",
       " 'international terrorists_0_country_5',\n",
       " 'international terrorists_0_country_6',\n",
       " 'international terrorists_0_country_7',\n",
       " 'international terrorists_0_country_8',\n",
       " 'cycle of poverty_0_country_3',\n",
       " 'cycle of poverty_0_country_4',\n",
       " 'cycle of poverty_0_country_5',\n",
       " 'cycle of poverty_0_country_6',\n",
       " 'cycle of poverty_0_country_7',\n",
       " 'cycle of poverty_0_country_8',\n",
       " 'bad harvests_0_country_3',\n",
       " 'bad harvests_0_country_4',\n",
       " 'bad harvests_0_country_5',\n",
       " 'bad harvests_0_country_6',\n",
       " 'bad harvests_0_country_7',\n",
       " 'bad harvests_0_country_8',\n",
       " 'destructive pattern_0_country_3',\n",
       " 'destructive pattern_0_country_4',\n",
       " 'destructive pattern_0_country_5',\n",
       " 'destructive pattern_0_country_6',\n",
       " 'destructive pattern_0_country_7',\n",
       " 'destructive pattern_0_country_8',\n",
       " 'price of food_0_country_3',\n",
       " 'price of food_0_country_4',\n",
       " 'price of food_0_country_5',\n",
       " 'price of food_0_country_6',\n",
       " 'price of food_0_country_7',\n",
       " 'price of food_0_country_8',\n",
       " 'corrupt government_0_country_3',\n",
       " 'corrupt government_0_country_4',\n",
       " 'corrupt government_0_country_5',\n",
       " 'corrupt government_0_country_6',\n",
       " 'corrupt government_0_country_7',\n",
       " 'corrupt government_0_country_8',\n",
       " 'militia groups_0_country_3',\n",
       " 'militia groups_0_country_4',\n",
       " 'militia groups_0_country_5',\n",
       " 'militia groups_0_country_6',\n",
       " 'militia groups_0_country_7',\n",
       " 'militia groups_0_country_8',\n",
       " 'poor soil quality_0_country_3',\n",
       " 'poor soil quality_0_country_4',\n",
       " 'poor soil quality_0_country_5',\n",
       " 'poor soil quality_0_country_6',\n",
       " 'poor soil quality_0_country_7',\n",
       " 'poor soil quality_0_country_8',\n",
       " 'cattle plague_0_country_3',\n",
       " 'cattle plague_0_country_4',\n",
       " 'cattle plague_0_country_5',\n",
       " 'cattle plague_0_country_6',\n",
       " 'cattle plague_0_country_7',\n",
       " 'cattle plague_0_country_8',\n",
       " 'food assistance_0_country_3',\n",
       " 'food assistance_0_country_4',\n",
       " 'food assistance_0_country_5',\n",
       " 'food assistance_0_country_6',\n",
       " 'food assistance_0_country_7',\n",
       " 'food assistance_0_country_8',\n",
       " 'continued strife_0_country_3',\n",
       " 'continued strife_0_country_4',\n",
       " 'continued strife_0_country_5',\n",
       " 'continued strife_0_country_6',\n",
       " 'continued strife_0_country_7',\n",
       " 'continued strife_0_country_8',\n",
       " 'ecological crisis_0_country_3',\n",
       " 'ecological crisis_0_country_4',\n",
       " 'ecological crisis_0_country_5',\n",
       " 'ecological crisis_0_country_6',\n",
       " 'ecological crisis_0_country_7',\n",
       " 'ecological crisis_0_country_8',\n",
       " 'hunger crises_0_country_3',\n",
       " 'hunger crises_0_country_4',\n",
       " 'hunger crises_0_country_5',\n",
       " 'hunger crises_0_country_6',\n",
       " 'hunger crises_0_country_7',\n",
       " 'hunger crises_0_country_8',\n",
       " 'rising food prices_0_country_3',\n",
       " 'rising food prices_0_country_4',\n",
       " 'rising food prices_0_country_5',\n",
       " 'rising food prices_0_country_6',\n",
       " 'rising food prices_0_country_7',\n",
       " 'rising food prices_0_country_8',\n",
       " 'restricted humanitarian access_0_country_3',\n",
       " 'restricted humanitarian access_0_country_4',\n",
       " 'restricted humanitarian access_0_country_5',\n",
       " 'restricted humanitarian access_0_country_6',\n",
       " 'restricted humanitarian access_0_country_7',\n",
       " 'restricted humanitarian access_0_country_8',\n",
       " 'water availability_0_country_3',\n",
       " 'water availability_0_country_4',\n",
       " 'water availability_0_country_5',\n",
       " 'water availability_0_country_6',\n",
       " 'water availability_0_country_7',\n",
       " 'water availability_0_country_8',\n",
       " 'alarming level_0_country_3',\n",
       " 'alarming level_0_country_4',\n",
       " 'alarming level_0_country_5',\n",
       " 'alarming level_0_country_6',\n",
       " 'alarming level_0_country_7',\n",
       " 'alarming level_0_country_8',\n",
       " 'police torture_0_country_3',\n",
       " 'police torture_0_country_4',\n",
       " 'police torture_0_country_5',\n",
       " 'police torture_0_country_6',\n",
       " 'police torture_0_country_7',\n",
       " 'police torture_0_country_8',\n",
       " 'potato blight_0_country_3',\n",
       " 'potato blight_0_country_4',\n",
       " 'potato blight_0_country_5',\n",
       " 'potato blight_0_country_6',\n",
       " 'potato blight_0_country_7',\n",
       " 'potato blight_0_country_8',\n",
       " 'the offensive_0_country_3',\n",
       " 'the offensive_0_country_4',\n",
       " 'the offensive_0_country_5',\n",
       " 'the offensive_0_country_6',\n",
       " 'the offensive_0_country_7',\n",
       " 'the offensive_0_country_8',\n",
       " 'land invasions_0_country_3',\n",
       " 'land invasions_0_country_4',\n",
       " 'land invasions_0_country_5',\n",
       " 'land invasions_0_country_6',\n",
       " 'land invasions_0_country_7',\n",
       " 'land invasions_0_country_8',\n",
       " 'clan warfare_0_country_3',\n",
       " 'clan warfare_0_country_4',\n",
       " 'clan warfare_0_country_5',\n",
       " 'clan warfare_0_country_6',\n",
       " 'clan warfare_0_country_7',\n",
       " 'clan warfare_0_country_8',\n",
       " 'stolen food aid_0_country_3',\n",
       " 'stolen food aid_0_country_4',\n",
       " 'stolen food aid_0_country_5',\n",
       " 'stolen food aid_0_country_6',\n",
       " 'stolen food aid_0_country_7',\n",
       " 'stolen food aid_0_country_8',\n",
       " 'politically engineered_0_country_3',\n",
       " 'politically engineered_0_country_4',\n",
       " 'politically engineered_0_country_5',\n",
       " 'politically engineered_0_country_6',\n",
       " 'politically engineered_0_country_7',\n",
       " 'politically engineered_0_country_8',\n",
       " 'scanty rainfall_0_country_3',\n",
       " 'scanty rainfall_0_country_4',\n",
       " 'scanty rainfall_0_country_5',\n",
       " 'scanty rainfall_0_country_6',\n",
       " 'scanty rainfall_0_country_7',\n",
       " 'scanty rainfall_0_country_8',\n",
       " 'water distribution shortages_0_country_3',\n",
       " 'water distribution shortages_0_country_4',\n",
       " 'water distribution shortages_0_country_5',\n",
       " 'water distribution shortages_0_country_6',\n",
       " 'water distribution shortages_0_country_7',\n",
       " 'water distribution shortages_0_country_8',\n",
       " 'cattle death_0_country_3',\n",
       " 'cattle death_0_country_4',\n",
       " 'cattle death_0_country_5',\n",
       " 'cattle death_0_country_6',\n",
       " 'cattle death_0_country_7',\n",
       " 'cattle death_0_country_8',\n",
       " 'asylum seekers_0_country_3',\n",
       " 'asylum seekers_0_country_4',\n",
       " 'asylum seekers_0_country_5',\n",
       " 'asylum seekers_0_country_6',\n",
       " 'asylum seekers_0_country_7',\n",
       " 'asylum seekers_0_country_8',\n",
       " 'major offensive_0_country_3',\n",
       " 'major offensive_0_country_4',\n",
       " 'major offensive_0_country_5',\n",
       " 'major offensive_0_country_6',\n",
       " 'major offensive_0_country_7',\n",
       " 'major offensive_0_country_8',\n",
       " 'without international aid_0_country_3',\n",
       " 'without international aid_0_country_4',\n",
       " 'without international aid_0_country_5',\n",
       " 'without international aid_0_country_6',\n",
       " 'without international aid_0_country_7',\n",
       " 'without international aid_0_country_8',\n",
       " 'prolonged dry spell_0_country_3',\n",
       " 'prolonged dry spell_0_country_4',\n",
       " 'prolonged dry spell_0_country_5',\n",
       " 'prolonged dry spell_0_country_6',\n",
       " 'prolonged dry spell_0_country_7',\n",
       " 'prolonged dry spell_0_country_8',\n",
       " 'rise_0_country_3',\n",
       " 'rise_0_country_4',\n",
       " 'rise_0_country_5',\n",
       " 'rise_0_country_6',\n",
       " 'rise_0_country_7',\n",
       " 'rise_0_country_8',\n",
       " 'restricted relief flights_0_country_3',\n",
       " 'restricted relief flights_0_country_4',\n",
       " 'restricted relief flights_0_country_5',\n",
       " 'restricted relief flights_0_country_6',\n",
       " 'restricted relief flights_0_country_7',\n",
       " 'restricted relief flights_0_country_8',\n",
       " 'civil strife_0_country_3',\n",
       " 'civil strife_0_country_4',\n",
       " 'civil strife_0_country_5',\n",
       " 'civil strife_0_country_6',\n",
       " 'civil strife_0_country_7',\n",
       " 'civil strife_0_country_8',\n",
       " 'aid workers died_0_country_3',\n",
       " 'aid workers died_0_country_4',\n",
       " 'aid workers died_0_country_5',\n",
       " 'aid workers died_0_country_6',\n",
       " 'aid workers died_0_country_7',\n",
       " 'aid workers died_0_country_8',\n",
       " 'rival warlords_0_country_3',\n",
       " 'rival warlords_0_country_4',\n",
       " 'rival warlords_0_country_5',\n",
       " 'rival warlords_0_country_6',\n",
       " 'rival warlords_0_country_7',\n",
       " 'rival warlords_0_country_8',\n",
       " 'land reform_0_country_3',\n",
       " 'land reform_0_country_4',\n",
       " 'land reform_0_country_5',\n",
       " 'land reform_0_country_6',\n",
       " 'land reform_0_country_7',\n",
       " 'land reform_0_country_8',\n",
       " 'lack of roads_0_country_3',\n",
       " 'lack of roads_0_country_4',\n",
       " 'lack of roads_0_country_5',\n",
       " 'lack of roads_0_country_6',\n",
       " 'lack of roads_0_country_7',\n",
       " 'lack of roads_0_country_8',\n",
       " 'pushing peasants off_0_country_3',\n",
       " 'pushing peasants off_0_country_4',\n",
       " 'pushing peasants off_0_country_5',\n",
       " 'pushing peasants off_0_country_6',\n",
       " 'pushing peasants off_0_country_7',\n",
       " 'pushing peasants off_0_country_8',\n",
       " 'locusts_0_country_3',\n",
       " 'locusts_0_country_4',\n",
       " 'locusts_0_country_5',\n",
       " 'locusts_0_country_6',\n",
       " 'locusts_0_country_7',\n",
       " 'locusts_0_country_8',\n",
       " 'gangs of bandits_0_country_3',\n",
       " 'gangs of bandits_0_country_4',\n",
       " 'gangs of bandits_0_country_5',\n",
       " 'gangs of bandits_0_country_6',\n",
       " 'gangs of bandits_0_country_7',\n",
       " 'gangs of bandits_0_country_8',\n",
       " 'repression_0_country_3',\n",
       " 'repression_0_country_4',\n",
       " 'repression_0_country_5',\n",
       " 'repression_0_country_6',\n",
       " 'repression_0_country_7',\n",
       " 'repression_0_country_8',\n",
       " 'humanitarian disaster_0_country_3',\n",
       " 'humanitarian disaster_0_country_4',\n",
       " 'humanitarian disaster_0_country_5',\n",
       " 'humanitarian disaster_0_country_6',\n",
       " 'humanitarian disaster_0_country_7',\n",
       " 'humanitarian disaster_0_country_8',\n",
       " 'years of warfare_0_country_3',\n",
       " 'years of warfare_0_country_4',\n",
       " 'years of warfare_0_country_5',\n",
       " 'years of warfare_0_country_6',\n",
       " 'years of warfare_0_country_7',\n",
       " 'years of warfare_0_country_8',\n",
       " 'floods_0_country_3',\n",
       " 'floods_0_country_4',\n",
       " 'floods_0_country_5',\n",
       " 'floods_0_country_6',\n",
       " 'floods_0_country_7',\n",
       " 'floods_0_country_8',\n",
       " 'unable to sow_0_country_3',\n",
       " 'unable to sow_0_country_4',\n",
       " 'unable to sow_0_country_5',\n",
       " 'unable to sow_0_country_6',\n",
       " 'unable to sow_0_country_7',\n",
       " 'unable to sow_0_country_8',\n",
       " 'transport bottleneck_0_country_3',\n",
       " 'transport bottleneck_0_country_4',\n",
       " 'transport bottleneck_0_country_5',\n",
       " 'transport bottleneck_0_country_6',\n",
       " 'transport bottleneck_0_country_7',\n",
       " 'transport bottleneck_0_country_8',\n",
       " 'pirates_0_country_3',\n",
       " 'pirates_0_country_4',\n",
       " 'pirates_0_country_5',\n",
       " 'pirates_0_country_6',\n",
       " 'pirates_0_country_7',\n",
       " 'pirates_0_country_8',\n",
       " 'reduced imports_0_country_3',\n",
       " 'reduced imports_0_country_4',\n",
       " 'reduced imports_0_country_5',\n",
       " 'reduced imports_0_country_6',\n",
       " 'reduced imports_0_country_7',\n",
       " 'reduced imports_0_country_8',\n",
       " 'apathy_0_country_3',\n",
       " 'apathy_0_country_4',\n",
       " 'apathy_0_country_5',\n",
       " 'apathy_0_country_6',\n",
       " 'apathy_0_country_7',\n",
       " 'apathy_0_country_8',\n",
       " 'coup_0_country_3',\n",
       " 'coup_0_country_4',\n",
       " 'coup_0_country_5',\n",
       " 'coup_0_country_6',\n",
       " 'coup_0_country_7',\n",
       " 'coup_0_country_8',\n",
       " 'epidemics_0_country_3',\n",
       " 'epidemics_0_country_4',\n",
       " 'epidemics_0_country_5',\n",
       " 'epidemics_0_country_6',\n",
       " 'epidemics_0_country_7',\n",
       " 'epidemics_0_country_8',\n",
       " 'siege_0_country_3',\n",
       " 'siege_0_country_4',\n",
       " 'siege_0_country_5',\n",
       " 'siege_0_country_6',\n",
       " 'siege_0_country_7',\n",
       " 'siege_0_country_8',\n",
       " 'power struggle_0_country_3',\n",
       " 'power struggle_0_country_4',\n",
       " 'power struggle_0_country_5',\n",
       " 'power struggle_0_country_6',\n",
       " 'power struggle_0_country_7',\n",
       " 'power struggle_0_country_8',\n",
       " 'livestock had died_0_country_3',\n",
       " 'livestock had died_0_country_4',\n",
       " 'livestock had died_0_country_5',\n",
       " 'livestock had died_0_country_6',\n",
       " 'livestock had died_0_country_7',\n",
       " 'livestock had died_0_country_8',\n",
       " 'blockade_0_country_3',\n",
       " 'blockade_0_country_4',\n",
       " 'blockade_0_country_5',\n",
       " 'blockade_0_country_6',\n",
       " 'blockade_0_country_7',\n",
       " 'blockade_0_country_8',\n",
       " 'burning houses_0_country_3',\n",
       " 'burning houses_0_country_4',\n",
       " 'burning houses_0_country_5',\n",
       " ...]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find columns that contain a particular substring\n",
    "\n",
    "list(filter(lambda x: 'co' in x, time_series.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find columns that begin with a particular substring\n",
    "list(filter(lambda x: x.startswith(\"coun\"), time_series.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: RF, Split: ((2011, 7), (2012, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2011, 7), (2012, 7)), Features: traditional, RMSE: 0.6266 [0.2275, 0.8565]\n",
      "Method: OLS, Split: ((2011, 7), (2012, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2011, 7), (2012, 7)), Features: traditional, RMSE: 4.0611 [3.6230, 4.4564]\n",
      "Method: Lasso, Split: ((2011, 7), (2012, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2011, 7), (2012, 7)), Features: traditional, RMSE: 0.7176 [0.3812, 0.9405]\n",
      "Method: RF, Split: ((2010, 7), (2011, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2010, 7), (2011, 7)), Features: traditional, RMSE: 0.3683 [nan, 0.6549]\n",
      "Method: OLS, Split: ((2010, 7), (2011, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2010, 7), (2011, 7)), Features: traditional, RMSE: 0.3164 [nan, 0.5964]\n",
      "Method: Lasso, Split: ((2010, 7), (2011, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2010, 7), (2011, 7)), Features: traditional, RMSE: 0.4417 [nan, 0.7627]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: RF, Split: ((2010, 7), (2011, 7)), Features: news, AUCPR: 0.9028\n",
      "Method: RF, Split: ((2010, 7), (2011, 7)), Features: news, RMSE: 0.4091 [nan, 0.7131]\n",
      "Method: RF, Split: ((2010, 7), (2011, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2010, 7), (2011, 7)), Features: traditional+news, RMSE: 0.4435 [nan, 0.7491]\n",
      "Method: OLS, Split: ((2010, 7), (2011, 7)), Features: news, AUCPR: 0.7639\n",
      "Method: OLS, Split: ((2010, 7), (2011, 7)), Features: news, RMSE: 0.4581 [nan, 0.7787]\n",
      "Method: OLS, Split: ((2010, 7), (2011, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2010, 7), (2011, 7)), Features: traditional+news, RMSE: 0.4167 [nan, 0.7311]\n",
      "Method: Lasso, Split: ((2010, 7), (2011, 7)), Features: news, AUCPR: 0.9028\n",
      "Method: Lasso, Split: ((2010, 7), (2011, 7)), Features: news, RMSE: 0.5171 [nan, 0.8353]\n",
      "Method: Lasso, Split: ((2010, 7), (2011, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2010, 7), (2011, 7)), Features: traditional+news, RMSE: 0.2907 [nan, 0.5717]\n",
      "Method: RF, Split: ((2011, 7), (2012, 7)), Features: news, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2011, 7), (2012, 7)), Features: news, RMSE: 0.5686 [0.4340, 0.6769]\n",
      "Method: OLS, Split: ((2011, 7), (2012, 7)), Features: news, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2011, 7), (2012, 7)), Features: news, RMSE: 0.6991 [0.4596, 0.8754]\n",
      "Method: Lasso, Split: ((2011, 7), (2012, 7)), Features: news, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2011, 7), (2012, 7)), Features: news, RMSE: 0.3515 [0.2251, 0.4432]\n",
      "Method: RF, Split: ((2011, 7), (2012, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2011, 7), (2012, 7)), Features: traditional+news, RMSE: 0.6068 [0.4660, 0.7207]\n",
      "Method: RF, Split: ((2012, 7), (2013, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2012, 7), (2013, 7)), Features: traditional, RMSE: 0.1390 [nan, 0.3554]\n",
      "Method: OLS, Split: ((2011, 7), (2012, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2011, 7), (2012, 7)), Features: traditional+news, RMSE: 0.7162 [0.4693, 0.8975]\n",
      "Method: OLS, Split: ((2012, 7), (2013, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2012, 7), (2013, 7)), Features: traditional, RMSE: 0.0423 [nan, 0.1987]\n",
      "Method: Lasso, Split: ((2011, 7), (2012, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2011, 7), (2012, 7)), Features: traditional+news, RMSE: 0.6627 [0.3469, 0.8707]\n",
      "Method: Lasso, Split: ((2012, 7), (2013, 7)), Features: traditional, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2012, 7), (2013, 7)), Features: traditional, RMSE: 0.1762 [nan, 0.2502]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py:85: RuntimeWarning: invalid value encountered in sqrt\n",
      "/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_ranking.py:1033: UserWarning: No positive class found in y_true, recall is set to one for all thresholds.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: RF, Split: ((2012, 7), (2013, 7)), Features: news, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2012, 7), (2013, 7)), Features: news, RMSE: 0.3876 [0.2015, 0.5098]\n",
      "Method: OLS, Split: ((2012, 7), (2013, 7)), Features: news, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2012, 7), (2013, 7)), Features: news, RMSE: 0.3448 [nan, 0.5946]\n",
      "Method: Lasso, Split: ((2012, 7), (2013, 7)), Features: news, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2012, 7), (2013, 7)), Features: news, RMSE: 0.2283 [nan, 0.3744]\n",
      "Method: RF, Split: ((2012, 7), (2013, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: RF, Split: ((2012, 7), (2013, 7)), Features: traditional+news, RMSE: 0.3317 [0.0851, 0.4613]\n",
      "Method: OLS, Split: ((2012, 7), (2013, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: OLS, Split: ((2012, 7), (2013, 7)), Features: traditional+news, RMSE: 0.3183 [nan, 0.5574]\n",
      "Method: Lasso, Split: ((2012, 7), (2013, 7)), Features: traditional+news, AUCPR: 0.5000\n",
      "Method: Lasso, Split: ((2012, 7), (2013, 7)), Features: traditional+news, RMSE: 0.2174 [nan, 0.4258]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by RandomForestRegressor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 428, in _process_worker\n    r = call_item()\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/joblib/externals/loky/process_executor.py\", line 275, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/joblib/_parallel_backends.py\", line 620, in __call__\n    return self.func(*args, **kwargs)\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py\", line 288, in __call__\n    return [func(*args, **kwargs)\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py\", line 288, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_82761/3286982531.py\", line 79, in train_and_evaluate\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_forest.py\", line 1066, in predict\n    X = self._validate_X_predict(X)\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/ensemble/_forest.py\", line 638, in _validate_X_predict\n    X = validate_data(\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py\", line 2944, in validate_data\n    out = check_array(X, input_name=\"X\", **check_params)\n  File \"/Users/wajihanaveed/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py\", line 1130, in check_array\n    raise ValueError(\nValueError: Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by RandomForestRegressor.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# run in parallel on 4 cpu cores/decrease this if you do not want ur system to crash (speaking from experience)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m all_results \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_and_evaluate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdev_splits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m fig_3a \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame([res \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m all_results \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m sublist])\n\u001b[1;32m    109\u001b[0m fig_3a\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfig_3a.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:438\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 438\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/_base.py:390\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    391\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    392\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 26)) while a minimum of 1 is required by RandomForestRegressor."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import root_mean_squared_error, precision_recall_curve, auc\n",
    "\n",
    "train_splits = [((2009,7), (2010,4)), ((2009,7), (2011,1)), ((2009,7), (2011,10)), \n",
    "                ((2009,7), (2012,7)), ((2009,7), (2013,7)), ((2009,7), (2014,1)), \n",
    "                ((2009,7), (2015,1)), ((2009,7), (2015,10)), ((2009,7), (2016,10)), \n",
    "                ((2009,7), (2017,2))]\n",
    "\n",
    "dev_splits = [((2010,4), (2010, 7)), ((2011,1), (2011, 7)), ((2011,10), (2012, 7)), \n",
    "              ((2012,7), (2013, 7)), ((2013,4), (2014, 7)), ((2014,1), (2015, 7)), \n",
    "              ((2015,1), (2016, 7)), ((2015,10), (2017, 7)), ((2016,10), (2018, 7)), \n",
    "              ((2017,2), (2019, 2))]\n",
    "\n",
    "test_splits = [((2010,7), (2011, 7)), ((2011,7), (2012, 7)), ((2012,7), (2013, 7)), \n",
    "               ((2013,7), (2014, 7)), ((2014,7), (2015, 7)), ((2015,7), (2016, 7)), \n",
    "               ((2016,7), (2017, 7)), ((2017,7), (2018, 7)), ((2018,7), (2019, 7)), \n",
    "               ((2019,2), (2020, 2))]\n",
    "\n",
    "# just like them we will evaluate three dufferent models, Random Forest, OLS and Lasso. Random Forest is a tree-based model, OLS is a linear regression model and Lasso is a linear regression model with L1 regularization\n",
    "models = {\n",
    "    'RF': RandomForestRegressor(max_features='sqrt', n_estimators=100, min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0),\n",
    "    'OLS': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=0.1)\n",
    "}\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return [f\"{f}_{t}\" for f in factors for t in range(3, 9)] + \\\n",
    "           [f\"{f}_province_{t}\" for f in factors for t in range(3, 9)] + \\\n",
    "           [f\"{f}_country_{t}\" for f in factors for t in range(3, 9)]\n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors],\n",
    "    \n",
    "    'news': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(news_factors)],\n",
    "    \n",
    "    'traditional+news': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors + \n",
    "        get_agg_lagged_features(news_factors)]\n",
    "}\n",
    "\n",
    "labels_df = time_series[['fews_ipc', 'year', 'month']]\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[\n",
    "        (((df['year'] > start[0])) | ((df['year'] == start[0]) & (df['month'] >= start[1]))) &\n",
    "        (((df['year'] < end[0])) | ((df['year'] == end[0]) & (df['month'] <= end[1])))\n",
    "    ]\n",
    "\n",
    "thresholds = {\n",
    "    'traditional': (2.236, 3.125), 'news': (1.907, 2.712), 'traditional+news': (2.105, 3.314),\n",
    "} # (lowerbound, upperbound)\n",
    "\n",
    "def train_and_evaluate(train, dev, test, f, D):\n",
    "    results = []\n",
    "\n",
    "    X_train = get_time_split(D, train[0], dev[1]).drop(columns=['year', 'month']).fillna(0).to_numpy() # not sure how okay it is to do fillna. When me and Bilal were running this we were getting the error that cannot run the model on NaN values. First we dropped na but this was causing the shape of the X_train to be different from the y_train. So we decided to fillna with 0. - aysha & bilal\n",
    "    y_train = get_time_split(labels_df, train[0], dev[1]).drop(columns=['year', 'month']).to_numpy().ravel()\n",
    "    \n",
    "    X_test = get_time_split(D, test[0], test[1]).drop(columns=['year', 'month']).fillna(0).to_numpy()\n",
    "    y_test = get_time_split(labels_df, test[0], test[1]).drop(columns=['year', 'month']).to_numpy().ravel()\n",
    "    \n",
    "    # convert y_test into binary classification (1 if inside threshold, else 0)\n",
    "    lower, upper = thresholds[f]\n",
    "    y_test_binary = np.where((y_test >= lower) & (y_test <= upper), 1, 0)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, preds)\n",
    "\n",
    "        stderr = np.std(y_test - preds) / np.sqrt(len(y_test))\n",
    "        upper_bound = np.sqrt(rmse**2 + 1.96 * stderr)\n",
    "        lower_bound = np.sqrt(rmse**2 - 1.96 * stderr)\n",
    "\n",
    "        precision, recall, _ = precision_recall_curve(y_test_binary, preds)\n",
    "        aucpr = auc(recall, precision)\n",
    "\n",
    "        results.append({\n",
    "            'method': name, 'split': test, 'features': f, \n",
    "            'rmse': rmse, 'lower_bound': lower_bound, 'upper_bound': upper_bound,\n",
    "            'aucpr': aucpr\n",
    "        })\n",
    "\n",
    "        print(f\"Method: {name}, Split: {test}, Features: {f}, AUCPR: {aucpr:.4f}\")\n",
    "        print(f\"Method: {name}, Split: {test}, Features: {f}, RMSE: {rmse:.4f} [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
    "        \n",
    "        # completely removed the part where they were doing country-wise evaluation. Do not see point - aysha\n",
    "    \n",
    "    return results\n",
    "\n",
    "# run in parallel on 4 cpu cores/decrease this if you do not want ur system to crash (speaking from experience)\n",
    "all_results = Parallel(n_jobs=4)(\n",
    "    delayed(train_and_evaluate)(train, dev, test, f, D) for train, dev, test in zip(train_splits, dev_splits, test_splits) for f, D in features.items()\n",
    ")\n",
    "\n",
    "fig_3a = pd.DataFrame([res for sublist in all_results for res in sublist])\n",
    "fig_3a.to_csv('fig_3a.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
