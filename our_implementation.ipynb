{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 **Re-Implementation of \"Predicting Food Crises Using News Streams\"**\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔍 **Objective**\n",
    "\n",
    "This notebook aims to **reproduce and analyze** the methodology presented in the paper:\n",
    "\n",
    "📄 **Paper:** [Predicting food crises using news streams](https://www.science.org/doi/10.1126/sciadv.abm3449)  \n",
    "📊 **Dataset:** [Harvard Dataverse Repository](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CJDWUW)  \n",
    "📜 **Original Code & Methods:** [GitHub - Regression Modeling (Step 5)](https://github.com/philippzi98/food_insecurity_predictions_nlp/blob/main/Step%205%20-%20Regression%20Modelling/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🛠 **Methodology**\n",
    "\n",
    "This implementation follows the **key steps** outlined in the paper to predict **food insecurity crises** using a combination of:\n",
    "1️⃣ **Traditional Risk Factors** (conflict, climate, food prices, etc.)  \n",
    "2️⃣ **News-Based Indicators** (text feature frequencies from news articles)  \n",
    "3️⃣ **Lagging & Aggregation** (temporal dependencies at district, province, and country levels)  \n",
    "4️⃣ **Machine Learning Models** (Random Forest, OLS, Lasso)\n",
    "\n",
    "---\n",
    "\n",
    "#### 🔗 **Reference Materials**\n",
    "\n",
    "📄 **Supplementary Material:** Available in `supplemental_material_from_paper.pdf`  \n",
    "📊 **Datasets Used:**\n",
    "\n",
    "- `time_series_with_causes_zscore_full.csv` (Main dataset with time-series features)\n",
    "- `famine-country-province-district-years-CS.csv` (Food insecurity classification)\n",
    "- `matching_districts.csv` (Geographical standardization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📚🔧 Import Libraries\n",
    "\n",
    "In this notebook, we will use uv to manage our Python environment and packages efficiently. uv is a modern and fast package manager that simplifies virtual environment creation, and dependency installation. We will create a virtual environment, install necessary libraries, and ensure our environment stays consistent across different setups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncoment the below cell to install `uv` if you have not already. You can also install it trhiugh `pip` by running `!pip install uv` but this will be within your current python environment and not globally.\n",
    "\n",
    "# !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# !uv venv world-bank\n",
    "# !source world-bank/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import editdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have the data downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📂 Load and Clean Data\n",
    "\n",
    "**Understanding the Time-Series Dataset & Column Selection**\n",
    "\n",
    "This dataset contains **district-level time-series data** on food insecurity risk factors, including:\n",
    "\n",
    "- **📅 Temporal Information:** `year`, `month`, `year_month`\n",
    "- **📍 Geographical Identifiers:** `admin_code`, `admin_name`, `province`, `country`\n",
    "- **🌍 Traditional Risk Factors:** Climate (`rain_mean`, `ndvi_mean`), conflict (`acled_count`), food prices (`p_staple_food`)\n",
    "- **📰 News-Based Indicators:** Proportions of news articles mentioning crisis-related keywords (`conflict_0`, `famine_0`, etc.)\n",
    "- **📉 Food Insecurity Label:** `fews_ipc` (Integrated Phase Classification)\n",
    "\n",
    "🔥 **Columns We Will Drop & Why**\n",
    "✔ **Redundant Aggregations:** `_1`, `_2` columns (province & country-level values) since we will recompute aggregations from scratch anyways.  \n",
    "✔ **Unnamed/Index Columns:** `Unnamed: 0` as it is unnecessary. It is just a duplicate of default index.\n",
    "✔ **Unnecessary Identifiers:** If `admin_code` and `admin_name`, after matching these to `matching_districts.csv`, we can drop them.\n",
    "\n",
    "---\n",
    "\n",
    "> ⚠️ **NOTE:**  \n",
    "> For a detailed explanation of the dataset and features, refer to the [`explore_time_series.ipynb`](./explore_time_series.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = pd.read_csv('./data/time_series_with_causes_zscore_full.csv')\n",
    "admins = pd.read_csv('./data/famine-country-province-district-years-CS.csv')\n",
    "valid_matching = pd.read_csv('./data/matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'abnormally low rainfall_0',\n",
       " 'abnormally low rainfall_1',\n",
       " 'abnormally low rainfall_2',\n",
       " 'acled_count',\n",
       " 'acled_fatalities',\n",
       " 'acute hunger_0',\n",
       " 'acute hunger_1',\n",
       " 'acute hunger_2',\n",
       " 'admin_code',\n",
       " 'admin_name',\n",
       " 'aid appeal_0',\n",
       " 'aid appeal_1',\n",
       " 'aid appeal_2',\n",
       " 'aid workers died_0',\n",
       " 'aid workers died_1',\n",
       " 'aid workers died_2',\n",
       " 'air attack_0',\n",
       " 'air attack_1',\n",
       " 'air attack_2',\n",
       " 'alarming level_0',\n",
       " 'alarming level_1',\n",
       " 'alarming level_2',\n",
       " 'anti-western policies_0',\n",
       " 'anti-western policies_1',\n",
       " 'anti-western policies_2',\n",
       " 'apathy_0',\n",
       " 'apathy_1',\n",
       " 'apathy_2',\n",
       " 'area',\n",
       " 'asylum seekers_0',\n",
       " 'asylum seekers_1',\n",
       " 'asylum seekers_2',\n",
       " 'authoritarian_0',\n",
       " 'authoritarian_1',\n",
       " 'authoritarian_2',\n",
       " 'bad harvests_0',\n",
       " 'bad harvests_1',\n",
       " 'bad harvests_2',\n",
       " 'blockade_0',\n",
       " 'blockade_1',\n",
       " 'blockade_2',\n",
       " 'bombing campaign_0',\n",
       " 'bombing campaign_1',\n",
       " 'bombing campaign_2',\n",
       " 'brain drain_0',\n",
       " 'brain drain_1',\n",
       " 'brain drain_2',\n",
       " 'brutal government_0',\n",
       " 'brutal government_1',\n",
       " 'brutal government_2',\n",
       " 'burning houses_0',\n",
       " 'burning houses_1',\n",
       " 'burning houses_2',\n",
       " 'call for donations_0',\n",
       " 'call for donations_1',\n",
       " 'call for donations_2',\n",
       " 'carbon_0',\n",
       " 'carbon_1',\n",
       " 'carbon_2',\n",
       " 'catastrophe_0',\n",
       " 'catastrophe_1',\n",
       " 'catastrophe_2',\n",
       " 'cattle death_0',\n",
       " 'cattle death_1',\n",
       " 'cattle death_2',\n",
       " 'cattle plague_0',\n",
       " 'cattle plague_1',\n",
       " 'cattle plague_2',\n",
       " 'centx',\n",
       " 'centy',\n",
       " 'change_fews',\n",
       " 'cholera outbreak_0',\n",
       " 'cholera outbreak_1',\n",
       " 'cholera outbreak_2',\n",
       " 'civil strife_0',\n",
       " 'civil strife_1',\n",
       " 'civil strife_2',\n",
       " 'civilians uprooted_0',\n",
       " 'civilians uprooted_1',\n",
       " 'civilians uprooted_2',\n",
       " 'clan battle_0',\n",
       " 'clan battle_1',\n",
       " 'clan battle_2',\n",
       " 'clan warfare_0',\n",
       " 'clan warfare_1',\n",
       " 'clan warfare_2',\n",
       " 'clans_0',\n",
       " 'clans_1',\n",
       " 'clans_2',\n",
       " 'climate change_0',\n",
       " 'climate change_1',\n",
       " 'climate change_2',\n",
       " 'climatic hazards_0',\n",
       " 'climatic hazards_1',\n",
       " 'climatic hazards_2',\n",
       " 'collapse of government_0',\n",
       " 'collapse of government_1',\n",
       " 'collapse of government_2',\n",
       " 'collapsing economy_0',\n",
       " 'collapsing economy_1',\n",
       " 'collapsing economy_2',\n",
       " 'conflict_0',\n",
       " 'conflict_1',\n",
       " 'conflict_2',\n",
       " 'continued deterioration_0',\n",
       " 'continued deterioration_1',\n",
       " 'continued deterioration_2',\n",
       " 'continued strife_0',\n",
       " 'continued strife_1',\n",
       " 'continued strife_2',\n",
       " 'convoys_0',\n",
       " 'convoys_1',\n",
       " 'convoys_2',\n",
       " 'corrupt government_0',\n",
       " 'corrupt government_1',\n",
       " 'corrupt government_2',\n",
       " 'corruption_0',\n",
       " 'corruption_1',\n",
       " 'corruption_2',\n",
       " 'country',\n",
       " 'coup_0',\n",
       " 'coup_1',\n",
       " 'coup_2',\n",
       " 'cropland_pct',\n",
       " 'cycle of poverty_0',\n",
       " 'cycle of poverty_1',\n",
       " 'cycle of poverty_2',\n",
       " 'cyclone_0',\n",
       " 'cyclone_1',\n",
       " 'cyclone_2',\n",
       " \"d'etat_0\",\n",
       " \"d'etat_1\",\n",
       " \"d'etat_2\",\n",
       " 'dehydrated_0',\n",
       " 'dehydrated_1',\n",
       " 'dehydrated_2',\n",
       " 'destructive pattern_0',\n",
       " 'destructive pattern_1',\n",
       " 'destructive pattern_2',\n",
       " 'devastated the economy_0',\n",
       " 'devastated the economy_1',\n",
       " 'devastated the economy_2',\n",
       " 'dictators_0',\n",
       " 'dictators_1',\n",
       " 'dictators_2',\n",
       " 'displaced_0',\n",
       " 'displaced_1',\n",
       " 'displaced_2',\n",
       " 'disrupted trade_0',\n",
       " 'disrupted trade_1',\n",
       " 'disrupted trade_2',\n",
       " 'disruption to farming_0',\n",
       " 'disruption to farming_1',\n",
       " 'disruption to farming_2',\n",
       " 'drought_0',\n",
       " 'drought_1',\n",
       " 'drought_2',\n",
       " 'dysfunction_0',\n",
       " 'dysfunction_1',\n",
       " 'dysfunction_2',\n",
       " 'ecological crisis_0',\n",
       " 'ecological crisis_1',\n",
       " 'ecological crisis_2',\n",
       " 'economic crisis_0',\n",
       " 'economic crisis_1',\n",
       " 'economic crisis_2',\n",
       " 'economic impoverishment_0',\n",
       " 'economic impoverishment_1',\n",
       " 'economic impoverishment_2',\n",
       " 'environmental degradation_0',\n",
       " 'environmental degradation_1',\n",
       " 'environmental degradation_2',\n",
       " 'epidemics_0',\n",
       " 'epidemics_1',\n",
       " 'epidemics_2',\n",
       " 'et_anom',\n",
       " 'et_mean',\n",
       " 'failed crops_0',\n",
       " 'failed crops_1',\n",
       " 'failed crops_2',\n",
       " 'failed rains_0',\n",
       " 'failed rains_1',\n",
       " 'failed rains_2',\n",
       " 'farmland_0',\n",
       " 'farmland_1',\n",
       " 'farmland_2',\n",
       " 'fews_ha',\n",
       " 'fews_ipc',\n",
       " 'fews_proj_med',\n",
       " 'fews_proj_med_ha',\n",
       " 'fews_proj_near',\n",
       " 'fews_proj_near_ha',\n",
       " 'flee_0',\n",
       " 'flee_1',\n",
       " 'flee_2',\n",
       " 'floods_0',\n",
       " 'floods_1',\n",
       " 'floods_2',\n",
       " 'food assistance_0',\n",
       " 'food assistance_1',\n",
       " 'food assistance_2',\n",
       " 'food crisis_0',\n",
       " 'food crisis_1',\n",
       " 'food crisis_2',\n",
       " 'food insecurity_0',\n",
       " 'food insecurity_1',\n",
       " 'food insecurity_2',\n",
       " 'foreign aid_0',\n",
       " 'foreign aid_1',\n",
       " 'foreign aid_2',\n",
       " 'foreign troops_0',\n",
       " 'foreign troops_1',\n",
       " 'foreign troops_2',\n",
       " 'forests destroyed_0',\n",
       " 'forests destroyed_1',\n",
       " 'forests destroyed_2',\n",
       " 'gangs of bandits_0',\n",
       " 'gangs of bandits_1',\n",
       " 'gangs of bandits_2',\n",
       " 'gastrointestinal_0',\n",
       " 'gastrointestinal_1',\n",
       " 'gastrointestinal_2',\n",
       " 'greenhouse gases_0',\n",
       " 'greenhouse gases_1',\n",
       " 'greenhouse gases_2',\n",
       " 'harvest decline_0',\n",
       " 'harvest decline_1',\n",
       " 'harvest decline_2',\n",
       " 'harvests are devastated_0',\n",
       " 'harvests are devastated_1',\n",
       " 'harvests are devastated_2',\n",
       " 'human rights abuses_0',\n",
       " 'human rights abuses_1',\n",
       " 'human rights abuses_2',\n",
       " 'humanitarian disaster_0',\n",
       " 'humanitarian disaster_1',\n",
       " 'humanitarian disaster_2',\n",
       " 'humanitarian situation_0',\n",
       " 'humanitarian situation_1',\n",
       " 'humanitarian situation_2',\n",
       " 'hunger crises_0',\n",
       " 'hunger crises_1',\n",
       " 'hunger crises_2',\n",
       " 'inadequate rainfall_0',\n",
       " 'inadequate rainfall_1',\n",
       " 'inadequate rainfall_2',\n",
       " 'increased external debt_0',\n",
       " 'increased external debt_1',\n",
       " 'increased external debt_2',\n",
       " 'index',\n",
       " 'infant mortality_0',\n",
       " 'infant mortality_1',\n",
       " 'infant mortality_2',\n",
       " 'infrastructure damage_0',\n",
       " 'infrastructure damage_1',\n",
       " 'infrastructure damage_2',\n",
       " 'internal strife_0',\n",
       " 'internal strife_1',\n",
       " 'internal strife_2',\n",
       " 'international alarm_0',\n",
       " 'international alarm_1',\n",
       " 'international alarm_2',\n",
       " 'international embargo_0',\n",
       " 'international embargo_1',\n",
       " 'international embargo_2',\n",
       " 'international intervention_0',\n",
       " 'international intervention_1',\n",
       " 'international intervention_2',\n",
       " 'international terrorists_0',\n",
       " 'international terrorists_1',\n",
       " 'international terrorists_2',\n",
       " 'jihadist groups_0',\n",
       " 'jihadist groups_1',\n",
       " 'jihadist groups_2',\n",
       " 'lack of agricultural infrastructure_0',\n",
       " 'lack of agricultural infrastructure_1',\n",
       " 'lack of agricultural infrastructure_2',\n",
       " 'lack of alternatives_0',\n",
       " 'lack of alternatives_1',\n",
       " 'lack of alternatives_2',\n",
       " 'lack of authority_0',\n",
       " 'lack of authority_1',\n",
       " 'lack of authority_2',\n",
       " 'lack of cultivation_0',\n",
       " 'lack of cultivation_1',\n",
       " 'lack of cultivation_2',\n",
       " 'lack of rains_0',\n",
       " 'lack of rains_1',\n",
       " 'lack of rains_2',\n",
       " 'lack of roads_0',\n",
       " 'lack of roads_1',\n",
       " 'lack of roads_2',\n",
       " 'land degradation_0',\n",
       " 'land degradation_1',\n",
       " 'land degradation_2',\n",
       " 'land grab_0',\n",
       " 'land grab_1',\n",
       " 'land grab_2',\n",
       " 'land invasions_0',\n",
       " 'land invasions_1',\n",
       " 'land invasions_2',\n",
       " 'land reform_0',\n",
       " 'land reform_1',\n",
       " 'land reform_2',\n",
       " 'land seizures_0',\n",
       " 'land seizures_1',\n",
       " 'land seizures_2',\n",
       " 'life-threatening hunger_0',\n",
       " 'life-threatening hunger_1',\n",
       " 'life-threatening hunger_2',\n",
       " 'livestock had died_0',\n",
       " 'livestock had died_1',\n",
       " 'livestock had died_2',\n",
       " 'locusts_0',\n",
       " 'locusts_1',\n",
       " 'locusts_2',\n",
       " 'looting_0',\n",
       " 'looting_1',\n",
       " 'looting_2',\n",
       " 'major offensive_0',\n",
       " 'major offensive_1',\n",
       " 'major offensive_2',\n",
       " 'makeshift camps_0',\n",
       " 'makeshift camps_1',\n",
       " 'makeshift camps_2',\n",
       " 'malnourished_0',\n",
       " 'malnourished_1',\n",
       " 'malnourished_2',\n",
       " 'man-made disaster_0',\n",
       " 'man-made disaster_1',\n",
       " 'man-made disaster_2',\n",
       " 'mass hunger_0',\n",
       " 'mass hunger_1',\n",
       " 'mass hunger_2',\n",
       " 'massive starvation_0',\n",
       " 'massive starvation_1',\n",
       " 'massive starvation_2',\n",
       " 'mayhem_0',\n",
       " 'mayhem_1',\n",
       " 'mayhem_2',\n",
       " 'migration_0',\n",
       " 'migration_1',\n",
       " 'migration_2',\n",
       " 'military dictatorship_0',\n",
       " 'military dictatorship_1',\n",
       " 'military dictatorship_2',\n",
       " 'military junta_0',\n",
       " 'military junta_1',\n",
       " 'military junta_2',\n",
       " 'militia groups_0',\n",
       " 'militia groups_1',\n",
       " 'militia groups_2',\n",
       " 'mismanagement_0',\n",
       " 'mismanagement_1',\n",
       " 'mismanagement_2',\n",
       " 'month',\n",
       " 'natural disaster_0',\n",
       " 'natural disaster_1',\n",
       " 'natural disaster_2',\n",
       " 'ndvi_anom',\n",
       " 'ndvi_mean',\n",
       " 'oppressive regimes_0',\n",
       " 'oppressive regimes_1',\n",
       " 'oppressive regimes_2',\n",
       " 'overthrow_0',\n",
       " 'overthrow_1',\n",
       " 'overthrow_2',\n",
       " 'p_staple_food',\n",
       " 'pasture_pct',\n",
       " 'pests_0',\n",
       " 'pests_1',\n",
       " 'pests_2',\n",
       " 'pirates_0',\n",
       " 'pirates_1',\n",
       " 'pirates_2',\n",
       " 'police torture_0',\n",
       " 'police torture_1',\n",
       " 'police torture_2',\n",
       " 'politically engineered_0',\n",
       " 'politically engineered_1',\n",
       " 'politically engineered_2',\n",
       " 'poor soil quality_0',\n",
       " 'poor soil quality_1',\n",
       " 'poor soil quality_2',\n",
       " 'pop',\n",
       " 'population crisis_0',\n",
       " 'population crisis_1',\n",
       " 'population crisis_2',\n",
       " 'potato blight_0',\n",
       " 'potato blight_1',\n",
       " 'potato blight_2',\n",
       " 'power struggle_0',\n",
       " 'power struggle_1',\n",
       " 'power struggle_2',\n",
       " 'price of food_0',\n",
       " 'price of food_1',\n",
       " 'price of food_2',\n",
       " 'price rise_0',\n",
       " 'price rise_1',\n",
       " 'price rise_2',\n",
       " 'prolonged dry spell_0',\n",
       " 'prolonged dry spell_1',\n",
       " 'prolonged dry spell_2',\n",
       " 'prolonged fighting_0',\n",
       " 'prolonged fighting_1',\n",
       " 'prolonged fighting_2',\n",
       " 'pushing peasants off_0',\n",
       " 'pushing peasants off_1',\n",
       " 'pushing peasants off_2',\n",
       " 'rain_anom',\n",
       " 'rain_mean',\n",
       " 'rebel insurgency_0',\n",
       " 'rebel insurgency_1',\n",
       " 'rebel insurgency_2',\n",
       " 'reduced imports_0',\n",
       " 'reduced imports_1',\n",
       " 'reduced imports_2',\n",
       " 'reduced national output_0',\n",
       " 'reduced national output_1',\n",
       " 'reduced national output_2',\n",
       " 'refugees_0',\n",
       " 'refugees_1',\n",
       " 'refugees_2',\n",
       " 'regimes were toppled_0',\n",
       " 'regimes were toppled_1',\n",
       " 'regimes were toppled_2',\n",
       " 'repression_0',\n",
       " 'repression_1',\n",
       " 'repression_2',\n",
       " 'restricted humanitarian access_0',\n",
       " 'restricted humanitarian access_1',\n",
       " 'restricted humanitarian access_2',\n",
       " 'restricted relief flights_0',\n",
       " 'restricted relief flights_1',\n",
       " 'restricted relief flights_2',\n",
       " 'rinderpest_0',\n",
       " 'rinderpest_1',\n",
       " 'rinderpest_2',\n",
       " 'rise_0',\n",
       " 'rise_1',\n",
       " 'rise_2',\n",
       " 'rising food prices_0',\n",
       " 'rising food prices_1',\n",
       " 'rising food prices_2',\n",
       " 'rising inflation_0',\n",
       " 'rising inflation_1',\n",
       " 'rising inflation_2',\n",
       " 'rival warlords_0',\n",
       " 'rival warlords_1',\n",
       " 'rival warlords_2',\n",
       " 'ruggedness_mean',\n",
       " 'scanty rainfall_0',\n",
       " 'scanty rainfall_1',\n",
       " 'scanty rainfall_2',\n",
       " 'secession_0',\n",
       " 'secession_1',\n",
       " 'secession_2',\n",
       " 'self reliance_0',\n",
       " 'self reliance_1',\n",
       " 'self reliance_2',\n",
       " 'severe rains_0',\n",
       " 'severe rains_1',\n",
       " 'severe rains_2',\n",
       " 'shortage of rains_0',\n",
       " 'shortage of rains_1',\n",
       " 'shortage of rains_2',\n",
       " 'siege_0',\n",
       " 'siege_1',\n",
       " 'siege_2',\n",
       " 'slashed export_0',\n",
       " 'slashed export_1',\n",
       " 'slashed export_2',\n",
       " 'slave trade_0',\n",
       " 'slave trade_1',\n",
       " 'slave trade_2',\n",
       " 'stolen food aid_0',\n",
       " 'stolen food aid_1',\n",
       " 'stolen food aid_2',\n",
       " 'terrorism_0',\n",
       " 'terrorism_1',\n",
       " 'terrorism_2',\n",
       " 'terrorist_0',\n",
       " 'terrorist_1',\n",
       " 'terrorist_2',\n",
       " 'the offensive_0',\n",
       " 'the offensive_1',\n",
       " 'the offensive_2',\n",
       " 'toll on livestock_0',\n",
       " 'toll on livestock_1',\n",
       " 'toll on livestock_2',\n",
       " 'totalitarian_0',\n",
       " 'totalitarian_1',\n",
       " 'totalitarian_2',\n",
       " 'tragedy_0',\n",
       " 'tragedy_1',\n",
       " 'tragedy_2',\n",
       " 'transport bottleneck_0',\n",
       " 'transport bottleneck_1',\n",
       " 'transport bottleneck_2',\n",
       " 'unable to sow_0',\n",
       " 'unable to sow_1',\n",
       " 'unable to sow_2',\n",
       " 'violent suppression_0',\n",
       " 'violent suppression_1',\n",
       " 'violent suppression_2',\n",
       " 'warlord_0',\n",
       " 'warlord_1',\n",
       " 'warlord_2',\n",
       " 'water availability_0',\n",
       " 'water availability_1',\n",
       " 'water availability_2',\n",
       " 'water distribution shortages_0',\n",
       " 'water distribution shortages_1',\n",
       " 'water distribution shortages_2',\n",
       " 'weather extremes_0',\n",
       " 'weather extremes_1',\n",
       " 'weather extremes_2',\n",
       " 'withheld relief_0',\n",
       " 'withheld relief_1',\n",
       " 'withheld relief_2',\n",
       " 'without international aid_0',\n",
       " 'without international aid_1',\n",
       " 'without international aid_2',\n",
       " 'wreaked havoc_0',\n",
       " 'wreaked havoc_1',\n",
       " 'wreaked havoc_2',\n",
       " 'year',\n",
       " 'year_month',\n",
       " 'years of warfare_0',\n",
       " 'years of warfare_1',\n",
       " 'years of warfare_2']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>centx</th>\n",
       "      <th>centy</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon_2</th>\n",
       "      <th>mayhem_0</th>\n",
       "      <th>mayhem_1</th>\n",
       "      <th>mayhem_2</th>\n",
       "      <th>dehydrated_0</th>\n",
       "      <th>dehydrated_1</th>\n",
       "      <th>dehydrated_2</th>\n",
       "      <th>mismanagement_0</th>\n",
       "      <th>mismanagement_1</th>\n",
       "      <th>mismanagement_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>-0.171000</td>\n",
       "      <td>-0.833000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>1.284667</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>-0.427667</td>\n",
       "      <td>0.668333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660812</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.520247</td>\n",
       "      <td>-0.782913</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.612254</td>\n",
       "      <td>-0.926921</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>-0.625133</td>\n",
       "      <td>-0.452467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.844333</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>-0.689667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>-0.471333</td>\n",
       "      <td>0.955333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326927</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>0.164790</td>\n",
       "      <td>-0.905210</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-0.810600</td>\n",
       "      <td>-0.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.085146</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.867913</td>\n",
       "      <td>-0.770247</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.974587</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>-0.709800</td>\n",
       "      <td>-0.622800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index      country  admin_code admin_name      centx  \\\n",
       "0           0     30  Afghanistan         202   Kandahar  65.709343   \n",
       "1           1     33  Afghanistan         202   Kandahar  65.709343   \n",
       "2           2     36  Afghanistan         202   Kandahar  65.709343   \n",
       "3           3     39  Afghanistan         202   Kandahar  65.709343   \n",
       "4           4     42  Afghanistan         202   Kandahar  65.709343   \n",
       "\n",
       "       centy year_month  year  month  ...  carbon_2  mayhem_0  mayhem_1  \\\n",
       "0  31.043618    2009_07  2009      7  ...  1.053000  0.667000 -0.171000   \n",
       "1  31.043618    2009_10  2009     10  ... -0.660812 -0.636580 -0.520247   \n",
       "2  31.043618    2010_01  2010      1  ... -0.134333  1.447667 -0.844333   \n",
       "3  31.043618    2010_04  2010      4  ... -0.326927 -0.594877  0.164790   \n",
       "4  31.043618    2010_07  2010      7  ... -1.085146 -0.709913 -0.867913   \n",
       "\n",
       "   mayhem_2  dehydrated_0  dehydrated_1  dehydrated_2  mismanagement_0  \\\n",
       "0 -0.833000      0.173667      0.168000      1.284667        -0.073000   \n",
       "1 -0.782913     -0.671587     -0.612254     -0.926921        -0.510467   \n",
       "2  0.778667     -0.676000     -0.689667      0.293333         0.530333   \n",
       "3 -0.905210     -0.620540      0.165794      0.045794        -1.011600   \n",
       "4 -0.770247     -0.787921     -0.974587     -0.946921        -0.611133   \n",
       "\n",
       "   mismanagement_1  mismanagement_2  \n",
       "0        -0.427667         0.668333  \n",
       "1        -0.625133        -0.452467  \n",
       "2        -0.471333         0.955333  \n",
       "3        -0.810600        -0.205600  \n",
       "4        -0.709800        -0.622800  \n",
       "\n",
       "[5 rows x 532 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = ['ndvi_mean', 'ndvi_anom', 'rain_mean', 'rain_anom', 'et_mean', 'et_anom', \n",
    "                                    'acled_count', 'acled_fatalities', 'p_staple_food']\n",
    "t_invariant_traditional_factors = ['area', 'cropland_pct', 'pop', 'ruggedness_mean', 'pasture_pct']\n",
    "\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'land seizures_0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count BEFORE dropping:  532\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count BEFORE dropping: \", len(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"Unnamed: 0\", \"centx\", \"centy\", 'change_fews', 'fews_ha', 'fews_proj_med', 'fews_proj_med_ha', 'fews_proj_near_ha'] + [col for col in time_series.columns if col.endswith(('_1', '_2', '_3'))]\n",
    "time_series.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential extra columns ['index', 'admin_code', 'year', 'fews_proj_near', 'month', 'country', 'admin_name', 'fews_ipc']\n"
     ]
    }
   ],
   "source": [
    "potential_extra_cols = set(time_series.columns.values) - set(t_variant_traditional_factors) - set(t_invariant_traditional_factors) - set(news_factors)\n",
    "potential_extra_cols = [col for col in potential_extra_cols if not col.endswith(('_1', '_2', '_3'))]\n",
    "print(\"Potential extra columns\", potential_extra_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count after dropping:  189\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count after dropping: \", len(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Columns names after dropping: \", sorted(time_series.columns.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🌍 Admin Level Mapping: Standardizing Geographical Identifiers\n",
    "\n",
    "In this section, we will **map and standardize** the `admin_code` and `admin_name` fields to their corresponding **district, province, and country names**. This step is **crucial** for ensuring **consistency** across different datasets and enabling **accurate aggregations** at multiple administrative levels.\n",
    "\n",
    "🛠 **Why is Admin Level Mapping Important?**\n",
    "✅ Different datasets may use **slightly different spellings or formats** for district names.  \n",
    "✅ Some district names might be **missing or misspelled**, requiring standardization.  \n",
    "✅ We need to **match and align** district names across various sources before aggregating at **province and country levels**.  \n",
    "✅ Proper mapping allows us to **merge datasets correctly** without losing information.  \n",
    "\n",
    "📌 **Steps in Admin Mapping**\n",
    "1️⃣ **Load the `matching_districts.csv` file**, which provides the mapping between different district name variations.  \n",
    "2️⃣ **Identify missing or unmatched `admin_name` values** and find their closest matches using fuzzy matching techniques.  \n",
    "3️⃣ **Ensure that each `admin_code` uniquely maps to one `district`, `province`, and `country`.**  \n",
    "4️⃣ **Replace inconsistent names** in the dataset with their standardized versions.  \n",
    "5️⃣ **Aggregate data at the `province` and `country` levels** after ensuring all districts are correctly mapped.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(admins.country.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'country', 'district', 'year', 'month', 'CS',\n",
       "       'province'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admins.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142 4113 474 39\n",
      "369\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy String Matching for Missing Names\n",
    "\n",
    "The function uses **fuzzy string matching** to find the best approximate matches for missing administrative names (e.g., districts and provinces). \n",
    "\n",
    "- Finds the **best matching district/province** for each missing name.\n",
    "- Uses **fuzzy string matching** to calculate the similarity between missing names and known names.\n",
    "- Returns a dictionary that maps each missing name to its closest match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamashkorieb Hamashkoreib Ghor\n",
      "North Shewa(R3) North Shewa North\n",
      "Sowdari Sodari Bari\n",
      "Lac-Léré Lac-Lere Lac\n",
      "East al Gazera Ganze Gaza\n",
      "Banadir Dandi Banaadir\n",
      "Special Woreda Borena Nord\n",
      "Sud-Kivu Kiru Sud\n",
      "UMP Bench Maji Unity\n",
      "Illéla Illela Sila\n",
      "Ad Dinder Ad Dis Zinder\n",
      "Merawi Marawi Mara\n",
      "Al Fasher El Fasher Al Mahrah\n",
      "Jebrat al Sheikh Jebrat El Sheikh Herat\n",
      "Al Kurumik Qulansiyah wa `Abd Al Kuri Ituri\n",
      "Lafon Lopa/Lafon Lac\n",
      "Mayo Binder Mayo-Binder Zinder\n",
      "Al Geneina El Geneina Geita\n",
      "Al Rahd El Rahad Al Mahrah\n",
      "Trou Du Nord Trou du Nord Nord\n",
      "Mt Elgon Mt. Elgon Khatlon\n",
      "Nandi South Nnewi South Nandi\n",
      "Al Faw El Faw Al Jawf\n",
      "Adan Yabaal Aadan Yabaal `Adan\n",
      "Ndjamena Ndia N'Djamena\n",
      "Al Gadaref Gada Gedaref\n",
      "Mbuji-Mayi City of Mbuji-Mayi Bay\n",
      "La Pendé La Pende Lac\n",
      "Shabelle Shebelle Middle Shabelle\n",
      "Al Kamlin Kamuli Kigali\n",
      "Mwingi Mwingi North Migori\n",
      "Ville de Niamey Ndia Niamey\n",
      "Kabkabiya Kebkabiya Abia\n",
      "Kasai.1 Kpaai Kasai\n",
      "Goma City of Goma Oromia\n",
      "Al Fushqa Al Husha' Arusha\n",
      "South Khartoum Khartoum Khartoum\n",
      "Ceca La Source Cerca La Source Sud\n",
      "West Harerge West Hararge West Darfur\n",
      "Djourouf Al Ahmar Sourou Amhara\n",
      "At Ta'izziyah At Ta`izziyah Ta'izz\n",
      "Eastern Tigray Lira Eastern\n",
      "Ad Damer Same Dhamar\n",
      "Tesker Tasker Western Bahr el Ghazal\n",
      "Shar'ab As Salam Shar`ab As Salam Mara\n",
      "La Nya Pendé La Nya Lac\n",
      "Berber Berbera Santa Barbara\n",
      "Kindu City of Kindu Kunduz\n",
      "Kisangani City of Kisangani Tanga\n",
      "Marakwet Marakwet West Elgeyo-Marakwet\n",
      "Um Al Gura Guera Guera\n",
      "Ville de Maradi Maridi Mara\n",
      "Agnuak Awgu Ouaka\n",
      "Tillabéri Tillaberi Commune Tillaberi\n",
      "Tanganyka Tanga Tanga\n",
      "Kajo-keji Kajo-Keji Kano\n",
      "Mutare Mutare Rural Mtwara\n",
      "Teso Teso South El Progreso\n",
      "Nandi North Nnewi North Nandi\n",
      "Lulua Luuka Lualaba\n",
      "Al Ma'afir Al Ma`afir Mara\n",
      "Likasi City of Likasi Laikipia\n",
      "North Gonder North Gondar North\n",
      "Mole Saint Nicolas Mole Saint-Nicolas White Nile\n",
      "Selti Selibaby Copperbelt\n",
      "Wardi Hawar Wadi Hawar Bari\n",
      "Laasqoray Rorya Tabora\n",
      "Khartoum Bahri Khartoum Khartoum\n",
      "Shar'ab Ar Rawnah Shar`ab Ar Rawnah Mara\n",
      "Rachuonyo Karachuonyo Oyo\n",
      "Baydhaba Baydhabo Bay\n",
      "Segen Peoples' Segen Benue\n",
      "Sheikan Shiekan Shinyanga\n",
      "Iriba Nyaribari Masaba Central Equatoria\n",
      "Kibale Kabale Kidal\n",
      "Damagaram Takaya Takaya Mara\n",
      "Nyala.1 Nyala Nyamira\n",
      "Lughaye Lughaya Bay\n",
      "Al Mahagil Mahagi Al Mahrah\n",
      "Meru South Meru Meru\n",
      "Al Gash Al Hashwah Al Mahrah\n",
      "Belet Xaawo Beled-Xaawo Gao\n",
      "Kolwezi City of Kolwezi Jonglei\n",
      "Bale.1 Bale Bay\n",
      "Chegutu Chegutu Rural Hodh ech Chargui\n",
      "North al Gazera Ganze North\n",
      "Anse-D'Ainault `Ain Abia\n",
      "Gokwe South Gokwe South Urban Southern\n",
      "Muranga Mkuranga Murang'a\n",
      "Mangwe (South) Mangwe Southern\n",
      "Téra Tarauni Trans Nzoia\n",
      "Al Jabalian Jaba Al Jawf\n",
      "Mwene-Ditu City of Mwene-Ditu Kitui\n",
      "Koibatek Kibra Kogi\n",
      "Al Galabat Western El Galabat Gaza\n",
      "Ad Damazin El Damazine Adamawa\n",
      "Majang Marangara Mahajanga\n",
      "Taleex Talex Woqooyi Galbeed\n",
      "Thika Thika Town Vihiga\n",
      "Shurugwi Shurugwi Rural Sud\n",
      "Gweru Gweru Rural Meru\n",
      "Mayo Boneye Bo Boke\n",
      "Zvishavane Zvishavane Urban Kanem\n",
      "Kananga nan Haut-Katanga\n",
      "Mbeere Mbeere North Mbeya\n",
      "Abu Jubaiyah Juba Raymah\n",
      "Zallingi Zalingei Singida\n",
      "Karary Karari Kwara\n",
      "Kuria Kuria East Ituri\n",
      "Anse-A-Veau `Ans Lamu\n",
      "Valliere Vallieres Zaire\n",
      "Owdweyne Oodweyne Benue\n",
      "Maragua Maragwa Mara\n",
      "Saint-Raphael Saint Raphael Santa Rosa\n",
      "Butembo City of Butembo Kemo\n",
      "Wadi Halfa Halfa Wadi Fira\n",
      "Port-Au-Prince Port au Prince Ituri\n",
      "Meru Central Meru Central\n",
      "Chipinge Chipinge Rural Uige\n",
      "Ad Douiem El Douiem Ad Dali`\n",
      "Acul Du Nord Acul du Nord Nord\n",
      "Ad Dali' Ad Dali` Ad Dali`\n",
      "Seteet Seme Tete\n",
      "MPongwe Mpongwe Bong\n",
      "Rab Dhuure Rabdhuure Central Darfur\n",
      "Lubumbashi City of Lubumbashi Ruvuma\n",
      "Nord-Kivu Kiru Nord\n",
      "Sheikh Jebrat El Sheikh Sahel\n",
      "Abu Hamad Abu Hamed Hilmand\n",
      "Tulus Tullus Retalhuleu\n",
      "Kwekwe Kwekwe Urban Kwale\n",
      "Hirat Wag Himra Hiiraan\n",
      "Al Gutaina El Gutaina Rutana\n",
      "Id El Ghanem Ganze Kanem\n",
      "Croix-Des-Bouquets Bo Ouest\n",
      "Sharg En Nile Sahar Niger\n",
      "Meru North Meru Meru\n",
      "Siti Sirisia Simiyu\n",
      "Gouré Govuro Ghor\n",
      "Al Deain Doedain Ali Sabieh\n",
      "Sar-e-Pul Sah Sari Pul\n",
      "Port De Paix Port de Paix Pwani\n",
      "Doolo Doolow Sool\n",
      "Mangalmé Mangalme Tanga\n",
      "Butere Mumias Butere Muyinga\n",
      "Bulilima (North) Bulilima North\n",
      "Bukavu City of Bukavu Busia\n",
      "Guji Gujii Guidimaka\n",
      "Amran `Amran `Amran\n",
      "Al Roseires El Roseires Zaire\n",
      "Amanat Al 'Asimah Arsi Amanat Al `Asimah\n",
      "Hwange Hwange Rural Iilemi triangle\n",
      "Grande Riviere Du Nord Grande Riviere du Nord Nord\n",
      "Port-Salut Port Salut Salamat\n",
      "Chiengi Chienge Muchinga\n",
      "Bankilaré Bankilare Sila\n",
      "Bandarbeyla Bandar Beyla Mbeya\n",
      "Filingué Filingue Enugu\n",
      "Chiredzi Chiredzi Rural Moyen-Chari\n",
      "Southern Tigray Lira Tigray\n",
      "South al Gazera Ganze Gaza\n",
      "Burtinle Butinle Iilemi triangle\n",
      "KT Koch Haute-Kotto\n",
      "Tayeeglow Tiyeglow Bay\n",
      "Hareri Harari Harari\n",
      "Baw Bahr El Arab Western Bahr el Ghazal\n",
      "Mashra'ah wa Hadnan nan Kankan\n",
      "Busia.1 Busia Busia\n",
      "Adan Aldai `Adan\n",
      "South Gonder South Gondar South Kordofan\n",
      "Kabia Mambah Kaba Kajiado\n",
      "Barh El Gazel Sud Barh el Gazel Sud Sud\n",
      "Kadoma Kadoma Urban Kano\n",
      "Keiyo Keiyo South Oyo\n",
      "Gothèye Gotheye Gao\n",
      "Nahr Atbara Atbara Mara\n",
      "North Shewa(R4) North Shewa North\n",
      "Barh-Kôh Barh-Koh Bari\n",
      "Um Kadada Um Keddada Kandahar\n",
      "Addis Adaba Alaba Addis Ababa\n",
      "Mawza' Mawza` Gaza\n",
      "Cayes Les Cayes Kayes\n",
      "Gourma-Rharous Gourma Ghor\n",
      "Gebiley Gabiley Blue Nile\n",
      "Sa'dah Sa`dah Sa`dah\n",
      "Western Tigray Lira Western\n",
      "Awi/Agew Awi Uige\n",
      "Komonjdjari Komondjari Bari\n",
      "Al Wazi'iyah Al Wazi`iyah Siaya\n",
      "Belet Weyne Bale Benue\n",
      "Maïné Soroa Maine Soroa Sool\n",
      "Gonave La Gonave Gao\n",
      "En Nuhud Al Nuhud Sud\n",
      "Beni San Benito Benshangul Gumuz\n",
      "Barh El Gazel Ouest Barh el Gazel Ouest Ouest\n",
      "Bulo Burto Burco Borno\n",
      "Um Badda Um Keddada Bay\n",
      "East Harerge East Hararge East Darfur\n",
      "Barh El Gazel Nord Barh el Gazel Nord Nord\n",
      "Gucha Kabuchai Ahuachapan\n",
      "Buret Bureti Blue Nile\n",
      "Caynabo Caynaba Bay\n",
      "Galdogob Goldogob Edo\n",
      "Wedza Dedza Gedaref\n",
      "Belbedji Bielel Abyei\n",
      "Balleyara Bale Mara\n",
      "Ville de Zinder Gile Zinder\n",
      "Al Marawi'ah Marawi Mara\n",
      "Beitbridge Beitbridge Urban Uige\n",
      "Kelem Wellega Kelem Kwale\n",
      "Bindura Bindura Urban Cabinda\n",
      "Kolwezi.1 City of Kolwezi Kwale\n",
      "Addabah Sabah Assaba\n",
      "Bura' Bura Guera\n",
      "Kantché Kantche Kano\n",
      "Bossaso Bo Gao\n",
      "Aguié Aguie Bangui\n",
      "Central Kisii Kiti Central\n",
      "Sharq al Gazera Ganze Gaza\n",
      "Ville de Tahoua Tahoua Tahoua\n",
      "Trans Mara Marka Mara\n",
      "North Western Tigray Lira Western\n",
      "Gedio Gedeo Gedo\n",
      "Kas Kasese Kassala\n",
      "Sami' Sami` Haut-Lomami\n",
      "As Salam Shar`ab As Salam Dar es Salaam\n",
      "Mayo-Lemi Mayo-Lemie Bay\n",
      "Saint Louis Du Nord Saint-Louis du Nord Nord\n",
      "Ghebeish Nesh Abyei\n",
      "Gwanda Gwanda Rural Nyandarua\n"
     ]
    }
   ],
   "source": [
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "\n",
    "# manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Decoding\n",
    "\n",
    "`to_ascii_escaped(s)`: Converts a Unicode string to an ASCII-safe representation using **unicode-escape**.\n",
    "\n",
    "`from_ascii_escaped(escaped)`: Converts the escaped ASCII string back into its original Unicode form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    # Using 'unicode-escape' encoding produces a bytes object,\n",
    "    # then decode it to get an ASCII string.\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def from_ascii_escaped(escaped):\n",
    "    \"\"\"\n",
    "    Convert the ASCII-escaped string back to the original Unicode string.\n",
    "    \"\"\"\n",
    "    # Encode the ASCII string to bytes, then decode using 'unicode-escape'\n",
    "    return escaped.encode('ascii').decode('unicode-escape')\n",
    "\n",
    "# # Test the round-trip on each unique value from valid_matching['missing']:\n",
    "# for m in valid_matching['missing'].unique():\n",
    "#     # Ensure m is a Unicode string\n",
    "#     original = m.decode('utf-8') if isinstance(m, bytes) else m\n",
    "#     # Convert to an ASCII-escaped representation\n",
    "#     encoded = to_ascii_escaped(original)\n",
    "#     # Convert back from the ASCII-escaped representation to Unicode\n",
    "#     decoded = from_ascii_escaped(encoded)\n",
    "    \n",
    "#     # Print the results\n",
    "#     print(\"Original: \", original)\n",
    "#     print(\"Encoded:  \", encoded)\n",
    "#     print(\"Decoded:  \", decoded)\n",
    "#     print(\"Round-trip equal:\", original == decoded)\n",
    "#     print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Province for a Given District or Province\n",
    "\n",
    "`find_province(x)`, finds the **province** corresponding to a given administrative name. It accounts for:\n",
    "- **Direct Lookups** (Exact match in known district/province lists)\n",
    "- **Fuzzy Matching** (Using ASCII-safe transformation for inconsistent text encoding)\n",
    "- **Validation Against a Predefined Mapping (`valid_matching`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matched globally\n",
    "matched = valid_matching['missing'].unique()\n",
    "\n",
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def find_province(x):\n",
    "    try:\n",
    "        # Ensure x is a Unicode string.\n",
    "        if isinstance(x, bytes):\n",
    "            x = x.decode('utf-8')\n",
    "        \n",
    "        # Direct lookup in districts or provinces.\n",
    "        if x in districts:\n",
    "            return admins[admins['district'] == x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "\n",
    "        # Convert x to an ASCII-escaped version.\n",
    "        escaped_x = to_ascii_escaped(x)\n",
    "        \n",
    "        # Check if the escaped version is in matched.\n",
    "        if escaped_x in matched:\n",
    "            v = valid_matching[valid_matching['missing'] == escaped_x]\n",
    "            if v['match'].values[0] == 'district':\n",
    "                x2 = v['district'].values[0]\n",
    "                return admins[admins['district'] == x2]['province'].values[0]\n",
    "            elif v['match'].values[0] == 'province':\n",
    "                return v['province'].values[0]\n",
    "        \n",
    "        # If no conditions are met, raise an exception.\n",
    "        raise Exception(\"No matching province found\")\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Province not found for: {} ({})\".format(x, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Admin Names with Accented Characters and Mapping to Provinces\n",
    "\n",
    "Maps `admin_names` to provinces using the `find_province(a)` function.  \n",
    "If a **direct lookup fails**, it tries to handle cases where the **admin name contains accented characters** (`é`, `è`, `ô`) ->  (encoding decoding issues resolved through directly replacing these with 'e' or 'o', leads to finding a valid match). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with: Mangalmé\n",
      "Replaced 'Mangalmé' with 'Mangalme', found province: Guera\n",
      "Error with: La Pendé\n",
      "Replaced 'La Pendé' with 'La Pende', found province: Logone Oriental\n",
      "Error with: La Nya Pendé\n",
      "Replaced 'La Nya Pendé' with 'La Nya Pende', found province: Logone Oriental\n",
      "Error with: Lac-Léré\n",
      "Replaced 'Lac-Léré' with 'Lac-Lere', found province: Mayo-Kebbi Ouest\n",
      "Error with: Barh-Kôh\n",
      "Replaced 'Barh-Kôh' with 'Barh-Koh', found province: Moyen-Chari\n",
      "Error with: Aguié\n",
      "Replaced 'Aguié' with 'Aguie', found province: Maradi\n",
      "Error with: Bankilaré\n",
      "Replaced 'Bankilaré' with 'Bankilare', found province: Tillaberi\n",
      "Error with: Filingué\n",
      "Replaced 'Filingué' with 'Filingue', found province: Tillaberi\n",
      "Error with: Gothèye\n",
      "Replaced 'Gothèye' with 'Gotheye', found province: Tillaberi\n",
      "Error with: Gouré\n",
      "Replaced 'Gouré' with 'Goure', found province: Zinder\n",
      "Error with: Illéla\n",
      "Replaced 'Illéla' with 'Illela', found province: Sokoto\n",
      "Error with: Kantché\n",
      "Replaced 'Kantché' with 'Kantche', found province: Zinder\n",
      "Error with: Maïné Soroa\n",
      "Modified name 'Maïne Soroa' not in districts.\n",
      "Error with: Téra\n",
      "Replaced 'Téra' with 'Tera', found province: Tillaberi\n",
      "Error with: Tillabéri\n",
      "Replaced 'Tillabéri' with 'Tillaberi', found province: Tillaberi\n"
     ]
    }
   ],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except Exception as e:\n",
    "        # Print the admin name that caused an error\n",
    "        print(\"Error with:\", a)\n",
    "        # Check if a contains accented characters \"é\" or \"è\"\n",
    "        if 'é' in a or 'è' in a or 'ô' in a:\n",
    "            a_modified = a.replace('é', 'e').replace('è', 'e').replace('ô', 'o')\n",
    "            # Check if the modified name is in districts\n",
    "            if a_modified in districts:\n",
    "                # Use the modified name to look up the province from admins\n",
    "                try:\n",
    "                    province = admins[admins['district'] == a_modified]['province'].values[0]\n",
    "                    admin_to_province[a] = province\n",
    "                    print(f\"Replaced '{a}' with '{a_modified}', found province: {province}\")\n",
    "                except Exception as ex:\n",
    "                    print(f\"Modified name '{a_modified}' not found in admins: {ex}\")\n",
    "            else:\n",
    "                print(f\"Modified name '{a_modified}' not in districts.\")\n",
    "        else:\n",
    "            print(f\"No accented e found in '{a}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key is :  Kandahar\n",
      "value is :  Kandahar\n",
      "key is :  Kapisa\n",
      "value is :  Kapisa\n",
      "key is :  Khost\n",
      "value is :  Khost\n",
      "key is :  Kunar\n",
      "value is :  Kunar\n",
      "key is :  Kunduz\n",
      "value is :  Kunduz\n",
      "key is :  Laghman\n",
      "value is :  Laghman\n",
      "key is :  Logar\n",
      "value is :  Logar\n",
      "key is :  Nangarhar\n",
      "value is :  Nangarhar\n",
      "key is :  Paktika\n",
      "value is :  Paktika\n",
      "key is :  Paktya\n",
      "value is :  Paktya\n",
      "key is :  Samangan\n",
      "value is :  Samangan\n",
      "key is :  Sar-e-Pul\n",
      "value is :  Sari Pul\n",
      "key is :  Takhar\n",
      "value is :  Takhar\n",
      "key is :  Wardak\n",
      "value is :  Wardak\n",
      "key is :  Zabul\n",
      "value is :  Zabul\n",
      "key is :  Daykundi\n",
      "value is :  Daykundi\n",
      "key is :  Panjsher\n",
      "value is :  Panjsher\n",
      "key is :  Parwan\n",
      "value is :  Parwan\n",
      "key is :  Uruzgan\n",
      "value is :  Uruzgan\n",
      "key is :  Badakhshan\n",
      "value is :  Badakhshan\n",
      "key is :  Badghis\n",
      "value is :  Badghis\n",
      "key is :  Baghlan\n",
      "value is :  Baghlan\n",
      "key is :  Balkh\n",
      "value is :  Balkh\n",
      "key is :  Bamyan\n",
      "value is :  Bamyan\n",
      "key is :  Farah\n",
      "value is :  Farah\n",
      "key is :  Faryab\n",
      "value is :  Faryab\n",
      "key is :  Ghazni\n",
      "value is :  Ghazni\n",
      "key is :  Ghor\n",
      "value is :  Ghor\n",
      "key is :  Hilmand\n",
      "value is :  Hilmand\n",
      "key is :  Hirat\n",
      "value is :  Herat\n",
      "key is :  Jawzjan\n",
      "value is :  Jawzjan\n",
      "key is :  Kabul\n",
      "value is :  Kabul\n",
      "key is :  Nimroz\n",
      "value is :  Nimroz\n",
      "key is :  Nuristan\n",
      "value is :  Nuristan\n",
      "key is :  Sissili\n",
      "value is :  Centre-Ouest\n",
      "key is :  Ziro\n",
      "value is :  Centre-Ouest\n",
      "key is :  Bazega\n",
      "value is :  Centre-Sud\n",
      "key is :  Nahouri\n",
      "value is :  Centre-Sud\n",
      "key is :  Zoundweogo\n",
      "value is :  Centre-Sud\n",
      "key is :  Gnagna\n",
      "value is :  Est\n",
      "key is :  Gourma\n",
      "value is :  Est\n",
      "key is :  Komonjdjari\n",
      "value is :  Est\n",
      "key is :  Kompienga\n",
      "value is :  Est\n",
      "key is :  Tapoa\n",
      "value is :  Est\n",
      "key is :  Houet\n",
      "value is :  Hauts-Bassins\n",
      "key is :  Kenedougou\n",
      "value is :  Hauts-Bassins\n",
      "key is :  Tuy\n",
      "value is :  Hauts-Bassins\n",
      "key is :  Ioba\n",
      "value is :  Sud-Ouest\n",
      "key is :  Noumbiel\n",
      "value is :  Sud-Ouest\n",
      "key is :  Poni\n",
      "value is :  Sud-Ouest\n",
      "key is :  Banwa\n",
      "value is :  Boucle du Mouhoun\n",
      "key is :  Kossi\n",
      "value is :  Boucle du Mouhoun\n",
      "key is :  Bale\n",
      "value is :  Oromia\n",
      "key is :  Mouhoun\n",
      "value is :  Boucle du Mouhoun\n",
      "key is :  Nayala\n",
      "value is :  Boucle du Mouhoun\n",
      "key is :  Sourou\n",
      "value is :  Boucle du Mouhoun\n",
      "key is :  Comoe\n",
      "value is :  Cascades\n",
      "key is :  Leraba\n",
      "value is :  Cascades\n",
      "key is :  Kadiogo\n",
      "value is :  Centre\n",
      "key is :  Boulgou\n",
      "value is :  Centre-Est\n",
      "key is :  Koulpelogo\n",
      "value is :  Centre-Est\n",
      "key is :  Kouritenga\n",
      "value is :  Centre-Est\n",
      "key is :  Bam\n",
      "value is :  Centre-Nord\n",
      "key is :  Namentenga\n",
      "value is :  Centre-Nord\n",
      "key is :  Sanmatenga\n",
      "value is :  Centre-Nord\n",
      "key is :  Boulkiemde\n",
      "value is :  Centre-Ouest\n",
      "key is :  Sanguie\n",
      "value is :  Centre-Ouest\n",
      "key is :  Loroum\n",
      "value is :  Nord\n",
      "key is :  Passore\n",
      "value is :  Nord\n",
      "key is :  Yatenga\n",
      "value is :  Nord\n",
      "key is :  Zondoma\n",
      "value is :  Nord\n",
      "key is :  Ganzourgou\n",
      "value is :  Plateau Central\n",
      "key is :  Kourweogo\n",
      "value is :  Plateau Central\n",
      "key is :  Oubritenga\n",
      "value is :  Plateau Central\n",
      "key is :  Oudalan\n",
      "value is :  Sahel\n",
      "key is :  Seno\n",
      "value is :  Sahel\n",
      "key is :  Soum\n",
      "value is :  Sahel\n",
      "key is :  Yagha\n",
      "value is :  Sahel\n",
      "key is :  Bougouriba\n",
      "value is :  Sud-Ouest\n",
      "key is :  Dababa\n",
      "value is :  Hadjer-Lamis\n",
      "key is :  Barh El Gazel Nord\n",
      "value is :  Barh el Gazel\n",
      "key is :  Wadi-Bissam\n",
      "value is :  Kanem\n",
      "key is :  Kouh-Ouest\n",
      "value is :  Logone Oriental\n",
      "key is :  Kouh-Est\n",
      "value is :  Logone Oriental\n",
      "key is :  Biltine\n",
      "value is :  Wadi Fira\n",
      "key is :  Megri\n",
      "value is :  Wadi Fira\n",
      "key is :  Barh-Signaka\n",
      "value is :  Guera\n",
      "key is :  Baguirmi\n",
      "value is :  Chari-Baguirmi\n",
      "key is :  Ngourkoussou\n",
      "value is :  Logone Occidental\n",
      "key is :  Dodje\n",
      "value is :  Logone Occidental\n",
      "key is :  Lac Wey\n",
      "value is :  Logone Occidental\n",
      "key is :  Fitri\n",
      "value is :  Batha\n",
      "key is :  Mamdi\n",
      "value is :  Lac\n",
      "key is :  Borkou Yala\n",
      "value is :  Borkou\n",
      "key is :  Fada\n",
      "value is :  Ennedi-Ouest\n",
      "key is :  Gueni\n",
      "value is :  Logone Occidental\n",
      "key is :  Tibesti-Ouest\n",
      "value is :  Tibesti\n",
      "key is :  Dagana\n",
      "value is :  Hadjer-Lamis\n",
      "key is :  Wayi\n",
      "value is :  Lac\n",
      "key is :  Loug-Chari\n",
      "value is :  Chari-Baguirmi\n",
      "key is :  Grande Sido\n",
      "value is :  Moyen-Chari\n",
      "key is :  Dar-Tama\n",
      "value is :  Wadi Fira\n",
      "key is :  Iriba\n",
      "value is :  Kisii\n",
      "key is :  Guera\n",
      "value is :  Guera\n",
      "key is :  Abtouyour\n",
      "value is :  Guera\n",
      "key is :  Mangalmé\n",
      "value is :  Guera\n",
      "key is :  Barh-Azoum\n",
      "value is :  Salamat\n",
      "key is :  Aboudeia\n",
      "value is :  Salamat\n",
      "key is :  Haraze Mangueigne\n",
      "value is :  Salamat\n",
      "key is :  Batha-Est\n",
      "value is :  Batha\n",
      "key is :  Batha-Ouest\n",
      "value is :  Batha\n",
      "key is :  Haraze-Al-Biar\n",
      "value is :  Hadjer-Lamis\n",
      "key is :  Chari\n",
      "value is :  Chari-Baguirmi\n",
      "key is :  La Pendé\n",
      "value is :  Logone Oriental\n",
      "key is :  Mayo Boneye\n",
      "value is :  Mayo-Kebbi Est\n",
      "key is :  Ndjamena\n",
      "value is :  NDjamena\n",
      "key is :  Nord-Kanem\n",
      "value is :  Kanem\n",
      "key is :  Kanem\n",
      "value is :  Kanem\n",
      "key is :  La Nya\n",
      "value is :  Logone Oriental\n",
      "key is :  La Nya Pendé\n",
      "value is :  Logone Oriental\n",
      "key is :  Monts de Lam\n",
      "value is :  Logone Oriental\n",
      "key is :  Djourouf Al Ahmar\n",
      "value is :  Sila\n",
      "key is :  Kabia\n",
      "value is :  Mayo-Kebbi Est\n",
      "key is :  Mont Illi\n",
      "value is :  Mayo-Kebbi Est\n",
      "key is :  Ouara\n",
      "value is :  Ouaddai\n",
      "key is :  Mayo Binder\n",
      "value is :  Mayo-Kebbi Ouest\n",
      "key is :  Lac-Léré\n",
      "value is :  Mayo-Kebbi Ouest\n",
      "key is :  Tandjile-Est\n",
      "value is :  Tandjile\n",
      "key is :  Mayo-Dallah\n",
      "value is :  Mayo-Kebbi Ouest\n",
      "key is :  Mayo-Lemi\n",
      "value is :  Mayo-Kebbi Est\n",
      "key is :  Barh-Kôh\n",
      "value is :  Moyen-Chari\n",
      "key is :  Lac Iro\n",
      "value is :  Moyen-Chari\n",
      "key is :  Mandoul Occidental\n",
      "value is :  Mandoul\n",
      "key is :  Barh-Sara\n",
      "value is :  Mandoul\n",
      "key is :  Mourtcha\n",
      "value is :  Ennedi-Ouest\n",
      "key is :  Mandoul Oriental\n",
      "value is :  Mandoul\n",
      "key is :  Tandjile-Ouest\n",
      "value is :  Tandjile\n",
      "key is :  Tandjile-Centre\n",
      "value is :  Tandjile\n",
      "key is :  Assongha\n",
      "value is :  Ouaddai\n",
      "key is :  Abdi\n",
      "value is :  Ouaddai\n",
      "key is :  Kimiti\n",
      "value is :  Sila\n",
      "key is :  Wardi Hawar\n",
      "value is :  Ennedi-Est\n",
      "key is :  Amdjarass\n",
      "value is :  Ennedi-Est\n",
      "key is :  Tibesti-Est\n",
      "value is :  Tibesti\n",
      "key is :  Borkou\n",
      "value is :  Borkou\n",
      "key is :  Barh El Gazel Sud\n",
      "value is :  Barh el Gazel\n",
      "key is :  Barh El Gazel Ouest\n",
      "value is :  Barh el Gazel\n",
      "key is :  Kananga\n",
      "value is :  Kasai-Central\n",
      "key is :  Lulua\n",
      "value is :  Kasai-Central\n",
      "key is :  Kasai\n",
      "value is :  Kasai\n",
      "key is :  Mbuji-Mayi\n",
      "value is :  Kasai-Oriental\n",
      "key is :  Sankuru\n",
      "value is :  Sankuru\n",
      "key is :  Tshilenge\n",
      "value is :  Kasai-Oriental\n",
      "key is :  Mwene-Ditu\n",
      "value is :  Lomami\n",
      "key is :  Kabinda\n",
      "value is :  Lomami\n",
      "key is :  Haut-Lomami\n",
      "value is :  Haut-Lomami\n",
      "key is :  Haut-Katanga\n",
      "value is :  Haut-Katanga\n",
      "key is :  Kolwezi\n",
      "value is :  Lualaba\n",
      "key is :  Lualaba\n",
      "value is :  Lualaba\n",
      "key is :  Lubumbashi\n",
      "value is :  Haut-Katanga\n",
      "key is :  Tanganyka\n",
      "value is :  Tanga\n",
      "key is :  Likasi\n",
      "value is :  Haut-Katanga\n",
      "key is :  Maniema\n",
      "value is :  Maniema\n",
      "key is :  Kindu\n",
      "value is :  Maniema\n",
      "key is :  Goma\n",
      "value is :  North Kivu\n",
      "key is :  Beni\n",
      "value is :  North Kivu\n",
      "key is :  Butembo\n",
      "value is :  North Kivu\n",
      "key is :  Nord-Kivu\n",
      "value is :  Zanzibar Central/South\n",
      "key is :  Bas-Uele\n",
      "value is :  Bas-Uele\n",
      "key is :  Haut-Uele\n",
      "value is :  Haut-Uele\n",
      "key is :  Ituri\n",
      "value is :  Ituri\n",
      "key is :  Kisangani\n",
      "value is :  Tshopo\n",
      "key is :  Tshopo\n",
      "value is :  Tshopo\n",
      "key is :  Sud-Kivu\n",
      "value is :  Zanzibar Central/South\n",
      "key is :  Bukavu\n",
      "value is :  South Kivu\n",
      "key is :  Kasai.1\n",
      "value is :  Kasai\n",
      "key is :  Kolwezi.1\n",
      "value is :  Lualaba\n",
      "key is :  Addis Adaba\n",
      "value is :  SNNPR\n",
      "key is :  Awi/Agew\n",
      "value is :  Amhara\n",
      "key is :  North Gonder\n",
      "value is :  Amhara\n",
      "key is :  South Wollo\n",
      "value is :  Amhara\n",
      "key is :  Special Woreda\n",
      "value is :  SNNPR\n",
      "key is :  Kemashi\n",
      "value is :  Benshangul Gumuz\n",
      "key is :  Agnuak\n",
      "value is :  Gambela\n",
      "key is :  Majang\n",
      "value is :  Gambela\n",
      "key is :  Nuer\n",
      "value is :  Gambela\n",
      "key is :  Arsi\n",
      "value is :  Oromia\n",
      "key is :  Bale.1\n",
      "value is :  Oromia\n",
      "key is :  East Shewa\n",
      "value is :  Oromia\n",
      "key is :  East Wellega\n",
      "value is :  Oromia\n",
      "key is :  Horo Guduru\n",
      "value is :  Oromia\n",
      "key is :  Ilubabor\n",
      "value is :  Oromia\n",
      "key is :  Kelem Wellega\n",
      "value is :  Oromia\n",
      "key is :  West Arsi\n",
      "value is :  Oromia\n",
      "key is :  West Wellega\n",
      "value is :  Oromia\n",
      "key is :  Bench Maji\n",
      "value is :  SNNPR\n",
      "key is :  Segen Peoples'\n",
      "value is :  SNNPR\n",
      "key is :  Southern Tigray\n",
      "value is :  Northern\n",
      "key is :  Awusi\n",
      "value is :  Afar\n",
      "key is :  Kilbati\n",
      "value is :  Afar\n",
      "key is :  Gabi\n",
      "value is :  Afar\n",
      "key is :  Fanti\n",
      "value is :  Afar\n",
      "key is :  Khari\n",
      "value is :  Afar\n",
      "key is :  East Gojam\n",
      "value is :  Amhara\n",
      "key is :  North Shewa(R3)\n",
      "value is :  Oromia\n",
      "key is :  North Wollo\n",
      "value is :  Amhara\n",
      "key is :  Oromia\n",
      "value is :  Amhara\n",
      "key is :  South Gonder\n",
      "value is :  Amhara\n",
      "key is :  Wag Himra\n",
      "value is :  Amhara\n",
      "key is :  West Gojam\n",
      "value is :  Amhara\n",
      "key is :  Asosa\n",
      "value is :  Benshangul Gumuz\n",
      "key is :  Metekel\n",
      "value is :  Benshangul Gumuz\n",
      "key is :  Dire Dawa\n",
      "value is :  Dire Dawa\n",
      "key is :  Hareri\n",
      "value is :  Harari\n",
      "key is :  Borena\n",
      "value is :  Oromia\n",
      "key is :  East Harerge\n",
      "value is :  Oromia\n",
      "key is :  Guji\n",
      "value is :  Oromia\n",
      "key is :  Jimma\n",
      "value is :  Oromia\n",
      "key is :  North Shewa(R4)\n",
      "value is :  Oromia\n",
      "key is :  South West Shewa\n",
      "value is :  Oromia\n",
      "key is :  West Harerge\n",
      "value is :  Oromia\n",
      "key is :  West Shewa\n",
      "value is :  Oromia\n",
      "key is :  Alaba\n",
      "value is :  SNNPR\n",
      "key is :  Basketo\n",
      "value is :  SNNPR\n",
      "key is :  Dawro\n",
      "value is :  SNNPR\n",
      "key is :  Gamo Gofa\n",
      "value is :  SNNPR\n",
      "key is :  Gedio\n",
      "value is :  SNNPR\n",
      "key is :  Gurage\n",
      "value is :  SNNPR\n",
      "key is :  Hadiya\n",
      "value is :  SNNPR\n",
      "key is :  Keffa\n",
      "value is :  SNNPR\n",
      "key is :  Konta\n",
      "value is :  SNNPR\n",
      "key is :  KT\n",
      "value is :  SNNPR\n",
      "key is :  Selti\n",
      "value is :  SNNPR\n",
      "key is :  Sheka\n",
      "value is :  SNNPR\n",
      "key is :  Sidama\n",
      "value is :  SNNPR\n",
      "key is :  South Omo\n",
      "value is :  SNNPR\n",
      "key is :  Wolayita\n",
      "value is :  SNNPR\n",
      "key is :  Yem\n",
      "value is :  SNNPR\n",
      "key is :  Afder\n",
      "value is :  Somali\n",
      "key is :  Doolo\n",
      "value is :  Gedo\n",
      "key is :  Fafan\n",
      "value is :  Somali\n",
      "key is :  Jarar\n",
      "value is :  Somali\n",
      "key is :  Korahe\n",
      "value is :  Somali\n",
      "key is :  Liben\n",
      "value is :  Somali\n",
      "key is :  Nogob\n",
      "value is :  Somali\n",
      "key is :  Shabelle\n",
      "value is :  Somali\n",
      "key is :  Siti\n",
      "value is :  Somali\n",
      "key is :  Central Tigray\n",
      "value is :  Tigray\n",
      "key is :  Eastern Tigray\n",
      "value is :  Sinnar\n",
      "key is :  North Western Tigray\n",
      "value is :  Tigray\n",
      "key is :  Western Tigray\n",
      "value is :  Tigray\n",
      "key is :  Guatemala\n",
      "value is :  Guatemala\n",
      "key is :  El Progreso\n",
      "value is :  Jutiapa\n",
      "key is :  Sacatepequez\n",
      "value is :  Sacatepequez\n",
      "key is :  Chimaltenango\n",
      "value is :  Chimaltenango\n",
      "key is :  Escuintla\n",
      "value is :  Escuintla\n",
      "key is :  Santa Rosa\n",
      "value is :  Santa Rosa\n",
      "key is :  Solola\n",
      "value is :  Solola\n",
      "key is :  Totonicapan\n",
      "value is :  Totonicapan\n",
      "key is :  Quetzaltenango\n",
      "value is :  Quetzaltenango\n",
      "key is :  Suchitepequez\n",
      "value is :  Suchitepequez\n",
      "key is :  Retalhuleu\n",
      "value is :  Retalhuleu\n",
      "key is :  San Marcos\n",
      "value is :  San Marcos\n",
      "key is :  Huehuetenango\n",
      "value is :  Huehuetenango\n",
      "key is :  Quiche\n",
      "value is :  Quiche\n",
      "key is :  Baja Verapaz\n",
      "value is :  Baja Verapaz\n",
      "key is :  Alta Verapaz\n",
      "value is :  Alta Verapaz\n",
      "key is :  Peten\n",
      "value is :  Peten\n",
      "key is :  Izabal\n",
      "value is :  Izabal\n",
      "key is :  Zacapa\n",
      "value is :  Zacapa\n",
      "key is :  Chiquimula\n",
      "value is :  Chiquimula\n",
      "key is :  Jalapa\n",
      "value is :  Jalapa\n",
      "key is :  Jutiapa\n",
      "value is :  Jutiapa\n",
      "key is :  Dessalines\n",
      "value is :  Artibonite\n",
      "key is :  Gros Morne\n",
      "value is :  Artibonite\n",
      "key is :  Gonaives\n",
      "value is :  Artibonite\n",
      "key is :  Marmelade\n",
      "value is :  Artibonite\n",
      "key is :  Saint-Marc\n",
      "value is :  Artibonite\n",
      "key is :  Ceca La Source\n",
      "value is :  Centre\n",
      "key is :  Hinche\n",
      "value is :  Centre\n",
      "key is :  Lascahobas\n",
      "value is :  Centre\n",
      "key is :  Mirebalais\n",
      "value is :  Centre\n",
      "key is :  Borgne\n",
      "value is :  Nord\n",
      "key is :  Grande Riviere Du Nord\n",
      "value is :  Nord\n",
      "key is :  Acul Du Nord\n",
      "value is :  Nord\n",
      "key is :  Cap Haitien\n",
      "value is :  Nord\n",
      "key is :  Limbe\n",
      "value is :  Nord\n",
      "key is :  Plaisance\n",
      "value is :  Nord\n",
      "key is :  Saint-Raphael\n",
      "value is :  Nord\n",
      "key is :  Fort Liberte\n",
      "value is :  Nord-Est\n",
      "key is :  Trou Du Nord\n",
      "value is :  Nord-Est\n",
      "key is :  Ouanaminthe\n",
      "value is :  Nord-Est\n",
      "key is :  Valliere\n",
      "value is :  Nord-Est\n",
      "key is :  Mole Saint Nicolas\n",
      "value is :  Nord-Ouest\n",
      "key is :  Port De Paix\n",
      "value is :  Nord-Ouest\n",
      "key is :  Saint Louis Du Nord\n",
      "value is :  Nord-Ouest\n",
      "key is :  Croix-Des-Bouquets\n",
      "value is :  Ouest\n",
      "key is :  Arcahaie\n",
      "value is :  Ouest\n",
      "key is :  Gonave\n",
      "value is :  Ouest\n",
      "key is :  Leogane\n",
      "value is :  Ouest\n",
      "key is :  Port-Au-Prince\n",
      "value is :  Ouest\n",
      "key is :  Aquin\n",
      "value is :  Sud\n",
      "key is :  Cayes\n",
      "value is :  Sud\n",
      "key is :  Chardonnieres\n",
      "value is :  Sud\n",
      "key is :  Coteaux\n",
      "value is :  Sud\n",
      "key is :  Port-Salut\n",
      "value is :  Sud\n",
      "key is :  Bainet\n",
      "value is :  Sud-Est\n",
      "key is :  Belle Anse\n",
      "value is :  Sud-Est\n",
      "key is :  Jacmel\n",
      "value is :  Sud-Est\n",
      "key is :  Anse-D'Ainault\n",
      "value is :  Grand'Anse\n",
      "key is :  Corail\n",
      "value is :  Grand'Anse\n",
      "key is :  Jeremie\n",
      "value is :  Grand'Anse\n",
      "key is :  Miragoane\n",
      "value is :  Nippes\n",
      "key is :  Baraderes\n",
      "value is :  Nippes\n",
      "key is :  Anse-A-Veau\n",
      "value is :  Nippes\n",
      "key is :  Kiambu\n",
      "value is :  Kiambu\n",
      "key is :  Kirinyaga\n",
      "value is :  Kirinyaga\n",
      "key is :  Maragua\n",
      "value is :  Murang'a\n",
      "key is :  Muranga\n",
      "value is :  Pwani\n",
      "key is :  Nyandarua\n",
      "value is :  Nyandarua\n",
      "key is :  Nyeri\n",
      "value is :  Nyeri\n",
      "key is :  Thika\n",
      "value is :  Kiambu\n",
      "key is :  Kilifi\n",
      "value is :  Kilifi\n",
      "key is :  Kwale\n",
      "value is :  Kwale\n",
      "key is :  Lamu\n",
      "value is :  Lamu\n",
      "key is :  Malindi\n",
      "value is :  Kilifi\n",
      "key is :  Mombasa\n",
      "value is :  Mombasa\n",
      "key is :  Taita Taveta\n",
      "value is :  Taita Taveta\n",
      "key is :  Tana River\n",
      "value is :  Tana River\n",
      "key is :  Embu\n",
      "value is :  Embu\n",
      "key is :  Isiolo\n",
      "value is :  Isiolo\n",
      "key is :  Kitui\n",
      "value is :  Kitui\n",
      "key is :  Machakos\n",
      "value is :  Machakos\n",
      "key is :  Makueni\n",
      "value is :  Makueni\n",
      "key is :  Marsabit\n",
      "value is :  Marsabit\n",
      "key is :  Mbeere\n",
      "value is :  Embu\n",
      "key is :  Meru Central\n",
      "value is :  Arusha\n",
      "key is :  Meru North\n",
      "value is :  Arusha\n",
      "key is :  Meru South\n",
      "value is :  Arusha\n",
      "key is :  Moyale\n",
      "value is :  Marsabit\n",
      "key is :  Mwingi\n",
      "value is :  Kitui\n",
      "key is :  Tharaka\n",
      "value is :  Tharaka Nithi\n",
      "key is :  Nairobi\n",
      "value is :  Nairobi\n",
      "key is :  Garissa\n",
      "value is :  Garissa\n",
      "key is :  Ijara\n",
      "value is :  Garissa\n",
      "key is :  Mandera\n",
      "value is :  Mandera\n",
      "key is :  Wajir\n",
      "value is :  Wajir\n",
      "key is :  Bondo\n",
      "value is :  Siaya\n",
      "key is :  Central Kisii\n",
      "value is :  Kisii\n",
      "key is :  Gucha\n",
      "value is :  Kisii\n",
      "key is :  Homa Bay\n",
      "value is :  Homa Bay\n",
      "key is :  Kisumu\n",
      "value is :  Kisumu\n",
      "key is :  Kuria\n",
      "value is :  Migori\n",
      "key is :  Migori\n",
      "value is :  Migori\n",
      "key is :  Nyamira\n",
      "value is :  Nyamira\n",
      "key is :  Nyando\n",
      "value is :  Kisumu\n",
      "key is :  Rachuonyo\n",
      "value is :  Homa Bay\n",
      "key is :  Siaya\n",
      "value is :  Siaya\n",
      "key is :  Suba\n",
      "value is :  Homa Bay\n",
      "key is :  Baringo\n",
      "value is :  Baringo\n",
      "key is :  Bomet\n",
      "value is :  Bomet\n",
      "key is :  Buret\n",
      "value is :  Kericho\n",
      "key is :  Kajiado\n",
      "value is :  Kajiado\n",
      "key is :  Keiyo\n",
      "value is :  Elgeyo-Marakwet\n",
      "key is :  Kericho\n",
      "value is :  Kericho\n",
      "key is :  Koibatek\n",
      "value is :  Baringo\n",
      "key is :  Laikipia\n",
      "value is :  Laikipia\n",
      "key is :  Marakwet\n",
      "value is :  Elgeyo-Marakwet\n",
      "key is :  Nakuru\n",
      "value is :  Nakuru\n",
      "key is :  Narok\n",
      "value is :  Narok\n",
      "key is :  Samburu\n",
      "value is :  Samburu\n",
      "key is :  Trans Mara\n",
      "value is :  Murang'a\n",
      "key is :  Trans Nzoia\n",
      "value is :  Trans Nzoia\n",
      "key is :  Turkana\n",
      "value is :  Turkana\n",
      "key is :  Uasin Gishu\n",
      "value is :  Uasin Gishu\n",
      "key is :  West Pokot\n",
      "value is :  West Pokot\n",
      "key is :  Nandi North\n",
      "value is :  Nandi\n",
      "key is :  Nandi South\n",
      "value is :  Nandi\n",
      "key is :  Bungoma\n",
      "value is :  Bungoma\n",
      "key is :  Busia\n",
      "value is :  Eastern\n",
      "key is :  Butere Mumias\n",
      "value is :  Kakamega\n",
      "key is :  Kakamega\n",
      "value is :  Kakamega\n",
      "key is :  Lugari\n",
      "value is :  Kakamega\n",
      "key is :  Mt Elgon\n",
      "value is :  Bungoma\n",
      "key is :  Teso\n",
      "value is :  Busia\n",
      "key is :  Vihiga\n",
      "value is :  Vihiga\n",
      "key is :  Dedza\n",
      "value is :  Central\n",
      "key is :  Dowa\n",
      "value is :  Central\n",
      "key is :  Kasungu\n",
      "value is :  Central\n",
      "key is :  Lilongwe\n",
      "value is :  Central\n",
      "key is :  Mchinji\n",
      "value is :  Central\n",
      "key is :  Nkhotakota\n",
      "value is :  Central\n",
      "key is :  Ntcheu\n",
      "value is :  Central\n",
      "key is :  Ntchisi\n",
      "value is :  Central\n",
      "key is :  Salima\n",
      "value is :  Central\n",
      "key is :  Chitipa\n",
      "value is :  Northern\n",
      "key is :  Karonga\n",
      "value is :  Northern\n",
      "key is :  Mzimba\n",
      "value is :  Northern\n",
      "key is :  Rumphi\n",
      "value is :  Northern\n",
      "key is :  Nkhata Bay\n",
      "value is :  Northern\n",
      "key is :  Blantyre\n",
      "value is :  Southern\n",
      "key is :  Chikwawa\n",
      "value is :  Southern\n",
      "key is :  Chiradzulu\n",
      "value is :  Southern\n",
      "key is :  Mangochi\n",
      "value is :  Southern\n",
      "key is :  Nsanje\n",
      "value is :  Southern\n",
      "key is :  Thyolo\n",
      "value is :  Southern\n",
      "key is :  Zomba\n",
      "value is :  Southern\n",
      "key is :  Balaka\n",
      "value is :  Southern\n",
      "key is :  Machinga\n",
      "value is :  Southern\n",
      "key is :  Mulanje\n",
      "value is :  Southern\n",
      "key is :  Phalombe\n",
      "value is :  Southern\n",
      "key is :  Neno\n",
      "value is :  Southern\n",
      "key is :  Mwanza\n",
      "value is :  Southern\n",
      "key is :  Bamako\n",
      "value is :  Bamako\n",
      "key is :  Tin-Essako\n",
      "value is :  Kidal\n",
      "key is :  Banamba\n",
      "value is :  Koulikoro\n",
      "key is :  Bafoulabe\n",
      "value is :  Kayes\n",
      "key is :  Diema\n",
      "value is :  Kayes\n",
      "key is :  Ansongo\n",
      "value is :  Gao\n",
      "key is :  Bourem\n",
      "value is :  Gao\n",
      "key is :  Gao\n",
      "value is :  Gao\n",
      "key is :  Menaka\n",
      "value is :  Gao\n",
      "key is :  Kita\n",
      "value is :  Kayes\n",
      "key is :  Kayes\n",
      "value is :  Kayes\n",
      "key is :  Nioro\n",
      "value is :  Kayes\n",
      "key is :  Kenieba\n",
      "value is :  Kayes\n",
      "key is :  Yelimane\n",
      "value is :  Kayes\n",
      "key is :  Abeibara\n",
      "value is :  Kidal\n",
      "key is :  Kidal\n",
      "value is :  Kidal\n",
      "key is :  Tessalit\n",
      "value is :  Kidal\n",
      "key is :  Dioila\n",
      "value is :  Koulikoro\n",
      "key is :  Kangaba\n",
      "value is :  Koulikoro\n",
      "key is :  Kolokani\n",
      "value is :  Koulikoro\n",
      "key is :  Koulikoro\n",
      "value is :  Koulikoro\n",
      "key is :  Nara\n",
      "value is :  Koulikoro\n",
      "key is :  Bandiagara\n",
      "value is :  Mopti\n",
      "key is :  Bankass\n",
      "value is :  Mopti\n",
      "key is :  Djenne\n",
      "value is :  Mopti\n",
      "key is :  Douentza\n",
      "value is :  Mopti\n",
      "key is :  Koro\n",
      "value is :  Mopti\n",
      "key is :  Mopti\n",
      "value is :  Mopti\n",
      "key is :  Tenenkou\n",
      "value is :  Mopti\n",
      "key is :  Youwarou\n",
      "value is :  Mopti\n",
      "key is :  Baroueli\n",
      "value is :  Ségou\n",
      "key is :  Bla\n",
      "value is :  Ségou\n",
      "key is :  Macina\n",
      "value is :  Ségou\n",
      "key is :  Niono\n",
      "value is :  Ségou\n",
      "key is :  San\n",
      "value is :  Ségou\n",
      "key is :  Segou\n",
      "value is :  Ségou\n",
      "key is :  Tominian\n",
      "value is :  Ségou\n",
      "key is :  Yorosso\n",
      "value is :  Sikasso\n",
      "key is :  Bougouni\n",
      "value is :  Sikasso\n",
      "key is :  Kadiolo\n",
      "value is :  Sikasso\n",
      "key is :  Dire\n",
      "value is :  Tombouctou\n",
      "key is :  Kolondieba\n",
      "value is :  Sikasso\n",
      "key is :  Koutiala\n",
      "value is :  Sikasso\n",
      "key is :  Sikasso\n",
      "value is :  Sikasso\n",
      "key is :  Gourma-Rharous\n",
      "value is :  Est\n",
      "key is :  Yanfolila\n",
      "value is :  Sikasso\n",
      "key is :  Goundam\n",
      "value is :  Tombouctou\n",
      "key is :  Niafunke\n",
      "value is :  Tombouctou\n",
      "key is :  Tombouctou\n",
      "value is :  Tombouctou\n",
      "key is :  Kati\n",
      "value is :  Zanzibar Central/South\n",
      "key is :  Adrar\n",
      "value is :  Adrar\n",
      "key is :  Assaba\n",
      "value is :  Assaba\n",
      "key is :  Brakna\n",
      "value is :  Brakna\n",
      "key is :  Dakhlet Nouadhibou\n",
      "value is :  Dakhlet Nouadhibou\n",
      "key is :  Gorgol\n",
      "value is :  Gorgol\n",
      "key is :  Guidimaka\n",
      "value is :  Guidimaka\n",
      "key is :  Hodh ech Chargui\n",
      "value is :  Hodh ech Chargui\n",
      "key is :  Hodh el Gharbi\n",
      "value is :  Hodh el Gharbi\n",
      "key is :  Inchiri\n",
      "value is :  Inchiri\n",
      "key is :  Nouakchott\n",
      "value is :  Nouakchott\n",
      "key is :  Tagant\n",
      "value is :  Tagant\n",
      "key is :  Tiris Zemmour\n",
      "value is :  Tiris Zemmour\n",
      "key is :  Trarza\n",
      "value is :  Trarza\n",
      "key is :  Cabo Delgado\n",
      "value is :  Cabo Delgado\n",
      "key is :  Gaza\n",
      "value is :  Gaza\n",
      "key is :  Inhambane\n",
      "value is :  Inhambane\n",
      "key is :  Manica\n",
      "value is :  Manica\n",
      "key is :  Maputo\n",
      "value is :  Maputo\n",
      "key is :  Maputo City\n",
      "value is :  Maputo City\n",
      "key is :  Nampula\n",
      "value is :  Nampula\n",
      "key is :  Niassa\n",
      "value is :  Niassa\n",
      "key is :  Sofala\n",
      "value is :  Sofala\n",
      "key is :  Tete\n",
      "value is :  Tete\n",
      "key is :  Zambezia\n",
      "value is :  Zambezia\n",
      "key is :  Abala\n",
      "value is :  Tillaberi\n",
      "key is :  Abalak\n",
      "value is :  Tahoua\n",
      "key is :  Aderbissinat\n",
      "value is :  Agadez\n",
      "key is :  Aguié\n",
      "value is :  Maradi\n",
      "key is :  Arlit\n",
      "value is :  Agadez\n",
      "key is :  Ayerou\n",
      "value is :  Tillaberi\n",
      "key is :  Bagaroua\n",
      "value is :  Tahoua\n",
      "key is :  Balleyara\n",
      "value is :  Tillaberi\n",
      "key is :  Banibangou\n",
      "value is :  Tillaberi\n",
      "key is :  Bankilaré\n",
      "value is :  Tillaberi\n",
      "key is :  Belbedji\n",
      "value is :  Zinder\n",
      "key is :  Bermo\n",
      "value is :  Maradi\n",
      "key is :  Bilma\n",
      "value is :  Agadez\n",
      "key is :  Birni N'Konni\n",
      "value is :  Tahoua\n",
      "key is :  Boboye\n",
      "value is :  Dosso\n",
      "key is :  Bosso\n",
      "value is :  Niger\n",
      "key is :  Bouza\n",
      "value is :  Tahoua\n",
      "key is :  Dakoro\n",
      "value is :  Maradi\n",
      "key is :  Damagaram Takaya\n",
      "value is :  Zinder\n",
      "key is :  Diffa\n",
      "value is :  Diffa\n",
      "key is :  Dioundiou\n",
      "value is :  Dosso\n",
      "key is :  Dogondoutchi\n",
      "value is :  Dosso\n",
      "key is :  Dosso\n",
      "value is :  Dosso\n",
      "key is :  Dungass\n",
      "value is :  Zinder\n",
      "key is :  Falmey\n",
      "value is :  Dosso\n",
      "key is :  Filingué\n",
      "value is :  Tillaberi\n",
      "key is :  Gaya\n",
      "value is :  Dosso\n",
      "key is :  Gazaoua\n",
      "value is :  Maradi\n",
      "key is :  Gothèye\n",
      "value is :  Tillaberi\n",
      "key is :  Goudoumaria\n",
      "value is :  Diffa\n",
      "key is :  Gouré\n",
      "value is :  Zinder\n",
      "key is :  Guidan Roumdji\n",
      "value is :  Maradi\n",
      "key is :  Iferouane\n",
      "value is :  Agadez\n",
      "key is :  Illéla\n",
      "value is :  Sokoto\n",
      "key is :  Ingall\n",
      "value is :  Agadez\n",
      "key is :  Kantché\n",
      "value is :  Zinder\n",
      "key is :  Keita\n",
      "value is :  Tahoua\n",
      "key is :  Kollo\n",
      "value is :  Tillaberi\n",
      "key is :  Loga\n",
      "value is :  Dosso\n",
      "key is :  Madaoua\n",
      "value is :  Tahoua\n",
      "key is :  Madarounfa\n",
      "value is :  Maradi\n",
      "key is :  Magaria\n",
      "value is :  Zinder\n",
      "key is :  Malbaza\n",
      "value is :  Tahoua\n",
      "key is :  Ville de Maradi\n",
      "value is :  Western Equatoria\n",
      "key is :  Mayahi\n",
      "value is :  Maradi\n",
      "key is :  Mirriah\n",
      "value is :  Zinder\n",
      "key is :  N'Gourti\n",
      "value is :  Diffa\n",
      "key is :  N'Guigmi\n",
      "value is :  Diffa\n",
      "key is :  Ville de Niamey\n",
      "value is :  Niamey\n",
      "key is :  Ouallam\n",
      "value is :  Tillaberi\n",
      "key is :  Say\n",
      "value is :  Tillaberi\n",
      "key is :  Tahoua\n",
      "value is :  Tahoua\n",
      "key is :  Takeita\n",
      "value is :  Zinder\n",
      "key is :  Tanout\n",
      "value is :  Zinder\n",
      "key is :  Tassara\n",
      "value is :  Tahoua\n",
      "key is :  Tchintabaraden\n",
      "value is :  Tahoua\n",
      "key is :  Tchirozerine\n",
      "value is :  Agadez\n",
      "key is :  Téra\n",
      "value is :  Tillaberi\n",
      "key is :  Tesker\n",
      "value is :  Zinder\n",
      "key is :  Tessaoua\n",
      "value is :  Maradi\n",
      "key is :  Tibiri\n",
      "value is :  Dosso\n",
      "key is :  Tillabéri\n",
      "value is :  Tillaberi\n",
      "key is :  Tillia\n",
      "value is :  Tahoua\n",
      "key is :  Torodi\n",
      "value is :  Tillaberi\n",
      "key is :  Ville de Tahoua\n",
      "value is :  Tahoua\n",
      "key is :  Ville de Zinder\n",
      "value is :  Zinder\n",
      "key is :  Abia\n",
      "value is :  Abia\n",
      "key is :  Demsa\n",
      "value is :  Adamawa\n",
      "key is :  Fufore\n",
      "value is :  Adamawa\n",
      "key is :  Ganye\n",
      "value is :  Adamawa\n",
      "key is :  Girei\n",
      "value is :  Adamawa\n",
      "key is :  Gombi\n",
      "value is :  Adamawa\n",
      "key is :  Guyuk\n",
      "value is :  Adamawa\n",
      "key is :  Hong\n",
      "value is :  Adamawa\n",
      "key is :  Jada\n",
      "value is :  Adamawa\n",
      "key is :  Lamurde\n",
      "value is :  Adamawa\n",
      "key is :  Madagali\n",
      "value is :  Adamawa\n",
      "key is :  Maiha\n",
      "value is :  Adamawa\n",
      "key is :  Mayo-Belwa\n",
      "value is :  Adamawa\n",
      "key is :  Michika\n",
      "value is :  Adamawa\n",
      "key is :  Mubi North\n",
      "value is :  Adamawa\n",
      "key is :  Mubi South\n",
      "value is :  Adamawa\n",
      "key is :  Numan\n",
      "value is :  Adamawa\n",
      "key is :  Shelleng\n",
      "value is :  Adamawa\n",
      "key is :  Song\n",
      "value is :  Adamawa\n",
      "key is :  Toungo\n",
      "value is :  Adamawa\n",
      "key is :  Yola North\n",
      "value is :  Adamawa\n",
      "key is :  Yola South\n",
      "value is :  Adamawa\n",
      "key is :  Akwa Ibom\n",
      "value is :  Akwa Ibom\n",
      "key is :  Anambra\n",
      "value is :  Anambra\n",
      "key is :  Bauchi\n",
      "value is :  Bauchi\n",
      "key is :  Bayelsa\n",
      "value is :  Bayelsa\n",
      "key is :  Benue\n",
      "value is :  Benue\n",
      "key is :  Abadam\n",
      "value is :  Borno\n",
      "key is :  Askira/Uba\n",
      "value is :  Borno\n",
      "key is :  Bama\n",
      "value is :  Borno\n",
      "key is :  Bayo\n",
      "value is :  Borno\n",
      "key is :  Biu\n",
      "value is :  Borno\n",
      "key is :  Chibok\n",
      "value is :  Borno\n",
      "key is :  Damboa\n",
      "value is :  Borno\n",
      "key is :  Dikwa\n",
      "value is :  Borno\n",
      "key is :  Gubio\n",
      "value is :  Borno\n",
      "key is :  Guzamala\n",
      "value is :  Borno\n",
      "key is :  Gwoza\n",
      "value is :  Borno\n",
      "key is :  Hawul\n",
      "value is :  Borno\n",
      "key is :  Jere\n",
      "value is :  Borno\n",
      "key is :  Kaga\n",
      "value is :  Borno\n",
      "key is :  Kala/Balge\n",
      "value is :  Borno\n",
      "key is :  Konduga\n",
      "value is :  Borno\n",
      "key is :  Kukawa\n",
      "value is :  Borno\n",
      "key is :  Kwaya Kusar\n",
      "value is :  Borno\n",
      "key is :  Mafa\n",
      "value is :  Borno\n",
      "key is :  Magumeri\n",
      "value is :  Borno\n",
      "key is :  Maiduguri\n",
      "value is :  Borno\n",
      "key is :  Marte\n",
      "value is :  Borno\n",
      "key is :  Mobbar\n",
      "value is :  Borno\n",
      "key is :  Monguno\n",
      "value is :  Borno\n",
      "key is :  Ngala\n",
      "value is :  Borno\n",
      "key is :  Nganzai\n",
      "value is :  Borno\n",
      "key is :  Shani\n",
      "value is :  Borno\n",
      "key is :  Cross River\n",
      "value is :  Cross River\n",
      "key is :  Delta\n",
      "value is :  Delta\n",
      "key is :  Ebonyi\n",
      "value is :  Ebonyi\n",
      "key is :  Edo\n",
      "value is :  Edo\n",
      "key is :  Ekiti\n",
      "value is :  Kwara\n",
      "key is :  Enugu\n",
      "value is :  Enugu\n",
      "key is :  Federal Capital Territory\n",
      "value is :  Federal Capital Territory\n",
      "key is :  Gombe\n",
      "value is :  Gombe\n",
      "key is :  Imo\n",
      "value is :  Imo\n",
      "key is :  Jigawa\n",
      "value is :  Jigawa\n",
      "key is :  Kaduna\n",
      "value is :  Kaduna\n",
      "key is :  Kano\n",
      "value is :  Kano\n",
      "key is :  Katsina\n",
      "value is :  Katsina\n",
      "key is :  Kebbi\n",
      "value is :  Kebbi\n",
      "key is :  Kogi\n",
      "value is :  Kogi\n",
      "key is :  Kwara\n",
      "value is :  Kwara\n",
      "key is :  Lagos\n",
      "value is :  Lagos\n",
      "key is :  Nasarawa\n",
      "value is :  Nasarawa\n",
      "key is :  Niger\n",
      "value is :  Niger\n",
      "key is :  Ogun\n",
      "value is :  Ogun\n",
      "key is :  Ondo\n",
      "value is :  Ondo\n",
      "key is :  Osun\n",
      "value is :  Osun\n",
      "key is :  Oyo\n",
      "value is :  Oyo\n",
      "key is :  Plateau\n",
      "value is :  Plateau\n",
      "key is :  Rivers\n",
      "value is :  Rivers\n",
      "key is :  Sokoto\n",
      "value is :  Sokoto\n",
      "key is :  Taraba\n",
      "value is :  Taraba\n",
      "key is :  Bade\n",
      "value is :  Yobe\n",
      "key is :  Bursari\n",
      "value is :  Yobe\n",
      "key is :  Damaturu\n",
      "value is :  Yobe\n",
      "key is :  Fika\n",
      "value is :  Yobe\n",
      "key is :  Fune\n",
      "value is :  Yobe\n",
      "key is :  Geidam\n",
      "value is :  Yobe\n",
      "key is :  Gujba\n",
      "value is :  Yobe\n",
      "key is :  Gulani\n",
      "value is :  Yobe\n",
      "key is :  Jakusko\n",
      "value is :  Yobe\n",
      "key is :  Karasuwa\n",
      "value is :  Yobe\n",
      "key is :  Machina\n",
      "value is :  Yobe\n",
      "key is :  Nangere\n",
      "value is :  Yobe\n",
      "key is :  Nguru\n",
      "value is :  Yobe\n",
      "key is :  Potiskum\n",
      "value is :  Yobe\n",
      "key is :  Tarmuwa\n",
      "value is :  Yobe\n",
      "key is :  Yunusari\n",
      "value is :  Yobe\n",
      "key is :  Yusufari\n",
      "value is :  Yobe\n",
      "key is :  Zamfara\n",
      "value is :  Zamfara\n",
      "key is :  Qardho\n",
      "value is :  Bari\n",
      "key is :  Baydhaba\n",
      "value is :  Bay\n",
      "key is :  Buur Hakaba\n",
      "value is :  Bay\n",
      "key is :  Diinsoor\n",
      "value is :  Bay\n",
      "key is :  Qansax Dheere\n",
      "value is :  Bay\n",
      "key is :  Garbahaarey\n",
      "value is :  Gedo\n",
      "key is :  Bulo Burto\n",
      "value is :  Hiiraan\n",
      "key is :  Jalalaqsi\n",
      "value is :  Hiiraan\n",
      "key is :  Tayeeglow\n",
      "value is :  Bakool\n",
      "key is :  Waajid\n",
      "value is :  Bakool\n",
      "key is :  Xudur\n",
      "value is :  Bakool\n",
      "key is :  Ceel Buur\n",
      "value is :  Galgaduud\n",
      "key is :  Dhuusamarreeb\n",
      "value is :  Galgaduud\n",
      "key is :  Kurtunwaarey\n",
      "value is :  Lower Shabelle\n",
      "key is :  Qoryooley\n",
      "value is :  Lower Shabelle\n",
      "key is :  Sablaale\n",
      "value is :  Lower Shabelle\n",
      "key is :  Wanla Weyn\n",
      "value is :  Lower Shabelle\n",
      "key is :  Bu'aale\n",
      "value is :  Middle Juba\n",
      "key is :  Saakow\n",
      "value is :  Middle Juba\n",
      "key is :  Garoowe\n",
      "value is :  Nugaal\n",
      "key is :  Sheikh\n",
      "value is :  North Kordofan\n",
      "key is :  Jowhar\n",
      "value is :  Middle Shabelle\n",
      "key is :  Caynabo\n",
      "value is :  Sool\n",
      "key is :  Laas Caanood\n",
      "value is :  Sool\n",
      "key is :  Taleex\n",
      "value is :  Sool\n",
      "key is :  Xudun\n",
      "value is :  Sool\n",
      "key is :  Banadir\n",
      "value is :  Banaadir\n",
      "key is :  Cabudwaaq\n",
      "value is :  Galgaduud\n",
      "key is :  Cadaado\n",
      "value is :  Galgaduud\n",
      "key is :  Jamaame\n",
      "value is :  Lower Juba\n",
      "key is :  Baardheere\n",
      "value is :  Gedo\n",
      "key is :  Belet Xaawo\n",
      "value is :  Gedo\n",
      "key is :  Ceel Waaq\n",
      "value is :  Gedo\n",
      "key is :  Afgooye\n",
      "value is :  Lower Shabelle\n",
      "key is :  Marka\n",
      "value is :  Lower Shabelle\n",
      "key is :  Gaalkacyo\n",
      "value is :  Mudug\n",
      "key is :  Galdogob\n",
      "value is :  Mudug\n",
      "key is :  Hobyo\n",
      "value is :  Mudug\n",
      "key is :  Jariiban\n",
      "value is :  Mudug\n",
      "key is :  Xarardheere\n",
      "value is :  Mudug\n",
      "key is :  Burtinle\n",
      "value is :  Nugaal\n",
      "key is :  Baki\n",
      "value is :  Awdal\n",
      "key is :  Borama\n",
      "value is :  Awdal\n",
      "key is :  Iskushuban\n",
      "value is :  Bari\n",
      "key is :  Qandala\n",
      "value is :  Bari\n",
      "key is :  Doolow\n",
      "value is :  Gedo\n",
      "key is :  Luuq\n",
      "value is :  Gedo\n",
      "key is :  Belet Weyne\n",
      "value is :  Hiiraan\n",
      "key is :  Afmadow\n",
      "value is :  Lower Juba\n",
      "key is :  Badhaadhe\n",
      "value is :  Lower Juba\n",
      "key is :  Lughaye\n",
      "value is :  Awdal\n",
      "key is :  Zeylac\n",
      "value is :  Awdal\n",
      "key is :  Ceel Barde\n",
      "value is :  Bakool\n",
      "key is :  Rab Dhuure\n",
      "value is :  Bakool\n",
      "key is :  Bandarbeyla\n",
      "value is :  Bari\n",
      "key is :  Bossaso\n",
      "value is :  Niger\n",
      "key is :  Caluula\n",
      "value is :  Bari\n",
      "key is :  Kismaayo\n",
      "value is :  Lower Juba\n",
      "key is :  Ceel Dheer\n",
      "value is :  Galgaduud\n",
      "key is :  Baraawe\n",
      "value is :  Lower Shabelle\n",
      "key is :  Jilib\n",
      "value is :  Middle Juba\n",
      "key is :  Adan Yabaal\n",
      "value is :  Middle Shabelle\n",
      "key is :  Balcad\n",
      "value is :  Middle Shabelle\n",
      "key is :  Burco\n",
      "value is :  Togdheer\n",
      "key is :  Buuhoodle\n",
      "value is :  Togdheer\n",
      "key is :  Owdweyne\n",
      "value is :  Togdheer\n",
      "key is :  Berbera\n",
      "value is :  Woqooyi Galbeed\n",
      "key is :  Gebiley\n",
      "value is :  Woqooyi Galbeed\n",
      "key is :  Hargeysa\n",
      "value is :  Woqooyi Galbeed\n",
      "key is :  Cadale\n",
      "value is :  Middle Shabelle\n",
      "key is :  Eyl\n",
      "value is :  Nugaal\n",
      "key is :  Laasqoray\n",
      "value is :  Sanaag\n",
      "key is :  Ceel Afweyn\n",
      "value is :  Sanaag\n",
      "key is :  Ceerigaabo\n",
      "value is :  Sanaag\n",
      "key is :  Bor South\n",
      "value is :  Jonglei\n",
      "key is :  Jur River\n",
      "value is :  Western Bahr el Ghazal\n",
      "key is :  Aweil North\n",
      "value is :  Northern Bahr el Ghazal\n",
      "key is :  Morobo\n",
      "value is :  Central Equatoria\n",
      "key is :  Magwi\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Kajo-keji\n",
      "value is :  Central Equatoria\n",
      "key is :  Ikotos\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Yei\n",
      "value is :  Central Equatoria\n",
      "key is :  Yambio\n",
      "value is :  Western Equatoria\n",
      "key is :  Ibba\n",
      "value is :  Western Equatoria\n",
      "key is :  Lainya\n",
      "value is :  Central Equatoria\n",
      "key is :  Maridi\n",
      "value is :  Western Equatoria\n",
      "key is :  Nzara\n",
      "value is :  Western Equatoria\n",
      "key is :  Kapoeta South\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Budi\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Torit\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Juba\n",
      "value is :  Central Equatoria\n",
      "key is :  Mundri West\n",
      "value is :  Western Equatoria\n",
      "key is :  Mundri East\n",
      "value is :  Western Equatoria\n",
      "key is :  Kapoeta North\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Lafon\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Kapoeta East\n",
      "value is :  Eastern Equatoria\n",
      "key is :  Ezo\n",
      "value is :  Western Equatoria\n",
      "key is :  Terekeka\n",
      "value is :  Central Equatoria\n",
      "key is :  Mvolo\n",
      "value is :  Western Equatoria\n",
      "key is :  Awerial\n",
      "value is :  Lakes\n",
      "key is :  Nagero\n",
      "value is :  Western Equatoria\n",
      "key is :  Yirol West\n",
      "value is :  Lakes\n",
      "key is :  Tambura\n",
      "value is :  Western Equatoria\n",
      "key is :  Wau\n",
      "value is :  Western Bahr el Ghazal\n",
      "key is :  Pibor\n",
      "value is :  Jonglei\n",
      "key is :  Wulu\n",
      "value is :  Lakes\n",
      "key is :  Rumbek East\n",
      "value is :  Lakes\n",
      "key is :  Yirol East\n",
      "value is :  Lakes\n",
      "key is :  Rumbek Centre\n",
      "value is :  Lakes\n",
      "key is :  Twic East\n",
      "value is :  Jonglei\n",
      "key is :  Cueibet\n",
      "value is :  Lakes\n",
      "key is :  Pochalla\n",
      "value is :  Jonglei\n",
      "key is :  Tonj South\n",
      "value is :  Warrap\n",
      "key is :  Rumbek North\n",
      "value is :  Lakes\n",
      "key is :  Akobo\n",
      "value is :  Jonglei\n",
      "key is :  Panyijiar\n",
      "value is :  Unity\n",
      "key is :  Duk\n",
      "value is :  Jonglei\n",
      "key is :  Tonj East\n",
      "value is :  Warrap\n",
      "key is :  Uror\n",
      "value is :  Jonglei\n",
      "key is :  Ulang\n",
      "value is :  Upper Nile\n",
      "key is :  Luakpiny/Nasir\n",
      "value is :  Upper Nile\n",
      "key is :  Leer\n",
      "value is :  Unity\n",
      "key is :  Mayendit\n",
      "value is :  Unity\n",
      "key is :  Maiwut\n",
      "value is :  Upper Nile\n",
      "key is :  Ayod\n",
      "value is :  Jonglei\n",
      "key is :  Tonj North\n",
      "value is :  Warrap\n",
      "key is :  Aweil South\n",
      "value is :  Northern Bahr el Ghazal\n",
      "key is :  Koch\n",
      "value is :  Unity\n",
      "key is :  Aweil Centre\n",
      "value is :  Northern Bahr el Ghazal\n",
      "key is :  Gogrial East\n",
      "value is :  Warrap\n",
      "key is :  Nyirol\n",
      "value is :  Jonglei\n",
      "key is :  Gogrial West\n",
      "value is :  Warrap\n",
      "key is :  Aweil West\n",
      "value is :  Northern Bahr el Ghazal\n",
      "key is :  Twic\n",
      "value is :  Warrap\n",
      "key is :  Canal/Pigi\n",
      "value is :  Jonglei\n",
      "key is :  Mayom\n",
      "value is :  Unity\n",
      "key is :  Abiemnhom\n",
      "value is :  Unity\n",
      "key is :  Longochuk\n",
      "value is :  Upper Nile\n",
      "key is :  Fangak\n",
      "value is :  Jonglei\n",
      "key is :  Maban\n",
      "value is :  Upper Nile\n",
      "key is :  Guit\n",
      "value is :  Unity\n",
      "key is :  Aweil East\n",
      "value is :  Northern Bahr el Ghazal\n",
      "key is :  Pariang\n",
      "value is :  Unity\n",
      "key is :  Rubkona\n",
      "value is :  Unity\n",
      "key is :  Panyikang\n",
      "value is :  Upper Nile\n",
      "key is :  Raga\n",
      "value is :  Western Bahr el Ghazal\n",
      "key is :  Baliet\n",
      "value is :  Upper Nile\n",
      "key is :  Fashoda\n",
      "value is :  Upper Nile\n",
      "key is :  Manyo\n",
      "value is :  Upper Nile\n",
      "key is :  Melut\n",
      "value is :  Upper Nile\n",
      "key is :  Renk\n",
      "value is :  Upper Nile\n",
      "key is :  Malakal\n",
      "value is :  Upper Nile\n",
      "key is :  Al Kamlin\n",
      "value is :  Gezira\n",
      "key is :  Al Mahagil\n",
      "value is :  Ituri\n",
      "key is :  East al Gazera\n",
      "value is :  Gezira\n",
      "key is :  North al Gazera\n",
      "value is :  Gezira\n",
      "key is :  Sharq al Gazera\n",
      "value is :  Gezira\n",
      "key is :  South al Gazera\n",
      "value is :  Gezira\n",
      "key is :  Um Al Gura\n",
      "value is :  Gezira\n",
      "key is :  Al Faw\n",
      "value is :  Gedaref\n",
      "key is :  Al Fushqa\n",
      "value is :  Gedaref\n",
      "key is :  Al Gadaref\n",
      "value is :  Gedaref\n",
      "key is :  Al Galabat\n",
      "value is :  Gedaref\n",
      "key is :  Al Rahd\n",
      "value is :  Gedaref\n",
      "key is :  Ad Damazin\n",
      "value is :  Blue Nile\n",
      "key is :  Al Kurumik\n",
      "value is :  Blue Nile\n",
      "key is :  Al Roseires\n",
      "value is :  Blue Nile\n",
      "key is :  Baw\n",
      "value is :  Blue Nile\n",
      "key is :  Geissan\n",
      "value is :  Blue Nile\n",
      "key is :  Mukjar\n",
      "value is :  Central Darfur\n",
      "key is :  Zallingi\n",
      "value is :  Central Darfur\n",
      "key is :  Al Deain\n",
      "value is :  South Darfur\n",
      "key is :  Nyala\n",
      "value is :  South Darfur\n",
      "key is :  Al Gash\n",
      "value is :  Kassala\n",
      "key is :  Hamashkorieb\n",
      "value is :  Kassala\n",
      "key is :  Kassala\n",
      "value is :  Kassala\n",
      "key is :  Nahr Atbara\n",
      "value is :  River Nile\n",
      "key is :  Seteet\n",
      "value is :  Kassala\n",
      "key is :  Karary\n",
      "value is :  Khartoum\n",
      "key is :  Khartoum Bahri\n",
      "value is :  Khartoum\n",
      "key is :  Khartoum\n",
      "value is :  Khartoum\n",
      "key is :  Omdurman\n",
      "value is :  Khartoum\n",
      "key is :  Sharg En Nile\n",
      "value is :  Khartoum\n",
      "key is :  South Khartoum\n",
      "value is :  Khartoum\n",
      "key is :  Um Badda\n",
      "value is :  Khartoum\n",
      "key is :  Al Fasher\n",
      "value is :  North Darfur\n",
      "key is :  Kabkabiya\n",
      "value is :  North Darfur\n",
      "key is :  Kutum\n",
      "value is :  North Darfur\n",
      "key is :  Mellit\n",
      "value is :  North Darfur\n",
      "key is :  Um Kadada\n",
      "value is :  North Darfur\n",
      "key is :  Bara\n",
      "value is :  North Kordofan\n",
      "key is :  Jebrat al Sheikh\n",
      "value is :  North Kordofan\n",
      "key is :  Sheikan\n",
      "value is :  North Kordofan\n",
      "key is :  Sowdari\n",
      "value is :  North Kordofan\n",
      "key is :  Um Rawaba\n",
      "value is :  North Kordofan\n",
      "key is :  Addabah\n",
      "value is :  Northern\n",
      "key is :  Dongola\n",
      "value is :  Northern\n",
      "key is :  Merawi\n",
      "value is :  Northern\n",
      "key is :  Wadi Halfa\n",
      "value is :  Northern\n",
      "key is :  Halayeb\n",
      "value is :  Red Sea\n",
      "key is :  Port Sudan\n",
      "value is :  Red Sea\n",
      "key is :  Sinkat\n",
      "value is :  Red Sea\n",
      "key is :  Tokar\n",
      "value is :  Red Sea\n",
      "key is :  Abu Hamad\n",
      "value is :  River Nile\n",
      "key is :  Ad Damer\n",
      "value is :  River Nile\n",
      "key is :  Al Matammah\n",
      "value is :  Al Jawf\n",
      "key is :  Atbara\n",
      "value is :  River Nile\n",
      "key is :  Berber\n",
      "value is :  Woqooyi Galbeed\n",
      "key is :  Shendi\n",
      "value is :  River Nile\n",
      "key is :  Ad Dinder\n",
      "value is :  Hadramaut\n",
      "key is :  Sennar\n",
      "value is :  Sinnar\n",
      "key is :  Singa\n",
      "value is :  Sinnar\n",
      "key is :  Buram\n",
      "value is :  South Darfur\n",
      "key is :  Id El Ghanem\n",
      "value is :  South Darfur\n",
      "key is :  Kas\n",
      "value is :  Western\n",
      "key is :  Nyala.1\n",
      "value is :  South Darfur\n",
      "key is :  Tulus\n",
      "value is :  South Darfur\n",
      "key is :  Abu Jubaiyah\n",
      "value is :  South Kordofan\n",
      "key is :  Dilling\n",
      "value is :  South Kordofan\n",
      "key is :  Kadugli\n",
      "value is :  South Kordofan\n",
      "key is :  Rashad\n",
      "value is :  South Kordofan\n",
      "key is :  Talodi\n",
      "value is :  South Kordofan\n",
      "key is :  Al Geneina\n",
      "value is :  West Darfur\n",
      "key is :  Abyei\n",
      "value is :  Warrap\n",
      "key is :  As Salam\n",
      "value is :  White Nile\n",
      "key is :  En Nuhud\n",
      "value is :  West Kordofan\n",
      "key is :  Ghebeish\n",
      "value is :  North Kordofan\n",
      "key is :  Lagawa\n",
      "value is :  West Kordofan\n",
      "key is :  Ad Douiem\n",
      "value is :  White Nile\n",
      "key is :  Al Gutaina\n",
      "value is :  White Nile\n",
      "key is :  Al Jabalian\n",
      "value is :  White Nile\n",
      "key is :  Kosti\n",
      "value is :  White Nile\n",
      "key is :  Adjumani\n",
      "value is :  Northern\n",
      "key is :  Apac\n",
      "value is :  Northern\n",
      "key is :  Arua\n",
      "value is :  Northern\n",
      "key is :  Bugiri\n",
      "value is :  Eastern\n",
      "key is :  Bundibugyo\n",
      "value is :  Western\n",
      "key is :  Bushenyi\n",
      "value is :  Western\n",
      "key is :  Busia.1\n",
      "value is :  Eastern\n",
      "key is :  Gulu\n",
      "value is :  Northern\n",
      "key is :  Hoima\n",
      "value is :  Western\n",
      "key is :  Iganga\n",
      "value is :  Eastern\n",
      "key is :  Jinja\n",
      "value is :  Eastern\n",
      "key is :  Kabale\n",
      "value is :  Western\n",
      "key is :  Kabarole\n",
      "value is :  Western\n",
      "key is :  Kaberamaido\n",
      "value is :  Eastern\n",
      "key is :  Kalangala\n",
      "value is :  Central\n",
      "key is :  Kampala\n",
      "value is :  Central\n",
      "key is :  Kamuli\n",
      "value is :  Eastern\n",
      "key is :  Kamwenge\n",
      "value is :  Western\n",
      "key is :  Kanungu\n",
      "value is :  Western\n",
      "key is :  Kapchorwa\n",
      "value is :  Eastern\n",
      "key is :  Kasese\n",
      "value is :  Western\n",
      "key is :  Katakwi\n",
      "value is :  Eastern\n",
      "key is :  Kayunga\n",
      "value is :  Central\n",
      "key is :  Kibale\n",
      "value is :  Western\n",
      "key is :  Kiboga\n",
      "value is :  Central\n",
      "key is :  Kisoro\n",
      "value is :  Western\n",
      "key is :  Kitgum\n",
      "value is :  Northern\n",
      "key is :  Kotido\n",
      "value is :  Northern\n",
      "key is :  Kumi\n",
      "value is :  Eastern\n",
      "key is :  Kyenjojo\n",
      "value is :  Western\n",
      "key is :  Lira\n",
      "value is :  Northern\n",
      "key is :  Luwero\n",
      "value is :  Central\n",
      "key is :  Masaka\n",
      "value is :  Central\n",
      "key is :  Masindi\n",
      "value is :  Western\n",
      "key is :  Mayuge\n",
      "value is :  Eastern\n",
      "key is :  Mbale\n",
      "value is :  Eastern\n",
      "key is :  Mbarara\n",
      "value is :  Western\n",
      "key is :  Moroto\n",
      "value is :  Northern\n",
      "key is :  Moyo\n",
      "value is :  Northern\n",
      "key is :  Mpigi\n",
      "value is :  Central\n",
      "key is :  Mubende\n",
      "value is :  Central\n",
      "key is :  Mukono\n",
      "value is :  Central\n",
      "key is :  Nakapiripirit\n",
      "value is :  Northern\n",
      "key is :  Nakasongola\n",
      "value is :  Central\n",
      "key is :  Nebbi\n",
      "value is :  Northern\n",
      "key is :  Ntungamo\n",
      "value is :  Western\n",
      "key is :  Pader\n",
      "value is :  Northern\n",
      "key is :  Pallisa\n",
      "value is :  Eastern\n",
      "key is :  Rakai\n",
      "value is :  Central\n",
      "key is :  Rukungiri\n",
      "value is :  Western\n",
      "key is :  Sembabule\n",
      "value is :  Central\n",
      "key is :  Sironko\n",
      "value is :  Eastern\n",
      "key is :  Soroti\n",
      "value is :  Eastern\n",
      "key is :  Tororo\n",
      "value is :  Eastern\n",
      "key is :  Wakiso\n",
      "value is :  Central\n",
      "key is :  Yumbe\n",
      "value is :  Northern\n",
      "key is :  Ibb\n",
      "value is :  Ibb\n",
      "key is :  Abyan\n",
      "value is :  Abyan\n",
      "key is :  Amanat Al 'Asimah\n",
      "value is :  Amanat Al Asimah\n",
      "key is :  Al Bayda'\n",
      "value is :  Al Bayda'\n",
      "key is :  Mawiyah\n",
      "value is :  Ta'izz\n",
      "key is :  Shar'ab As Salam\n",
      "value is :  Ta'izz\n",
      "key is :  Shar'ab Ar Rawnah\n",
      "value is :  Ta'izz\n",
      "key is :  Maqbanah\n",
      "value is :  Ta'izz\n",
      "key is :  Al Mukha'\n",
      "value is :  Ta'izz\n",
      "key is :  Dhubab\n",
      "value is :  Ta'izz\n",
      "key is :  Mawza'\n",
      "value is :  Ta'izz\n",
      "key is :  Jabal Habashi\n",
      "value is :  Ta'izz\n",
      "key is :  Mashra'ah wa Hadnan\n",
      "value is :  Ta'izz\n",
      "key is :  Sabir Al Mawadim\n",
      "value is :  Ta'izz\n",
      "key is :  Al Misrakh\n",
      "value is :  Ta'izz\n",
      "key is :  Dimnat Khadir\n",
      "value is :  Ta'izz\n",
      "key is :  As Silw\n",
      "value is :  Ta'izz\n",
      "key is :  Ash Shamayatayn\n",
      "value is :  Ta'izz\n",
      "key is :  Al Wazi'iyah\n",
      "value is :  Ta'izz\n",
      "key is :  Hayfan\n",
      "value is :  Ta'izz\n",
      "key is :  Al Mudaffar\n",
      "value is :  Ta'izz\n",
      "key is :  Al Qahirah\n",
      "value is :  Ta'izz\n",
      "key is :  Salah\n",
      "value is :  Ta'izz\n",
      "key is :  At Ta'izziyah\n",
      "value is :  Ta'izz\n",
      "key is :  Al Ma'afir\n",
      "value is :  Ta'izz\n",
      "key is :  Al Mawasit\n",
      "value is :  Ta'izz\n",
      "key is :  Sami'\n",
      "value is :  Ta'izz\n",
      "key is :  Al Jawf\n",
      "value is :  Al Jawf\n",
      "key is :  Hajjah\n",
      "value is :  Hajjah\n",
      "key is :  Az Zuhrah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Luhayyah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Kamaran\n",
      "value is :  Al Hudaydah\n",
      "key is :  As Salif\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Munirah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Qanawis\n",
      "value is :  Al Hudaydah\n",
      "key is :  Az Zaydiyah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Mighlaf\n",
      "value is :  Al Hudaydah\n",
      "key is :  Ad Dahi\n",
      "value is :  Al Hudaydah\n",
      "key is :  Bajil\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Hajjaylah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Bura'\n",
      "value is :  Tana River\n",
      "key is :  Al Marawi'ah\n",
      "value is :  Northern\n",
      "key is :  Ad Durayhimi\n",
      "value is :  Al Hudaydah\n",
      "key is :  As Sukhnah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Mansuriyah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Bayt Al Faqih\n",
      "value is :  Al Hudaydah\n",
      "key is :  Jabal Ra's\n",
      "value is :  Al Hudaydah\n",
      "key is :  Hays\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Khawkhah\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Hawak\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Mina'\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Hali\n",
      "value is :  Al Hudaydah\n",
      "key is :  Zabid\n",
      "value is :  Al Hudaydah\n",
      "key is :  Al Jarrahi\n",
      "value is :  Al Hudaydah\n",
      "key is :  At Tuhayta\n",
      "value is :  Al Hudaydah\n",
      "key is :  Hadramaut\n",
      "value is :  Hadramaut\n",
      "key is :  Dhamar\n",
      "value is :  Dhamar\n",
      "key is :  Shabwah\n",
      "value is :  Shabwah\n",
      "key is :  Sa'dah\n",
      "value is :  Sa`dah\n",
      "key is :  Sana'a\n",
      "value is :  Sana'a\n",
      "key is :  Adan\n",
      "value is :  Adan\n",
      "key is :  Lahij\n",
      "value is :  Lahij\n",
      "key is :  Ma'rib\n",
      "value is :  Ma'rib\n",
      "key is :  Al Mahwit\n",
      "value is :  Al Mahwit\n",
      "key is :  Al Mahrah\n",
      "value is :  Al Mahrah\n",
      "key is :  Amran\n",
      "value is :  `Amran\n",
      "key is :  Ad Dali'\n",
      "value is :  Ad Dali`\n",
      "key is :  Raymah\n",
      "value is :  Raymah\n",
      "key is :  Socotra\n",
      "value is :  Socotra\n",
      "key is :  Chibombo\n",
      "value is :  Central\n",
      "key is :  Kabwe\n",
      "value is :  Central\n",
      "key is :  Kapiri Mposhi\n",
      "value is :  Central\n",
      "key is :  Mkushi\n",
      "value is :  Central\n",
      "key is :  Mumbwa\n",
      "value is :  Central\n",
      "key is :  Serenje\n",
      "value is :  Central\n",
      "key is :  Chililabombwe\n",
      "value is :  Copperbelt\n",
      "key is :  Chingola\n",
      "value is :  Copperbelt\n",
      "key is :  Kalulushi\n",
      "value is :  Copperbelt\n",
      "key is :  Kitwe\n",
      "value is :  Copperbelt\n",
      "key is :  Luanshya\n",
      "value is :  Copperbelt\n",
      "key is :  Lufwanyama\n",
      "value is :  Copperbelt\n",
      "key is :  Masaiti\n",
      "value is :  Copperbelt\n",
      "key is :  MPongwe\n",
      "value is :  Copperbelt\n",
      "key is :  Mufulira\n",
      "value is :  Copperbelt\n",
      "key is :  Ndola\n",
      "value is :  Copperbelt\n",
      "key is :  Chadiza\n",
      "value is :  Eastern\n",
      "key is :  Chipata\n",
      "value is :  Eastern\n",
      "key is :  Katete\n",
      "value is :  Eastern\n",
      "key is :  Lundazi\n",
      "value is :  Eastern\n",
      "key is :  Mambwe\n",
      "value is :  Eastern\n",
      "key is :  Nyimba\n",
      "value is :  Eastern\n",
      "key is :  Petauke\n",
      "value is :  Eastern\n",
      "key is :  Chiengi\n",
      "value is :  Luapula\n",
      "key is :  Kawambwa\n",
      "value is :  Luapula\n",
      "key is :  Mansa\n",
      "value is :  Luapula\n",
      "key is :  Milenge\n",
      "value is :  Luapula\n",
      "key is :  Mwense\n",
      "value is :  Luapula\n",
      "key is :  Nchelenge\n",
      "value is :  Luapula\n",
      "key is :  Samfya\n",
      "value is :  Luapula\n",
      "key is :  Chongwe\n",
      "value is :  Lusaka\n",
      "key is :  Kafue\n",
      "value is :  Lusaka\n",
      "key is :  Luangwa\n",
      "value is :  Lusaka\n",
      "key is :  Lusaka\n",
      "value is :  Lusaka\n",
      "key is :  Chama\n",
      "value is :  Muchinga\n",
      "key is :  Chinsali\n",
      "value is :  Muchinga\n",
      "key is :  Isoka\n",
      "value is :  Muchinga\n",
      "key is :  Mpika\n",
      "value is :  Muchinga\n",
      "key is :  Nakonde\n",
      "value is :  Muchinga\n",
      "key is :  Chavuma\n",
      "value is :  North-Western\n",
      "key is :  Kabompo\n",
      "value is :  North-Western\n",
      "key is :  Kasempa\n",
      "value is :  North-Western\n",
      "key is :  Mufumbwe\n",
      "value is :  North-Western\n",
      "key is :  Mwinilunga\n",
      "value is :  North-Western\n",
      "key is :  Solwezi\n",
      "value is :  North-Western\n",
      "key is :  Zambezi\n",
      "value is :  North-Western\n",
      "key is :  Chilubi\n",
      "value is :  Northern\n",
      "key is :  Kaputa\n",
      "value is :  Northern\n",
      "key is :  Kasama\n",
      "value is :  Northern\n",
      "key is :  Luwingu\n",
      "value is :  Northern\n",
      "key is :  Mbala\n",
      "value is :  Northern\n",
      "key is :  Mporokoso\n",
      "value is :  Northern\n",
      "key is :  Mpulungu\n",
      "value is :  Northern\n",
      "key is :  Mungwi\n",
      "value is :  Northern\n",
      "key is :  Choma\n",
      "value is :  Southern\n",
      "key is :  Gwembe\n",
      "value is :  Southern\n",
      "key is :  Itezhi-Tezhi\n",
      "value is :  Southern\n",
      "key is :  Kalomo\n",
      "value is :  Southern\n",
      "key is :  Kazungula\n",
      "value is :  Southern\n",
      "key is :  Livingstone\n",
      "value is :  Southern\n",
      "key is :  Mazabuka\n",
      "value is :  Southern\n",
      "key is :  Monze\n",
      "value is :  Southern\n",
      "key is :  Namwala\n",
      "value is :  Southern\n",
      "key is :  Siavonga\n",
      "value is :  Southern\n",
      "key is :  Sinazongwe\n",
      "value is :  Southern\n",
      "key is :  Kalabo\n",
      "value is :  Western\n",
      "key is :  Kaoma\n",
      "value is :  Western\n",
      "key is :  Lukulu\n",
      "value is :  Western\n",
      "key is :  Mongu\n",
      "value is :  Western\n",
      "key is :  Senanga\n",
      "value is :  Western\n",
      "key is :  Sesheke\n",
      "value is :  Western\n",
      "key is :  Shangombo\n",
      "value is :  Western\n",
      "key is :  Bulawayo\n",
      "value is :  Bulawayo\n",
      "key is :  Harare\n",
      "value is :  Harare\n",
      "key is :  Buhera\n",
      "value is :  Manicaland\n",
      "key is :  Chimanimani\n",
      "value is :  Manicaland\n",
      "key is :  Chipinge\n",
      "value is :  Manicaland\n",
      "key is :  Makoni\n",
      "value is :  Manicaland\n",
      "key is :  Mutare\n",
      "value is :  Manicaland\n",
      "key is :  Mutasa\n",
      "value is :  Manicaland\n",
      "key is :  Nyanga\n",
      "value is :  Manicaland\n",
      "key is :  Bindura\n",
      "value is :  Mashonaland Central\n",
      "key is :  Centenary\n",
      "value is :  Mashonaland Central\n",
      "key is :  Guruve\n",
      "value is :  Mashonaland Central\n",
      "key is :  Mazowe\n",
      "value is :  Mashonaland Central\n",
      "key is :  Mount Darwin\n",
      "value is :  Mashonaland Central\n",
      "key is :  Rushinga\n",
      "value is :  Mashonaland Central\n",
      "key is :  Shamva\n",
      "value is :  Mashonaland Central\n",
      "key is :  Chikomba\n",
      "value is :  Mashonaland East\n",
      "key is :  Goromonzi\n",
      "value is :  Mashonaland East\n",
      "key is :  Marondera\n",
      "value is :  Mashonaland East\n",
      "key is :  Mudzi\n",
      "value is :  Mashonaland East\n",
      "key is :  Murehwa\n",
      "value is :  Mashonaland East\n",
      "key is :  Mutoko\n",
      "value is :  Mashonaland East\n",
      "key is :  Seke\n",
      "value is :  Mashonaland East\n",
      "key is :  UMP\n",
      "value is :  Mashonaland East\n",
      "key is :  Wedza\n",
      "value is :  Mashonaland East\n",
      "key is :  Chegutu\n",
      "value is :  Mashonaland West\n",
      "key is :  Hurungwe\n",
      "value is :  Mashonaland West\n",
      "key is :  Kadoma\n",
      "value is :  Mashonaland West\n",
      "key is :  Kariba\n",
      "value is :  Mashonaland West\n",
      "key is :  Makonde\n",
      "value is :  Mashonaland West\n",
      "key is :  Zvimba\n",
      "value is :  Mashonaland West\n",
      "key is :  Bikita\n",
      "value is :  Masvingo\n",
      "key is :  Chiredzi\n",
      "value is :  Masvingo\n",
      "key is :  Chivi\n",
      "value is :  Masvingo\n",
      "key is :  Gutu\n",
      "value is :  Masvingo\n",
      "key is :  Masvingo\n",
      "value is :  Masvingo\n",
      "key is :  Mwenezi\n",
      "value is :  Masvingo\n",
      "key is :  Zaka\n",
      "value is :  Masvingo\n",
      "key is :  Binga\n",
      "value is :  Matabeleland North\n",
      "key is :  Bubi\n",
      "value is :  Matabeleland North\n",
      "key is :  Hwange\n",
      "value is :  Matabeleland North\n",
      "key is :  Lupane\n",
      "value is :  Matabeleland North\n",
      "key is :  Nkayi\n",
      "value is :  Matabeleland North\n",
      "key is :  Tsholotsho\n",
      "value is :  Matabeleland North\n",
      "key is :  Umguza\n",
      "value is :  Matabeleland North\n",
      "key is :  Beitbridge\n",
      "value is :  Matabeleland South\n",
      "key is :  Bulilima (North)\n",
      "value is :  Matabeleland South\n",
      "key is :  Gwanda\n",
      "value is :  Matabeleland South\n",
      "key is :  Insiza\n",
      "value is :  Matabeleland South\n",
      "key is :  Mangwe (South)\n",
      "value is :  Matabeleland South\n",
      "key is :  Matobo\n",
      "value is :  Matabeleland South\n",
      "key is :  Umzingwane\n",
      "value is :  Matabeleland South\n",
      "key is :  Chirumhanzu\n",
      "value is :  Midlands\n",
      "key is :  Gokwe North\n",
      "value is :  Midlands\n",
      "key is :  Gokwe South\n",
      "value is :  Midlands\n",
      "key is :  Gweru\n",
      "value is :  Midlands\n",
      "key is :  Kwekwe\n",
      "value is :  Midlands\n",
      "key is :  Mberengwa\n",
      "value is :  Midlands\n",
      "key is :  Shurugwi\n",
      "value is :  Midlands\n",
      "key is :  Zvishavane\n",
      "value is :  Midlands\n"
     ]
    }
   ],
   "source": [
    "# print(admin_to_province)\n",
    "for k, v in admin_to_province.items():\n",
    "    print(\"key is : \", k)\n",
    "    print(\"value is : \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Administrative Names to Provinces in time_series\n",
    "\n",
    "Maps `admin_name` to their respective **provinces** using a precomputed dictionary - >`admin_to_province` in `time_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series['province'] = time_series['admin_name'].apply(lambda x: admin_to_province[x])\n",
    "time_series['province'] = time_series['admin_name'].apply(\n",
    "    lambda x: admin_to_province[x] if x in admin_to_province else admin_to_province.get(x.replace('ô', 'o'))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ⏳ Time Lagging & Feature Engineering\n",
    "\n",
    "#### 📅 **Why Use Lagging?**\n",
    "\n",
    "To predict food insecurity **for a given quarter**, we use:\n",
    "\n",
    "- **6 months of historical values** for traditional & news-based features.\n",
    "- **Province & country-level aggregations** to capture broader shocks.\n",
    "- **6 quarters of lagged IPC phase values** to model temporal dependencies.\n",
    "\n",
    "#### ⚡ **Optimized Lagging Approach**\n",
    "\n",
    "To improve computational efficiency, we:\n",
    "✔ Use `groupby()` for **fast province & country-level aggregations**.  \n",
    "✔ Merge lagged data via `merge()` instead of slow `.apply()`.  \n",
    "✔ Only keep **past data** to ensure no data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lagged(x, f, t):\n",
    "    admin_code = x['admin_code']\n",
    "    year = x['year']\n",
    "    month = x['month']\n",
    "    l_month = ((month-1-t)%12)+1\n",
    "    l_year = year\n",
    "    if month-t<=0:\n",
    "        l_year -= 1\n",
    "    ts=time_series[time_series['admin_code']==admin_code]\n",
    "    lagged_year_month = '{}_{}'.format(l_year, l_month)\n",
    "    if lagged_year_month in ts['year_month'].values:\n",
    "        ts = ts[ts['year_month']==lagged_year_month]\n",
    "        return ts[f].values[0]\n",
    "    else:\n",
    "        return x[f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True):\n",
    "    if agg:\n",
    "        levels = ['', '_province', '_country']\n",
    "    else:\n",
    "        levels = ['']\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f+suffix\n",
    "            for t in range(start,end,diff):\n",
    "                if '{}_{}'.format(f_s,t) in time_series:\n",
    "                    continue\n",
    "                time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add province and country aggregate values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def add_agg_factors(features, level='province'):\n",
    "#     grouped_df = time_series.groupby(['year_month', level]).mean(numeric_only=True)\n",
    "#     for f in features:\n",
    "#         time_series['{}_{}'.format(f, level)] = time_series.apply(lambda x: grouped_df.loc[x['year_month'], x[level]][f], axis=1)\n",
    "\n",
    "\n",
    "def add_agg_factors(features, level='province'):\n",
    "    # First, create a cleaned version of the grouping column.\n",
    "    # (If time_series[level] is already a string column, this works directly.)\n",
    "    time_series['{}_clean'.format(level)] = time_series[level]\n",
    "    \n",
    "    # Now group by 'year_month' and the cleaned level.\n",
    "    grouped_df = time_series.groupby(['year_month', '{}_clean'.format(level)]).mean(numeric_only=True)\n",
    "    \n",
    "    # For each feature, add a new column.\n",
    "    for f in features:\n",
    "        # Use the cleaned level for the lookup in the grouped DataFrame.\n",
    "        time_series['{}_{}'.format(f, level)] = time_series.apply(\n",
    "            lambda x: grouped_df.loc[x['year_month'], x['{}_clean'.format(level)]][f]\n",
    "                      if pd.notnull(x['{}_clean'.format(level)]) and x['{}_clean'.format(level)] in grouped_df.loc[x['year_month']].index\n",
    "                      else np.nan,\n",
    "            axis=1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year_month'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madd_agg_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_factors\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 13\u001b[0m, in \u001b[0;36madd_agg_factors\u001b[0;34m(features, level)\u001b[0m\n\u001b[1;32m     10\u001b[0m time_series[\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_clean\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(level)] \u001b[38;5;241m=\u001b[39m time_series[level]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Now group by 'year_month' and the cleaned level.\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m grouped_df \u001b[38;5;241m=\u001b[39m \u001b[43mtime_series\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear_month\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_clean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(numeric_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# For each feature, add a new column.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# Use the cleaned level for the lookup in the grouped DataFrame.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:9183\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   9180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   9181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 9183\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9186\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9187\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9189\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9192\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/groupby/grouper.py:1043\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m   1041\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1043\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year_month'"
     ]
    }
   ],
   "source": [
    "add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'index', 'country', 'admin_code', 'admin_name',\n",
       "       'centx', 'centy', 'year_month', 'year', 'month', 'fews_ipc',\n",
       "       'fews_ha', 'fews_proj_near', 'fews_proj_near_ha', 'fews_proj_med',\n",
       "       'fews_proj_med_ha', 'ndvi_mean', 'ndvi_anom', 'rain_mean',\n",
       "       'rain_anom', 'et_mean', 'et_anom', 'acled_count',\n",
       "       'acled_fatalities', 'p_staple_food', 'area', 'cropland_pct', 'pop',\n",
       "       'ruggedness_mean', 'pasture_pct', 'change_fews', 'land seizures_0',\n",
       "       'land seizures_1', 'land seizures_2', 'slashed export_0',\n",
       "       'slashed export_1', 'slashed export_2', 'price rise_0',\n",
       "       'price rise_1', 'price rise_2', 'mass hunger_0', 'mass hunger_1',\n",
       "       'mass hunger_2', 'cyclone_0', 'cyclone_1', 'cyclone_2',\n",
       "       'failed crops_0', 'failed crops_1', 'failed crops_2',\n",
       "       'disruption to farming_0', 'disruption to farming_1',\n",
       "       'disruption to farming_2', 'massive starvation_0',\n",
       "       'massive starvation_1', 'massive starvation_2',\n",
       "       'abnormally low rainfall_0', 'abnormally low rainfall_1',\n",
       "       'abnormally low rainfall_2', 'withheld relief_0',\n",
       "       'withheld relief_1', 'withheld relief_2', 'international alarm_0',\n",
       "       'international alarm_1', 'international alarm_2',\n",
       "       'reduced national output_0', 'reduced national output_1',\n",
       "       'reduced national output_2', 'oppressive regimes_0',\n",
       "       'oppressive regimes_1', 'oppressive regimes_2', 'pests_0',\n",
       "       'pests_1', 'pests_2', 'continued deterioration_0',\n",
       "       'continued deterioration_1', 'continued deterioration_2',\n",
       "       'forests destroyed_0', 'forests destroyed_1',\n",
       "       'forests destroyed_2', 'man-made disaster_0',\n",
       "       'man-made disaster_1', 'man-made disaster_2', 'food insecurity_0',\n",
       "       'food insecurity_1', 'food insecurity_2',\n",
       "       'harvests are devastated_0', 'harvests are devastated_1',\n",
       "       'harvests are devastated_2', 'humanitarian situation_0',\n",
       "       'humanitarian situation_1', 'humanitarian situation_2',\n",
       "       'economic impoverishment_0', 'economic impoverishment_1',\n",
       "       'economic impoverishment_2', 'clan battle_0', 'clan battle_1',\n",
       "       'clan battle_2', 'population crisis_0', 'population crisis_1',\n",
       "       'population crisis_2', 'province', 'land seizures_0_province',\n",
       "       'slashed export_0_province', 'price rise_0_province',\n",
       "       'mass hunger_0_province', 'cyclone_0_province',\n",
       "       'failed crops_0_province', 'disruption to farming_0_province',\n",
       "       'massive starvation_0_province',\n",
       "       'abnormally low rainfall_0_province', 'withheld relief_0_province',\n",
       "       'international alarm_0_province',\n",
       "       'reduced national output_0_province',\n",
       "       'oppressive regimes_0_province', 'pests_0_province',\n",
       "       'continued deterioration_0_province',\n",
       "       'forests destroyed_0_province', 'man-made disaster_0_province',\n",
       "       'food insecurity_0_province', 'harvests are devastated_0_province',\n",
       "       'humanitarian situation_0_province',\n",
       "       'economic impoverishment_0_province', 'clan battle_0_province',\n",
       "       'population crisis_0_province', 'land seizures_0_country',\n",
       "       'slashed export_0_country', 'price rise_0_country',\n",
       "       'mass hunger_0_country', 'cyclone_0_country',\n",
       "       'failed crops_0_country', 'disruption to farming_0_country',\n",
       "       'massive starvation_0_country',\n",
       "       'abnormally low rainfall_0_country', 'withheld relief_0_country',\n",
       "       'international alarm_0_country',\n",
       "       'reduced national output_0_country',\n",
       "       'oppressive regimes_0_country', 'pests_0_country',\n",
       "       'continued deterioration_0_country', 'forests destroyed_0_country',\n",
       "       'man-made disaster_0_country', 'food insecurity_0_country',\n",
       "       'harvests are devastated_0_country',\n",
       "       'humanitarian situation_0_country',\n",
       "       'economic impoverishment_0_country', 'clan battle_0_country',\n",
       "       'population crisis_0_country'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_agg_factors(news_factors, level='country')\n",
    "display(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'index', 'country', 'admin_code', 'admin_name',\n",
       "       'centx', 'centy', 'year_month', 'year', 'month', 'fews_ipc',\n",
       "       'fews_ha', 'fews_proj_near', 'fews_proj_near_ha', 'fews_proj_med',\n",
       "       'fews_proj_med_ha', 'ndvi_mean', 'ndvi_anom', 'rain_mean',\n",
       "       'rain_anom', 'et_mean', 'et_anom', 'acled_count',\n",
       "       'acled_fatalities', 'p_staple_food', 'area', 'cropland_pct', 'pop',\n",
       "       'ruggedness_mean', 'pasture_pct', 'change_fews', 'land seizures_0',\n",
       "       'land seizures_1', 'land seizures_2', 'slashed export_0',\n",
       "       'slashed export_1', 'slashed export_2', 'price rise_0',\n",
       "       'price rise_1', 'price rise_2', 'mass hunger_0', 'mass hunger_1',\n",
       "       'mass hunger_2', 'cyclone_0', 'cyclone_1', 'cyclone_2',\n",
       "       'failed crops_0', 'failed crops_1', 'failed crops_2',\n",
       "       'disruption to farming_0', 'disruption to farming_1',\n",
       "       'disruption to farming_2', 'massive starvation_0',\n",
       "       'massive starvation_1', 'massive starvation_2',\n",
       "       'abnormally low rainfall_0', 'abnormally low rainfall_1',\n",
       "       'abnormally low rainfall_2', 'withheld relief_0',\n",
       "       'withheld relief_1', 'withheld relief_2', 'international alarm_0',\n",
       "       'international alarm_1', 'international alarm_2',\n",
       "       'reduced national output_0', 'reduced national output_1',\n",
       "       'reduced national output_2', 'oppressive regimes_0',\n",
       "       'oppressive regimes_1', 'oppressive regimes_2', 'pests_0',\n",
       "       'pests_1', 'pests_2', 'continued deterioration_0',\n",
       "       'continued deterioration_1', 'continued deterioration_2',\n",
       "       'forests destroyed_0', 'forests destroyed_1',\n",
       "       'forests destroyed_2', 'man-made disaster_0',\n",
       "       'man-made disaster_1', 'man-made disaster_2', 'food insecurity_0',\n",
       "       'food insecurity_1', 'food insecurity_2',\n",
       "       'harvests are devastated_0', 'harvests are devastated_1',\n",
       "       'harvests are devastated_2', 'humanitarian situation_0',\n",
       "       'humanitarian situation_1', 'humanitarian situation_2',\n",
       "       'economic impoverishment_0', 'economic impoverishment_1',\n",
       "       'economic impoverishment_2', 'clan battle_0', 'clan battle_1',\n",
       "       'clan battle_2', 'population crisis_0', 'population crisis_1',\n",
       "       'population crisis_2', 'province', 'land seizures_0_province',\n",
       "       'slashed export_0_province', 'price rise_0_province',\n",
       "       'mass hunger_0_province', 'cyclone_0_province',\n",
       "       'failed crops_0_province', 'disruption to farming_0_province',\n",
       "       'massive starvation_0_province',\n",
       "       'abnormally low rainfall_0_province', 'withheld relief_0_province',\n",
       "       'international alarm_0_province',\n",
       "       'reduced national output_0_province',\n",
       "       'oppressive regimes_0_province', 'pests_0_province',\n",
       "       'continued deterioration_0_province',\n",
       "       'forests destroyed_0_province', 'man-made disaster_0_province',\n",
       "       'food insecurity_0_province', 'harvests are devastated_0_province',\n",
       "       'humanitarian situation_0_province',\n",
       "       'economic impoverishment_0_province', 'clan battle_0_province',\n",
       "       'population crisis_0_province', 'land seizures_0_country',\n",
       "       'slashed export_0_country', 'price rise_0_country',\n",
       "       'mass hunger_0_country', 'cyclone_0_country',\n",
       "       'failed crops_0_country', 'disruption to farming_0_country',\n",
       "       'massive starvation_0_country',\n",
       "       'abnormally low rainfall_0_country', 'withheld relief_0_country',\n",
       "       'international alarm_0_country',\n",
       "       'reduced national output_0_country',\n",
       "       'oppressive regimes_0_country', 'pests_0_country',\n",
       "       'continued deterioration_0_country', 'forests destroyed_0_country',\n",
       "       'man-made disaster_0_country', 'food insecurity_0_country',\n",
       "       'harvests are devastated_0_country',\n",
       "       'humanitarian situation_0_country',\n",
       "       'economic impoverishment_0_country', 'clan battle_0_country',\n",
       "       'population crisis_0_country', 'ndvi_mean_province',\n",
       "       'ndvi_anom_province', 'rain_mean_province', 'rain_anom_province',\n",
       "       'et_mean_province', 'et_anom_province', 'acled_count_province',\n",
       "       'acled_fatalities_province', 'p_staple_food_province'],\n",
       "      dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_agg_factors(t_variant_traditional_factors, level='province')\n",
    "display(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_agg_factors(news_factors, level='country')\n",
    "add_agg_factors(t_variant_traditional_factors, level='province')\n",
    "add_agg_factors(t_variant_traditional_factors, level='country')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_csv('agg_province_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time lagged features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n"
     ]
    }
   ],
   "source": [
    "add_time_lagged(t_variant_traditional_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n"
     ]
    }
   ],
   "source": [
    "add_time_lagged(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n",
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n"
     ]
    }
   ],
   "source": [
    "add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2b/1yzz7bcn205dx3sqkbz883x00000gn/T/ipykernel_96069/1584446215.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)\n"
     ]
    }
   ],
   "source": [
    "add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'index', 'country', 'admin_code', 'admin_name',\n",
       "       'centx', 'centy', 'year_month', 'year', 'month', 'fews_ipc',\n",
       "       'fews_ha', 'fews_proj_near', 'fews_proj_near_ha', 'fews_proj_med',\n",
       "       'fews_proj_med_ha', 'ndvi_mean', 'ndvi_anom', 'rain_mean',\n",
       "       'rain_anom', 'et_mean', 'et_anom', 'acled_count',\n",
       "       'acled_fatalities', 'p_staple_food', 'area', 'cropland_pct', 'pop',\n",
       "       'ruggedness_mean', 'pasture_pct', 'change_fews', 'land seizures_0',\n",
       "       'land seizures_1', 'land seizures_2', 'slashed export_0',\n",
       "       'slashed export_1', 'slashed export_2', 'price rise_0',\n",
       "       'price rise_1', 'price rise_2', 'mass hunger_0', 'mass hunger_1',\n",
       "       'mass hunger_2', 'cyclone_0', 'cyclone_1', 'cyclone_2',\n",
       "       'failed crops_0', 'failed crops_1', 'failed crops_2',\n",
       "       'disruption to farming_0', 'disruption to farming_1',\n",
       "       'disruption to farming_2', 'massive starvation_0',\n",
       "       'massive starvation_1', 'massive starvation_2',\n",
       "       'abnormally low rainfall_0', 'abnormally low rainfall_1',\n",
       "       'abnormally low rainfall_2', 'withheld relief_0',\n",
       "       'withheld relief_1', 'withheld relief_2', 'international alarm_0',\n",
       "       'international alarm_1', 'international alarm_2',\n",
       "       'reduced national output_0', 'reduced national output_1',\n",
       "       'reduced national output_2', 'oppressive regimes_0',\n",
       "       'oppressive regimes_1', 'oppressive regimes_2', 'pests_0',\n",
       "       'pests_1', 'pests_2', 'continued deterioration_0',\n",
       "       'continued deterioration_1', 'continued deterioration_2',\n",
       "       'forests destroyed_0', 'forests destroyed_1',\n",
       "       'forests destroyed_2', 'man-made disaster_0',\n",
       "       'man-made disaster_1', 'man-made disaster_2', 'food insecurity_0',\n",
       "       'food insecurity_1', 'food insecurity_2',\n",
       "       'harvests are devastated_0', 'harvests are devastated_1',\n",
       "       'harvests are devastated_2', 'humanitarian situation_0',\n",
       "       'humanitarian situation_1', 'humanitarian situation_2',\n",
       "       'economic impoverishment_0', 'economic impoverishment_1',\n",
       "       'economic impoverishment_2', 'clan battle_0', 'clan battle_1',\n",
       "       'clan battle_2', 'population crisis_0', 'population crisis_1',\n",
       "       'population crisis_2', 'province', 'land seizures_0_province',\n",
       "       'slashed export_0_province', 'price rise_0_province',\n",
       "       'mass hunger_0_province', 'cyclone_0_province',\n",
       "       'failed crops_0_province', 'disruption to farming_0_province',\n",
       "       'massive starvation_0_province',\n",
       "       'abnormally low rainfall_0_province', 'withheld relief_0_province',\n",
       "       'international alarm_0_province',\n",
       "       'reduced national output_0_province',\n",
       "       'oppressive regimes_0_province', 'pests_0_province',\n",
       "       'continued deterioration_0_province',\n",
       "       'forests destroyed_0_province', 'man-made disaster_0_province',\n",
       "       'food insecurity_0_province', 'harvests are devastated_0_province',\n",
       "       'humanitarian situation_0_province',\n",
       "       'economic impoverishment_0_province', 'clan battle_0_province',\n",
       "       'population crisis_0_province', 'land seizures_0_country',\n",
       "       'slashed export_0_country', 'price rise_0_country',\n",
       "       'mass hunger_0_country', 'cyclone_0_country',\n",
       "       'failed crops_0_country', 'disruption to farming_0_country',\n",
       "       'massive starvation_0_country',\n",
       "       'abnormally low rainfall_0_country', 'withheld relief_0_country',\n",
       "       'international alarm_0_country',\n",
       "       'reduced national output_0_country',\n",
       "       'oppressive regimes_0_country', 'pests_0_country',\n",
       "       'continued deterioration_0_country', 'forests destroyed_0_country',\n",
       "       'man-made disaster_0_country', 'food insecurity_0_country',\n",
       "       'harvests are devastated_0_country',\n",
       "       'humanitarian situation_0_country',\n",
       "       'economic impoverishment_0_country', 'clan battle_0_country',\n",
       "       'population crisis_0_country', 'ndvi_mean_province',\n",
       "       'ndvi_anom_province', 'rain_mean_province', 'rain_anom_province',\n",
       "       'et_mean_province', 'et_anom_province', 'acled_count_province',\n",
       "       'acled_fatalities_province', 'p_staple_food_province',\n",
       "       'ndvi_mean_country', 'ndvi_anom_country', 'rain_mean_country',\n",
       "       'rain_anom_country', 'et_mean_country', 'et_anom_country',\n",
       "       'acled_count_country', 'acled_fatalities_country',\n",
       "       'p_staple_food_country', 'area_province', 'cropland_pct_province',\n",
       "       'pop_province', 'ruggedness_mean_province', 'pasture_pct_province',\n",
       "       'area_country', 'cropland_pct_country', 'pop_country',\n",
       "       'ruggedness_mean_country', 'pasture_pct_country', 'ndvi_mean_3',\n",
       "       'ndvi_mean_4', 'ndvi_mean_5', 'ndvi_mean_6', 'ndvi_mean_7',\n",
       "       'ndvi_mean_8', 'ndvi_anom_3', 'ndvi_anom_4', 'ndvi_anom_5',\n",
       "       'ndvi_anom_6', 'ndvi_anom_7', 'ndvi_anom_8', 'rain_mean_3',\n",
       "       'rain_mean_4', 'rain_mean_5', 'rain_mean_6', 'rain_mean_7',\n",
       "       'rain_mean_8', 'rain_anom_3', 'rain_anom_4', 'rain_anom_5',\n",
       "       'rain_anom_6', 'rain_anom_7', 'rain_anom_8', 'et_mean_3',\n",
       "       'et_mean_4', 'et_mean_5', 'et_mean_6', 'et_mean_7', 'et_mean_8',\n",
       "       'et_anom_3', 'et_anom_4', 'et_anom_5', 'et_anom_6', 'et_anom_7',\n",
       "       'et_anom_8', 'acled_count_3', 'acled_count_4', 'acled_count_5',\n",
       "       'acled_count_6', 'acled_count_7', 'acled_count_8',\n",
       "       'acled_fatalities_3', 'acled_fatalities_4', 'acled_fatalities_5',\n",
       "       'acled_fatalities_6', 'acled_fatalities_7', 'acled_fatalities_8',\n",
       "       'p_staple_food_3', 'p_staple_food_4', 'p_staple_food_5',\n",
       "       'p_staple_food_6', 'p_staple_food_7', 'p_staple_food_8',\n",
       "       'ndvi_mean_province_3', 'ndvi_mean_province_4',\n",
       "       'ndvi_mean_province_5', 'ndvi_mean_province_6',\n",
       "       'ndvi_mean_province_7', 'ndvi_mean_province_8',\n",
       "       'ndvi_anom_province_3', 'ndvi_anom_province_4',\n",
       "       'ndvi_anom_province_5', 'ndvi_anom_province_6',\n",
       "       'ndvi_anom_province_7', 'ndvi_anom_province_8',\n",
       "       'rain_mean_province_3', 'rain_mean_province_4',\n",
       "       'rain_mean_province_5', 'rain_mean_province_6',\n",
       "       'rain_mean_province_7', 'rain_mean_province_8',\n",
       "       'rain_anom_province_3', 'rain_anom_province_4',\n",
       "       'rain_anom_province_5', 'rain_anom_province_6',\n",
       "       'rain_anom_province_7', 'rain_anom_province_8',\n",
       "       'et_mean_province_3', 'et_mean_province_4', 'et_mean_province_5',\n",
       "       'et_mean_province_6', 'et_mean_province_7', 'et_mean_province_8',\n",
       "       'et_anom_province_3', 'et_anom_province_4', 'et_anom_province_5',\n",
       "       'et_anom_province_6', 'et_anom_province_7', 'et_anom_province_8',\n",
       "       'acled_count_province_3', 'acled_count_province_4',\n",
       "       'acled_count_province_5', 'acled_count_province_6',\n",
       "       'acled_count_province_7', 'acled_count_province_8',\n",
       "       'acled_fatalities_province_3', 'acled_fatalities_province_4',\n",
       "       'acled_fatalities_province_5', 'acled_fatalities_province_6',\n",
       "       'acled_fatalities_province_7', 'acled_fatalities_province_8',\n",
       "       'p_staple_food_province_3', 'p_staple_food_province_4',\n",
       "       'p_staple_food_province_5', 'p_staple_food_province_6',\n",
       "       'p_staple_food_province_7', 'p_staple_food_province_8',\n",
       "       'ndvi_mean_country_3', 'ndvi_mean_country_4',\n",
       "       'ndvi_mean_country_5', 'ndvi_mean_country_6',\n",
       "       'ndvi_mean_country_7', 'ndvi_mean_country_8',\n",
       "       'ndvi_anom_country_3', 'ndvi_anom_country_4',\n",
       "       'ndvi_anom_country_5', 'ndvi_anom_country_6',\n",
       "       'ndvi_anom_country_7', 'ndvi_anom_country_8',\n",
       "       'rain_mean_country_3', 'rain_mean_country_4',\n",
       "       'rain_mean_country_5', 'rain_mean_country_6',\n",
       "       'rain_mean_country_7', 'rain_mean_country_8',\n",
       "       'rain_anom_country_3', 'rain_anom_country_4',\n",
       "       'rain_anom_country_5', 'rain_anom_country_6',\n",
       "       'rain_anom_country_7', 'rain_anom_country_8', 'et_mean_country_3',\n",
       "       'et_mean_country_4', 'et_mean_country_5', 'et_mean_country_6',\n",
       "       'et_mean_country_7', 'et_mean_country_8', 'et_anom_country_3',\n",
       "       'et_anom_country_4', 'et_anom_country_5', 'et_anom_country_6',\n",
       "       'et_anom_country_7', 'et_anom_country_8', 'acled_count_country_3',\n",
       "       'acled_count_country_4', 'acled_count_country_5',\n",
       "       'acled_count_country_6', 'acled_count_country_7',\n",
       "       'acled_count_country_8', 'acled_fatalities_country_3',\n",
       "       'acled_fatalities_country_4', 'acled_fatalities_country_5',\n",
       "       'acled_fatalities_country_6', 'acled_fatalities_country_7',\n",
       "       'acled_fatalities_country_8', 'p_staple_food_country_3',\n",
       "       'p_staple_food_country_4', 'p_staple_food_country_5',\n",
       "       'p_staple_food_country_6', 'p_staple_food_country_7',\n",
       "       'p_staple_food_country_8', 'land seizures_0_3',\n",
       "       'land seizures_0_4', 'land seizures_0_5', 'land seizures_0_6',\n",
       "       'land seizures_0_7', 'land seizures_0_8', 'slashed export_0_3',\n",
       "       'slashed export_0_4', 'slashed export_0_5', 'slashed export_0_6',\n",
       "       'slashed export_0_7', 'slashed export_0_8', 'price rise_0_3',\n",
       "       'price rise_0_4', 'price rise_0_5', 'price rise_0_6',\n",
       "       'price rise_0_7', 'price rise_0_8', 'mass hunger_0_3',\n",
       "       'mass hunger_0_4', 'mass hunger_0_5', 'mass hunger_0_6',\n",
       "       'mass hunger_0_7', 'mass hunger_0_8', 'cyclone_0_3', 'cyclone_0_4',\n",
       "       'cyclone_0_5', 'cyclone_0_6', 'cyclone_0_7', 'cyclone_0_8',\n",
       "       'failed crops_0_3', 'failed crops_0_4', 'failed crops_0_5',\n",
       "       'failed crops_0_6', 'failed crops_0_7', 'failed crops_0_8',\n",
       "       'disruption to farming_0_3', 'disruption to farming_0_4',\n",
       "       'disruption to farming_0_5', 'disruption to farming_0_6',\n",
       "       'disruption to farming_0_7', 'disruption to farming_0_8',\n",
       "       'massive starvation_0_3', 'massive starvation_0_4',\n",
       "       'massive starvation_0_5', 'massive starvation_0_6',\n",
       "       'massive starvation_0_7', 'massive starvation_0_8',\n",
       "       'abnormally low rainfall_0_3', 'abnormally low rainfall_0_4',\n",
       "       'abnormally low rainfall_0_5', 'abnormally low rainfall_0_6',\n",
       "       'abnormally low rainfall_0_7', 'abnormally low rainfall_0_8',\n",
       "       'withheld relief_0_3', 'withheld relief_0_4',\n",
       "       'withheld relief_0_5', 'withheld relief_0_6',\n",
       "       'withheld relief_0_7', 'withheld relief_0_8',\n",
       "       'international alarm_0_3', 'international alarm_0_4',\n",
       "       'international alarm_0_5', 'international alarm_0_6',\n",
       "       'international alarm_0_7', 'international alarm_0_8',\n",
       "       'reduced national output_0_3', 'reduced national output_0_4',\n",
       "       'reduced national output_0_5', 'reduced national output_0_6',\n",
       "       'reduced national output_0_7', 'reduced national output_0_8',\n",
       "       'oppressive regimes_0_3', 'oppressive regimes_0_4',\n",
       "       'oppressive regimes_0_5', 'oppressive regimes_0_6',\n",
       "       'oppressive regimes_0_7', 'oppressive regimes_0_8', 'pests_0_3',\n",
       "       'pests_0_4', 'pests_0_5', 'pests_0_6', 'pests_0_7', 'pests_0_8',\n",
       "       'continued deterioration_0_3', 'continued deterioration_0_4',\n",
       "       'continued deterioration_0_5', 'continued deterioration_0_6',\n",
       "       'continued deterioration_0_7', 'continued deterioration_0_8',\n",
       "       'forests destroyed_0_3', 'forests destroyed_0_4',\n",
       "       'forests destroyed_0_5', 'forests destroyed_0_6',\n",
       "       'forests destroyed_0_7', 'forests destroyed_0_8',\n",
       "       'man-made disaster_0_3', 'man-made disaster_0_4',\n",
       "       'man-made disaster_0_5', 'man-made disaster_0_6',\n",
       "       'man-made disaster_0_7', 'man-made disaster_0_8',\n",
       "       'food insecurity_0_3', 'food insecurity_0_4',\n",
       "       'food insecurity_0_5', 'food insecurity_0_6',\n",
       "       'food insecurity_0_7', 'food insecurity_0_8',\n",
       "       'harvests are devastated_0_3', 'harvests are devastated_0_4',\n",
       "       'harvests are devastated_0_5', 'harvests are devastated_0_6',\n",
       "       'harvests are devastated_0_7', 'harvests are devastated_0_8',\n",
       "       'humanitarian situation_0_3', 'humanitarian situation_0_4',\n",
       "       'humanitarian situation_0_5', 'humanitarian situation_0_6',\n",
       "       'humanitarian situation_0_7', 'humanitarian situation_0_8',\n",
       "       'economic impoverishment_0_3', 'economic impoverishment_0_4',\n",
       "       'economic impoverishment_0_5', 'economic impoverishment_0_6',\n",
       "       'economic impoverishment_0_7', 'economic impoverishment_0_8',\n",
       "       'clan battle_0_3', 'clan battle_0_4', 'clan battle_0_5',\n",
       "       'clan battle_0_6', 'clan battle_0_7', 'clan battle_0_8',\n",
       "       'population crisis_0_3', 'population crisis_0_4',\n",
       "       'population crisis_0_5', 'population crisis_0_6',\n",
       "       'population crisis_0_7', 'population crisis_0_8',\n",
       "       'land seizures_0_province_3', 'land seizures_0_province_4',\n",
       "       'land seizures_0_province_5', 'land seizures_0_province_6',\n",
       "       'land seizures_0_province_7', 'land seizures_0_province_8',\n",
       "       'slashed export_0_province_3', 'slashed export_0_province_4',\n",
       "       'slashed export_0_province_5', 'slashed export_0_province_6',\n",
       "       'slashed export_0_province_7', 'slashed export_0_province_8',\n",
       "       'price rise_0_province_3', 'price rise_0_province_4',\n",
       "       'price rise_0_province_5', 'price rise_0_province_6',\n",
       "       'price rise_0_province_7', 'price rise_0_province_8',\n",
       "       'mass hunger_0_province_3', 'mass hunger_0_province_4',\n",
       "       'mass hunger_0_province_5', 'mass hunger_0_province_6',\n",
       "       'mass hunger_0_province_7', 'mass hunger_0_province_8',\n",
       "       'cyclone_0_province_3', 'cyclone_0_province_4',\n",
       "       'cyclone_0_province_5', 'cyclone_0_province_6',\n",
       "       'cyclone_0_province_7', 'cyclone_0_province_8',\n",
       "       'failed crops_0_province_3', 'failed crops_0_province_4',\n",
       "       'failed crops_0_province_5', 'failed crops_0_province_6',\n",
       "       'failed crops_0_province_7', 'failed crops_0_province_8',\n",
       "       'disruption to farming_0_province_3',\n",
       "       'disruption to farming_0_province_4',\n",
       "       'disruption to farming_0_province_5',\n",
       "       'disruption to farming_0_province_6',\n",
       "       'disruption to farming_0_province_7',\n",
       "       'disruption to farming_0_province_8',\n",
       "       'massive starvation_0_province_3',\n",
       "       'massive starvation_0_province_4',\n",
       "       'massive starvation_0_province_5',\n",
       "       'massive starvation_0_province_6',\n",
       "       'massive starvation_0_province_7',\n",
       "       'massive starvation_0_province_8',\n",
       "       'abnormally low rainfall_0_province_3',\n",
       "       'abnormally low rainfall_0_province_4',\n",
       "       'abnormally low rainfall_0_province_5',\n",
       "       'abnormally low rainfall_0_province_6',\n",
       "       'abnormally low rainfall_0_province_7',\n",
       "       'abnormally low rainfall_0_province_8',\n",
       "       'withheld relief_0_province_3', 'withheld relief_0_province_4',\n",
       "       'withheld relief_0_province_5', 'withheld relief_0_province_6',\n",
       "       'withheld relief_0_province_7', 'withheld relief_0_province_8',\n",
       "       'international alarm_0_province_3',\n",
       "       'international alarm_0_province_4',\n",
       "       'international alarm_0_province_5',\n",
       "       'international alarm_0_province_6',\n",
       "       'international alarm_0_province_7',\n",
       "       'international alarm_0_province_8',\n",
       "       'reduced national output_0_province_3',\n",
       "       'reduced national output_0_province_4',\n",
       "       'reduced national output_0_province_5',\n",
       "       'reduced national output_0_province_6',\n",
       "       'reduced national output_0_province_7',\n",
       "       'reduced national output_0_province_8',\n",
       "       'oppressive regimes_0_province_3',\n",
       "       'oppressive regimes_0_province_4',\n",
       "       'oppressive regimes_0_province_5',\n",
       "       'oppressive regimes_0_province_6',\n",
       "       'oppressive regimes_0_province_7',\n",
       "       'oppressive regimes_0_province_8', 'pests_0_province_3',\n",
       "       'pests_0_province_4', 'pests_0_province_5', 'pests_0_province_6',\n",
       "       'pests_0_province_7', 'pests_0_province_8',\n",
       "       'continued deterioration_0_province_3',\n",
       "       'continued deterioration_0_province_4',\n",
       "       'continued deterioration_0_province_5',\n",
       "       'continued deterioration_0_province_6',\n",
       "       'continued deterioration_0_province_7',\n",
       "       'continued deterioration_0_province_8',\n",
       "       'forests destroyed_0_province_3', 'forests destroyed_0_province_4',\n",
       "       'forests destroyed_0_province_5', 'forests destroyed_0_province_6',\n",
       "       'forests destroyed_0_province_7', 'forests destroyed_0_province_8',\n",
       "       'man-made disaster_0_province_3', 'man-made disaster_0_province_4',\n",
       "       'man-made disaster_0_province_5', 'man-made disaster_0_province_6',\n",
       "       'man-made disaster_0_province_7', 'man-made disaster_0_province_8',\n",
       "       'food insecurity_0_province_3', 'food insecurity_0_province_4',\n",
       "       'food insecurity_0_province_5', 'food insecurity_0_province_6',\n",
       "       'food insecurity_0_province_7', 'food insecurity_0_province_8',\n",
       "       'harvests are devastated_0_province_3',\n",
       "       'harvests are devastated_0_province_4',\n",
       "       'harvests are devastated_0_province_5',\n",
       "       'harvests are devastated_0_province_6',\n",
       "       'harvests are devastated_0_province_7',\n",
       "       'harvests are devastated_0_province_8',\n",
       "       'humanitarian situation_0_province_3',\n",
       "       'humanitarian situation_0_province_4',\n",
       "       'humanitarian situation_0_province_5',\n",
       "       'humanitarian situation_0_province_6',\n",
       "       'humanitarian situation_0_province_7',\n",
       "       'humanitarian situation_0_province_8',\n",
       "       'economic impoverishment_0_province_3',\n",
       "       'economic impoverishment_0_province_4',\n",
       "       'economic impoverishment_0_province_5',\n",
       "       'economic impoverishment_0_province_6',\n",
       "       'economic impoverishment_0_province_7',\n",
       "       'economic impoverishment_0_province_8', 'clan battle_0_province_3',\n",
       "       'clan battle_0_province_4', 'clan battle_0_province_5',\n",
       "       'clan battle_0_province_6', 'clan battle_0_province_7',\n",
       "       'clan battle_0_province_8', 'population crisis_0_province_3',\n",
       "       'population crisis_0_province_4', 'population crisis_0_province_5',\n",
       "       'population crisis_0_province_6', 'population crisis_0_province_7',\n",
       "       'population crisis_0_province_8', 'land seizures_0_country_3',\n",
       "       'land seizures_0_country_4', 'land seizures_0_country_5',\n",
       "       'land seizures_0_country_6', 'land seizures_0_country_7',\n",
       "       'land seizures_0_country_8', 'slashed export_0_country_3',\n",
       "       'slashed export_0_country_4', 'slashed export_0_country_5',\n",
       "       'slashed export_0_country_6', 'slashed export_0_country_7',\n",
       "       'slashed export_0_country_8', 'price rise_0_country_3',\n",
       "       'price rise_0_country_4', 'price rise_0_country_5',\n",
       "       'price rise_0_country_6', 'price rise_0_country_7',\n",
       "       'price rise_0_country_8', 'mass hunger_0_country_3',\n",
       "       'mass hunger_0_country_4', 'mass hunger_0_country_5',\n",
       "       'mass hunger_0_country_6', 'mass hunger_0_country_7',\n",
       "       'mass hunger_0_country_8', 'cyclone_0_country_3',\n",
       "       'cyclone_0_country_4', 'cyclone_0_country_5',\n",
       "       'cyclone_0_country_6', 'cyclone_0_country_7',\n",
       "       'cyclone_0_country_8', 'failed crops_0_country_3',\n",
       "       'failed crops_0_country_4', 'failed crops_0_country_5',\n",
       "       'failed crops_0_country_6', 'failed crops_0_country_7',\n",
       "       'failed crops_0_country_8', 'disruption to farming_0_country_3',\n",
       "       'disruption to farming_0_country_4',\n",
       "       'disruption to farming_0_country_5',\n",
       "       'disruption to farming_0_country_6',\n",
       "       'disruption to farming_0_country_7',\n",
       "       'disruption to farming_0_country_8',\n",
       "       'massive starvation_0_country_3', 'massive starvation_0_country_4',\n",
       "       'massive starvation_0_country_5', 'massive starvation_0_country_6',\n",
       "       'massive starvation_0_country_7', 'massive starvation_0_country_8',\n",
       "       'abnormally low rainfall_0_country_3',\n",
       "       'abnormally low rainfall_0_country_4',\n",
       "       'abnormally low rainfall_0_country_5',\n",
       "       'abnormally low rainfall_0_country_6',\n",
       "       'abnormally low rainfall_0_country_7',\n",
       "       'abnormally low rainfall_0_country_8',\n",
       "       'withheld relief_0_country_3', 'withheld relief_0_country_4',\n",
       "       'withheld relief_0_country_5', 'withheld relief_0_country_6',\n",
       "       'withheld relief_0_country_7', 'withheld relief_0_country_8',\n",
       "       'international alarm_0_country_3',\n",
       "       'international alarm_0_country_4',\n",
       "       'international alarm_0_country_5',\n",
       "       'international alarm_0_country_6',\n",
       "       'international alarm_0_country_7',\n",
       "       'international alarm_0_country_8',\n",
       "       'reduced national output_0_country_3',\n",
       "       'reduced national output_0_country_4',\n",
       "       'reduced national output_0_country_5',\n",
       "       'reduced national output_0_country_6',\n",
       "       'reduced national output_0_country_7',\n",
       "       'reduced national output_0_country_8',\n",
       "       'oppressive regimes_0_country_3', 'oppressive regimes_0_country_4',\n",
       "       'oppressive regimes_0_country_5', 'oppressive regimes_0_country_6',\n",
       "       'oppressive regimes_0_country_7', 'oppressive regimes_0_country_8',\n",
       "       'pests_0_country_3', 'pests_0_country_4', 'pests_0_country_5',\n",
       "       'pests_0_country_6', 'pests_0_country_7', 'pests_0_country_8',\n",
       "       'continued deterioration_0_country_3',\n",
       "       'continued deterioration_0_country_4',\n",
       "       'continued deterioration_0_country_5',\n",
       "       'continued deterioration_0_country_6',\n",
       "       'continued deterioration_0_country_7',\n",
       "       'continued deterioration_0_country_8',\n",
       "       'forests destroyed_0_country_3', 'forests destroyed_0_country_4',\n",
       "       'forests destroyed_0_country_5', 'forests destroyed_0_country_6',\n",
       "       'forests destroyed_0_country_7', 'forests destroyed_0_country_8',\n",
       "       'man-made disaster_0_country_3', 'man-made disaster_0_country_4',\n",
       "       'man-made disaster_0_country_5', 'man-made disaster_0_country_6',\n",
       "       'man-made disaster_0_country_7', 'man-made disaster_0_country_8',\n",
       "       'food insecurity_0_country_3', 'food insecurity_0_country_4',\n",
       "       'food insecurity_0_country_5', 'food insecurity_0_country_6',\n",
       "       'food insecurity_0_country_7', 'food insecurity_0_country_8',\n",
       "       'harvests are devastated_0_country_3',\n",
       "       'harvests are devastated_0_country_4',\n",
       "       'harvests are devastated_0_country_5',\n",
       "       'harvests are devastated_0_country_6',\n",
       "       'harvests are devastated_0_country_7',\n",
       "       'harvests are devastated_0_country_8',\n",
       "       'humanitarian situation_0_country_3',\n",
       "       'humanitarian situation_0_country_4',\n",
       "       'humanitarian situation_0_country_5',\n",
       "       'humanitarian situation_0_country_6',\n",
       "       'humanitarian situation_0_country_7',\n",
       "       'humanitarian situation_0_country_8',\n",
       "       'economic impoverishment_0_country_3',\n",
       "       'economic impoverishment_0_country_4',\n",
       "       'economic impoverishment_0_country_5',\n",
       "       'economic impoverishment_0_country_6',\n",
       "       'economic impoverishment_0_country_7',\n",
       "       'economic impoverishment_0_country_8', 'clan battle_0_country_3',\n",
       "       'clan battle_0_country_4', 'clan battle_0_country_5',\n",
       "       'clan battle_0_country_6', 'clan battle_0_country_7',\n",
       "       'clan battle_0_country_8', 'population crisis_0_country_3',\n",
       "       'population crisis_0_country_4', 'population crisis_0_country_5',\n",
       "       'population crisis_0_country_6', 'population crisis_0_country_7',\n",
       "       'population crisis_0_country_8', 'fews_ipc_3', 'fews_ipc_6',\n",
       "       'fews_ipc_9', 'fews_ipc_12', 'fews_ipc_15', 'fews_ipc_18',\n",
       "       'fews_proj_near_3'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save data for Fig 3A, B, C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'year'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[144], line 112\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train, dev, test \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(train_splits, dev_splits, test_splits):\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f, D \u001b[38;5;129;01min\u001b[39;00m features\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 112\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[43mget_time_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m         y \u001b[38;5;241m=\u001b[39m get_time_split(labels_df, test[\u001b[38;5;241m0\u001b[39m], test[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    114\u001b[0m         X_test \u001b[38;5;241m=\u001b[39m get_time_split(D, test[\u001b[38;5;241m0\u001b[39m], test[\u001b[38;5;241m1\u001b[39m])\n",
      "Cell \u001b[0;32mIn[144], line 94\u001b[0m, in \u001b[0;36mget_time_split\u001b[0;34m(df, start, end)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_time_split\u001b[39m(df, start, end):\n\u001b[0;32m---> 94\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43myear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m&\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m start[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m&\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m&\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end[\u001b[38;5;241m1\u001b[39m]]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'year'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "test_splits = [\n",
    "    ((2010,7), (2011, 7)), \n",
    "    ((2011,7), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)), \n",
    "    ((2013,7), (2014, 7)), \n",
    "    ((2014,7), (2015, 7)), \n",
    "    ((2015,7), (2016, 7)), \n",
    "    ((2016,7), (2017, 7)), \n",
    "    ((2017,7), (2018, 7)),\n",
    "    ((2018,7), (2019, 7)), \n",
    "    ((2019,2), (2020, 2)),\n",
    "]\n",
    "train_splits = [\n",
    "    ((2009,7), (2010,4)),\n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2009,7), (2011,10)),\n",
    "    ((2009,7), (2012,7)),\n",
    "    ((2009,7), (2013,7)),\n",
    "    ((2009,7), (2014,1)),\n",
    "    ((2009,7), (2015,1)),\n",
    "    ((2009,7), (2015,10)),\n",
    "    ((2009,7), (2016,10)),\n",
    "    ((2009,7), (2017,2))]\n",
    "dev_splits = [\n",
    "    ((2010,4), (2010, 7)),\n",
    "    ((2011,1), (2011, 7)),\n",
    "    ((2011,10), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)),\n",
    "    ((2013,4), (2014, 7)),\n",
    "    ((2014,1), (2015, 7)),\n",
    "    ((2015,1), (2016, 7)),\n",
    "    ((2015,10), (2017, 7)),\n",
    "    ((2016,10), (2018, 7)),\n",
    "    ((2017,2), (2019, 2)),\n",
    "]\n",
    "rf = RandomForestRegressor(max_features='auto', n_estimators=100, \n",
    "                             min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0)\n",
    "ols = LinearRegression()\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return ['{}_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + ['{}_province_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + ['{}_country_{}'.format(f, t) for f, t in zip(factors, range(3,9))]\n",
    "        \n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ], \n",
    "    'news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ], \n",
    "    'traditional+news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert': time_series['fews_proj_near_3'],\n",
    "    'expert+traditional': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ],\n",
    "    'expert+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert+traditional+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ]\n",
    "}\n",
    "\n",
    "labels_df = time_series['fews_ipc']\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[df['year'] >= start[0] & df['month'] >= start[1] & df['year'] <= end[0] & df['month'] <= end[1]]\n",
    "\n",
    "\n",
    "fig_3a = pd.DataFrame(columns=['method', 'split', 'features', 'country', 'rmse', 'lower_bound', 'upper_bound'])\n",
    "fig_3b = pd.DataFrame(columns=['method', 'split', 'features', 'aucpr'])\n",
    "fig_3c = pd.DataFrame(columns=['method', 'split', 'features', 'recall_at_80p'])\n",
    "\n",
    "thresholds = {'traditional': (2.236, 3.125), \n",
    "              'news': (1.907, 2.712), \n",
    "              'traditional+news': (2.105, 3.314),\n",
    "              'expert': (2, 3),\n",
    "              'expert+news': (1.912, 2.813),\n",
    "              'expert+traditional': (2.241, 3.132),\n",
    "              'expert+traditional+news': (2.172, 3.321)\n",
    "             }\n",
    "\n",
    "for train, dev, test in zip(train_splits, dev_splits, test_splits):\n",
    "    for f, D in features.items():\n",
    "        X = get_time_split(D, train[0], train[1])\n",
    "        y = get_time_split(labels_df, test[0], test[1])\n",
    "        X_test = get_time_split(D, test[0], test[1])\n",
    "        for name, regr in zip(['RF', 'OLS', 'Lasso'], [rf, ols, lasso]):\n",
    "            regr.fit(X, y)\n",
    "            preds = regr.predict(X_test)\n",
    "            labels = get_time_split(labels_df, test[0], test[1])\n",
    "            rmse = mean_squared_error(labels, preds, squared=False)\n",
    "            stderr = diebold_mariano(preds, labels)\n",
    "            upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "            lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "            precision, recall, thresholds = precision_recall_curve(labels, preds)\n",
    "            auc_precision_recall = auc(recall, precision)\n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], 'country': ['all'],\n",
    "                                           'rmse': [rmse], 'lower_bound': [lower_bound], 'upper_bound': [upper_bound]},\n",
    "                                          orient='columns')\n",
    "            fig_3a = pd.concat([fig_3a, _row], axis=0)\n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], \n",
    "                                           'aucpr': [auc_precision_recall]},\n",
    "                                          orient='columns')\n",
    "            fig_3b = pd.concat([fig_3b, _row], axis=0)\n",
    "            print (\"Method: {}, Split: {}, Features: {}, AUCPR: {}\".format(name, test, f, auc_precision_recall))\n",
    "            print (\"Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(name, test, f, rmse, lower_bound, upper_bound))\n",
    "            \n",
    "            recall_at_80p = 0\n",
    "            for p_t, p_t_add_3, p_t_min_3 in zip(preds, preds[3:] + [1,1,1], preds[:-3]+[5,5,5]):\n",
    "                u_b = thresholds[f]['upper_bound']\n",
    "                l_b = thresholds[f]['lower_bound']\n",
    "                if p_t >= u_b and p_t_add_3 >= u_b and p_t_min_3 <= l_b:\n",
    "                    recall_at_80p += 1\n",
    "            \n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], \n",
    "                                           'recall_at_80p': [recall_at_80p]},\n",
    "                                          orient='columns')\n",
    "            fig_3c = pd.concat([fig_3c, _row], axis=0)\n",
    "            \n",
    "            for country in time_series['country'].unique():\n",
    "                c_id = X_test[X_test['country']==country]\n",
    "                labels_c = labels[c_id]\n",
    "                preds_c = preds[c_id]\n",
    "                rmse = mean_squared_error(labels_c, preds_c, squared=False)\n",
    "                stderr = diebold_mariano(preds_c, labels_c)\n",
    "                upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "                lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "                _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], 'country': [country],\n",
    "                                           'rmse': [rmse], 'lower_bound': [lower_bound], 'upper_bound': [upper_bound]},\n",
    "                                          orient='columns')\n",
    "                fig_3a = pd.concat([fig_3a, _row], axis=0)\n",
    "                print (\"Country: {}, Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(country, name, test, f, rmse, lower_bound, upper_bound))\n",
    "\n",
    "fig_3a.to_csv('fig_3a.csv')\n",
    "fig_3b.to_csv('fig_3b.csv')\n",
    "fig_3c.to_csv('fig_3c.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
