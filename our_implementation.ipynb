{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy gdown matplotlib seaborn scikit-learn editdistance fuzzywuzzy --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gdown\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_list(list_to_print):\n",
    "    formatted_columns = \"\\n- \" + \"\\n- \".join(list_to_print)  \n",
    "    formatted_columns = sorted(list_to_print)\n",
    "    print(\"\\n- \" + \"\\n- \".join(formatted_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have the data downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "admins = pd.read_csv('./data/famine-country-province-district-years-CS.csv')\n",
    "time_series = pd.read_csv('./data/time_series_with_causes_zscore_full.csv')\n",
    "valid_matching = pd.read_csv('./data/matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>centx</th>\n",
       "      <th>centy</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>...</th>\n",
       "      <th>carbon_2</th>\n",
       "      <th>mayhem_0</th>\n",
       "      <th>mayhem_1</th>\n",
       "      <th>mayhem_2</th>\n",
       "      <th>dehydrated_0</th>\n",
       "      <th>dehydrated_1</th>\n",
       "      <th>dehydrated_2</th>\n",
       "      <th>mismanagement_0</th>\n",
       "      <th>mismanagement_1</th>\n",
       "      <th>mismanagement_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>1.053000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>-0.171000</td>\n",
       "      <td>-0.833000</td>\n",
       "      <td>0.173667</td>\n",
       "      <td>0.168000</td>\n",
       "      <td>1.284667</td>\n",
       "      <td>-0.073000</td>\n",
       "      <td>-0.427667</td>\n",
       "      <td>0.668333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.660812</td>\n",
       "      <td>-0.636580</td>\n",
       "      <td>-0.520247</td>\n",
       "      <td>-0.782913</td>\n",
       "      <td>-0.671587</td>\n",
       "      <td>-0.612254</td>\n",
       "      <td>-0.926921</td>\n",
       "      <td>-0.510467</td>\n",
       "      <td>-0.625133</td>\n",
       "      <td>-0.452467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.134333</td>\n",
       "      <td>1.447667</td>\n",
       "      <td>-0.844333</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>-0.676000</td>\n",
       "      <td>-0.689667</td>\n",
       "      <td>0.293333</td>\n",
       "      <td>0.530333</td>\n",
       "      <td>-0.471333</td>\n",
       "      <td>0.955333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326927</td>\n",
       "      <td>-0.594877</td>\n",
       "      <td>0.164790</td>\n",
       "      <td>-0.905210</td>\n",
       "      <td>-0.620540</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.045794</td>\n",
       "      <td>-1.011600</td>\n",
       "      <td>-0.810600</td>\n",
       "      <td>-0.205600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>65.709343</td>\n",
       "      <td>31.043618</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.085146</td>\n",
       "      <td>-0.709913</td>\n",
       "      <td>-0.867913</td>\n",
       "      <td>-0.770247</td>\n",
       "      <td>-0.787921</td>\n",
       "      <td>-0.974587</td>\n",
       "      <td>-0.946921</td>\n",
       "      <td>-0.611133</td>\n",
       "      <td>-0.709800</td>\n",
       "      <td>-0.622800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 532 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index      country  admin_code admin_name      centx  \\\n",
       "0           0     30  Afghanistan         202   Kandahar  65.709343   \n",
       "1           1     33  Afghanistan         202   Kandahar  65.709343   \n",
       "2           2     36  Afghanistan         202   Kandahar  65.709343   \n",
       "3           3     39  Afghanistan         202   Kandahar  65.709343   \n",
       "4           4     42  Afghanistan         202   Kandahar  65.709343   \n",
       "\n",
       "       centy year_month  year  month  ...  carbon_2  mayhem_0  mayhem_1  \\\n",
       "0  31.043618    2009_07  2009      7  ...  1.053000  0.667000 -0.171000   \n",
       "1  31.043618    2009_10  2009     10  ... -0.660812 -0.636580 -0.520247   \n",
       "2  31.043618    2010_01  2010      1  ... -0.134333  1.447667 -0.844333   \n",
       "3  31.043618    2010_04  2010      4  ... -0.326927 -0.594877  0.164790   \n",
       "4  31.043618    2010_07  2010      7  ... -1.085146 -0.709913 -0.867913   \n",
       "\n",
       "   mayhem_2  dehydrated_0  dehydrated_1  dehydrated_2  mismanagement_0  \\\n",
       "0 -0.833000      0.173667      0.168000      1.284667        -0.073000   \n",
       "1 -0.782913     -0.671587     -0.612254     -0.926921        -0.510467   \n",
       "2  0.778667     -0.676000     -0.689667      0.293333         0.530333   \n",
       "3 -0.905210     -0.620540      0.165794      0.045794        -1.011600   \n",
       "4 -0.770247     -0.787921     -0.974587     -0.946921        -0.611133   \n",
       "\n",
       "   mismanagement_1  mismanagement_2  \n",
       "0        -0.427667         0.668333  \n",
       "1        -0.625133        -0.452467  \n",
       "2        -0.471333         0.955333  \n",
       "3        -0.810600        -0.205600  \n",
       "4        -0.709800        -0.622800  \n",
       "\n",
       "[5 rows x 532 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.drop_duplicates(inplace=True)\n",
    "time_series.drop(columns=[\"Unnamed: 0\", \"centx\", \"centy\", ], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows :  40952\n",
      "No. of columns :  530\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of rows : \", time_series.shape[0])\n",
    "print(\"No. of columns : \", time_series.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üóÇÔ∏è The column names in the dataset are as follows:\n",
      "\n",
      "\n",
      "- abnormally low rainfall_0\n",
      "- abnormally low rainfall_1\n",
      "- abnormally low rainfall_2\n",
      "- acled_count\n",
      "- acled_fatalities\n",
      "- acute hunger_0\n",
      "- acute hunger_1\n",
      "- acute hunger_2\n",
      "- admin_code\n",
      "- admin_name\n",
      "- aid appeal_0\n",
      "- aid appeal_1\n",
      "- aid appeal_2\n",
      "- aid workers died_0\n",
      "- aid workers died_1\n",
      "- aid workers died_2\n",
      "- air attack_0\n",
      "- air attack_1\n",
      "- air attack_2\n",
      "- alarming level_0\n",
      "- alarming level_1\n",
      "- alarming level_2\n",
      "- anti-western policies_0\n",
      "- anti-western policies_1\n",
      "- anti-western policies_2\n",
      "- apathy_0\n",
      "- apathy_1\n",
      "- apathy_2\n",
      "- area\n",
      "- asylum seekers_0\n",
      "- asylum seekers_1\n",
      "- asylum seekers_2\n",
      "- authoritarian_0\n",
      "- authoritarian_1\n",
      "- authoritarian_2\n",
      "- bad harvests_0\n",
      "- bad harvests_1\n",
      "- bad harvests_2\n",
      "- blockade_0\n",
      "- blockade_1\n",
      "- blockade_2\n",
      "- bombing campaign_0\n",
      "- bombing campaign_1\n",
      "- bombing campaign_2\n",
      "- brain drain_0\n",
      "- brain drain_1\n",
      "- brain drain_2\n",
      "- brutal government_0\n",
      "- brutal government_1\n",
      "- brutal government_2\n",
      "- burning houses_0\n",
      "- burning houses_1\n",
      "- burning houses_2\n",
      "- call for donations_0\n",
      "- call for donations_1\n",
      "- call for donations_2\n",
      "- carbon_0\n",
      "- carbon_1\n",
      "- carbon_2\n",
      "- catastrophe_0\n",
      "- catastrophe_1\n",
      "- catastrophe_2\n",
      "- cattle death_0\n",
      "- cattle death_1\n",
      "- cattle death_2\n",
      "- cattle plague_0\n",
      "- cattle plague_1\n",
      "- cattle plague_2\n",
      "- centx\n",
      "- centy\n",
      "- change_fews\n",
      "- cholera outbreak_0\n",
      "- cholera outbreak_1\n",
      "- cholera outbreak_2\n",
      "- civil strife_0\n",
      "- civil strife_1\n",
      "- civil strife_2\n",
      "- civilians uprooted_0\n",
      "- civilians uprooted_1\n",
      "- civilians uprooted_2\n",
      "- clan battle_0\n",
      "- clan battle_1\n",
      "- clan battle_2\n",
      "- clan warfare_0\n",
      "- clan warfare_1\n",
      "- clan warfare_2\n",
      "- clans_0\n",
      "- clans_1\n",
      "- clans_2\n",
      "- climate change_0\n",
      "- climate change_1\n",
      "- climate change_2\n",
      "- climatic hazards_0\n",
      "- climatic hazards_1\n",
      "- climatic hazards_2\n",
      "- collapse of government_0\n",
      "- collapse of government_1\n",
      "- collapse of government_2\n",
      "- collapsing economy_0\n",
      "- collapsing economy_1\n",
      "- collapsing economy_2\n",
      "- conflict_0\n",
      "- conflict_1\n",
      "- conflict_2\n",
      "- continued deterioration_0\n",
      "- continued deterioration_1\n",
      "- continued deterioration_2\n",
      "- continued strife_0\n",
      "- continued strife_1\n",
      "- continued strife_2\n",
      "- convoys_0\n",
      "- convoys_1\n",
      "- convoys_2\n",
      "- corrupt government_0\n",
      "- corrupt government_1\n",
      "- corrupt government_2\n",
      "- corruption_0\n",
      "- corruption_1\n",
      "- corruption_2\n",
      "- country\n",
      "- coup_0\n",
      "- coup_1\n",
      "- coup_2\n",
      "- cropland_pct\n",
      "- cycle of poverty_0\n",
      "- cycle of poverty_1\n",
      "- cycle of poverty_2\n",
      "- cyclone_0\n",
      "- cyclone_1\n",
      "- cyclone_2\n",
      "- d'etat_0\n",
      "- d'etat_1\n",
      "- d'etat_2\n",
      "- dehydrated_0\n",
      "- dehydrated_1\n",
      "- dehydrated_2\n",
      "- destructive pattern_0\n",
      "- destructive pattern_1\n",
      "- destructive pattern_2\n",
      "- devastated the economy_0\n",
      "- devastated the economy_1\n",
      "- devastated the economy_2\n",
      "- dictators_0\n",
      "- dictators_1\n",
      "- dictators_2\n",
      "- displaced_0\n",
      "- displaced_1\n",
      "- displaced_2\n",
      "- disrupted trade_0\n",
      "- disrupted trade_1\n",
      "- disrupted trade_2\n",
      "- disruption to farming_0\n",
      "- disruption to farming_1\n",
      "- disruption to farming_2\n",
      "- drought_0\n",
      "- drought_1\n",
      "- drought_2\n",
      "- dysfunction_0\n",
      "- dysfunction_1\n",
      "- dysfunction_2\n",
      "- ecological crisis_0\n",
      "- ecological crisis_1\n",
      "- ecological crisis_2\n",
      "- economic crisis_0\n",
      "- economic crisis_1\n",
      "- economic crisis_2\n",
      "- economic impoverishment_0\n",
      "- economic impoverishment_1\n",
      "- economic impoverishment_2\n",
      "- environmental degradation_0\n",
      "- environmental degradation_1\n",
      "- environmental degradation_2\n",
      "- epidemics_0\n",
      "- epidemics_1\n",
      "- epidemics_2\n",
      "- et_anom\n",
      "- et_mean\n",
      "- failed crops_0\n",
      "- failed crops_1\n",
      "- failed crops_2\n",
      "- failed rains_0\n",
      "- failed rains_1\n",
      "- failed rains_2\n",
      "- farmland_0\n",
      "- farmland_1\n",
      "- farmland_2\n",
      "- fews_ha\n",
      "- fews_ipc\n",
      "- fews_proj_med\n",
      "- fews_proj_med_ha\n",
      "- fews_proj_near\n",
      "- fews_proj_near_ha\n",
      "- flee_0\n",
      "- flee_1\n",
      "- flee_2\n",
      "- floods_0\n",
      "- floods_1\n",
      "- floods_2\n",
      "- food assistance_0\n",
      "- food assistance_1\n",
      "- food assistance_2\n",
      "- food crisis_0\n",
      "- food crisis_1\n",
      "- food crisis_2\n",
      "- food insecurity_0\n",
      "- food insecurity_1\n",
      "- food insecurity_2\n",
      "- foreign aid_0\n",
      "- foreign aid_1\n",
      "- foreign aid_2\n",
      "- foreign troops_0\n",
      "- foreign troops_1\n",
      "- foreign troops_2\n",
      "- forests destroyed_0\n",
      "- forests destroyed_1\n",
      "- forests destroyed_2\n",
      "- gangs of bandits_0\n",
      "- gangs of bandits_1\n",
      "- gangs of bandits_2\n",
      "- gastrointestinal_0\n",
      "- gastrointestinal_1\n",
      "- gastrointestinal_2\n",
      "- greenhouse gases_0\n",
      "- greenhouse gases_1\n",
      "- greenhouse gases_2\n",
      "- harvest decline_0\n",
      "- harvest decline_1\n",
      "- harvest decline_2\n",
      "- harvests are devastated_0\n",
      "- harvests are devastated_1\n",
      "- harvests are devastated_2\n",
      "- human rights abuses_0\n",
      "- human rights abuses_1\n",
      "- human rights abuses_2\n",
      "- humanitarian disaster_0\n",
      "- humanitarian disaster_1\n",
      "- humanitarian disaster_2\n",
      "- humanitarian situation_0\n",
      "- humanitarian situation_1\n",
      "- humanitarian situation_2\n",
      "- hunger crises_0\n",
      "- hunger crises_1\n",
      "- hunger crises_2\n",
      "- inadequate rainfall_0\n",
      "- inadequate rainfall_1\n",
      "- inadequate rainfall_2\n",
      "- increased external debt_0\n",
      "- increased external debt_1\n",
      "- increased external debt_2\n",
      "- index\n",
      "- infant mortality_0\n",
      "- infant mortality_1\n",
      "- infant mortality_2\n",
      "- infrastructure damage_0\n",
      "- infrastructure damage_1\n",
      "- infrastructure damage_2\n",
      "- internal strife_0\n",
      "- internal strife_1\n",
      "- internal strife_2\n",
      "- international alarm_0\n",
      "- international alarm_1\n",
      "- international alarm_2\n",
      "- international embargo_0\n",
      "- international embargo_1\n",
      "- international embargo_2\n",
      "- international intervention_0\n",
      "- international intervention_1\n",
      "- international intervention_2\n",
      "- international terrorists_0\n",
      "- international terrorists_1\n",
      "- international terrorists_2\n",
      "- jihadist groups_0\n",
      "- jihadist groups_1\n",
      "- jihadist groups_2\n",
      "- lack of agricultural infrastructure_0\n",
      "- lack of agricultural infrastructure_1\n",
      "- lack of agricultural infrastructure_2\n",
      "- lack of alternatives_0\n",
      "- lack of alternatives_1\n",
      "- lack of alternatives_2\n",
      "- lack of authority_0\n",
      "- lack of authority_1\n",
      "- lack of authority_2\n",
      "- lack of cultivation_0\n",
      "- lack of cultivation_1\n",
      "- lack of cultivation_2\n",
      "- lack of rains_0\n",
      "- lack of rains_1\n",
      "- lack of rains_2\n",
      "- lack of roads_0\n",
      "- lack of roads_1\n",
      "- lack of roads_2\n",
      "- land degradation_0\n",
      "- land degradation_1\n",
      "- land degradation_2\n",
      "- land grab_0\n",
      "- land grab_1\n",
      "- land grab_2\n",
      "- land invasions_0\n",
      "- land invasions_1\n",
      "- land invasions_2\n",
      "- land reform_0\n",
      "- land reform_1\n",
      "- land reform_2\n",
      "- land seizures_0\n",
      "- land seizures_1\n",
      "- land seizures_2\n",
      "- life-threatening hunger_0\n",
      "- life-threatening hunger_1\n",
      "- life-threatening hunger_2\n",
      "- livestock had died_0\n",
      "- livestock had died_1\n",
      "- livestock had died_2\n",
      "- locusts_0\n",
      "- locusts_1\n",
      "- locusts_2\n",
      "- looting_0\n",
      "- looting_1\n",
      "- looting_2\n",
      "- major offensive_0\n",
      "- major offensive_1\n",
      "- major offensive_2\n",
      "- makeshift camps_0\n",
      "- makeshift camps_1\n",
      "- makeshift camps_2\n",
      "- malnourished_0\n",
      "- malnourished_1\n",
      "- malnourished_2\n",
      "- man-made disaster_0\n",
      "- man-made disaster_1\n",
      "- man-made disaster_2\n",
      "- mass hunger_0\n",
      "- mass hunger_1\n",
      "- mass hunger_2\n",
      "- massive starvation_0\n",
      "- massive starvation_1\n",
      "- massive starvation_2\n",
      "- mayhem_0\n",
      "- mayhem_1\n",
      "- mayhem_2\n",
      "- migration_0\n",
      "- migration_1\n",
      "- migration_2\n",
      "- military dictatorship_0\n",
      "- military dictatorship_1\n",
      "- military dictatorship_2\n",
      "- military junta_0\n",
      "- military junta_1\n",
      "- military junta_2\n",
      "- militia groups_0\n",
      "- militia groups_1\n",
      "- militia groups_2\n",
      "- mismanagement_0\n",
      "- mismanagement_1\n",
      "- mismanagement_2\n",
      "- month\n",
      "- natural disaster_0\n",
      "- natural disaster_1\n",
      "- natural disaster_2\n",
      "- ndvi_anom\n",
      "- ndvi_mean\n",
      "- oppressive regimes_0\n",
      "- oppressive regimes_1\n",
      "- oppressive regimes_2\n",
      "- overthrow_0\n",
      "- overthrow_1\n",
      "- overthrow_2\n",
      "- p_staple_food\n",
      "- pasture_pct\n",
      "- pests_0\n",
      "- pests_1\n",
      "- pests_2\n",
      "- pirates_0\n",
      "- pirates_1\n",
      "- pirates_2\n",
      "- police torture_0\n",
      "- police torture_1\n",
      "- police torture_2\n",
      "- politically engineered_0\n",
      "- politically engineered_1\n",
      "- politically engineered_2\n",
      "- poor soil quality_0\n",
      "- poor soil quality_1\n",
      "- poor soil quality_2\n",
      "- pop\n",
      "- population crisis_0\n",
      "- population crisis_1\n",
      "- population crisis_2\n",
      "- potato blight_0\n",
      "- potato blight_1\n",
      "- potato blight_2\n",
      "- power struggle_0\n",
      "- power struggle_1\n",
      "- power struggle_2\n",
      "- price of food_0\n",
      "- price of food_1\n",
      "- price of food_2\n",
      "- price rise_0\n",
      "- price rise_1\n",
      "- price rise_2\n",
      "- prolonged dry spell_0\n",
      "- prolonged dry spell_1\n",
      "- prolonged dry spell_2\n",
      "- prolonged fighting_0\n",
      "- prolonged fighting_1\n",
      "- prolonged fighting_2\n",
      "- pushing peasants off_0\n",
      "- pushing peasants off_1\n",
      "- pushing peasants off_2\n",
      "- rain_anom\n",
      "- rain_mean\n",
      "- rebel insurgency_0\n",
      "- rebel insurgency_1\n",
      "- rebel insurgency_2\n",
      "- reduced imports_0\n",
      "- reduced imports_1\n",
      "- reduced imports_2\n",
      "- reduced national output_0\n",
      "- reduced national output_1\n",
      "- reduced national output_2\n",
      "- refugees_0\n",
      "- refugees_1\n",
      "- refugees_2\n",
      "- regimes were toppled_0\n",
      "- regimes were toppled_1\n",
      "- regimes were toppled_2\n",
      "- repression_0\n",
      "- repression_1\n",
      "- repression_2\n",
      "- restricted humanitarian access_0\n",
      "- restricted humanitarian access_1\n",
      "- restricted humanitarian access_2\n",
      "- restricted relief flights_0\n",
      "- restricted relief flights_1\n",
      "- restricted relief flights_2\n",
      "- rinderpest_0\n",
      "- rinderpest_1\n",
      "- rinderpest_2\n",
      "- rise_0\n",
      "- rise_1\n",
      "- rise_2\n",
      "- rising food prices_0\n",
      "- rising food prices_1\n",
      "- rising food prices_2\n",
      "- rising inflation_0\n",
      "- rising inflation_1\n",
      "- rising inflation_2\n",
      "- rival warlords_0\n",
      "- rival warlords_1\n",
      "- rival warlords_2\n",
      "- ruggedness_mean\n",
      "- scanty rainfall_0\n",
      "- scanty rainfall_1\n",
      "- scanty rainfall_2\n",
      "- secession_0\n",
      "- secession_1\n",
      "- secession_2\n",
      "- self reliance_0\n",
      "- self reliance_1\n",
      "- self reliance_2\n",
      "- severe rains_0\n",
      "- severe rains_1\n",
      "- severe rains_2\n",
      "- shortage of rains_0\n",
      "- shortage of rains_1\n",
      "- shortage of rains_2\n",
      "- siege_0\n",
      "- siege_1\n",
      "- siege_2\n",
      "- slashed export_0\n",
      "- slashed export_1\n",
      "- slashed export_2\n",
      "- slave trade_0\n",
      "- slave trade_1\n",
      "- slave trade_2\n",
      "- stolen food aid_0\n",
      "- stolen food aid_1\n",
      "- stolen food aid_2\n",
      "- terrorism_0\n",
      "- terrorism_1\n",
      "- terrorism_2\n",
      "- terrorist_0\n",
      "- terrorist_1\n",
      "- terrorist_2\n",
      "- the offensive_0\n",
      "- the offensive_1\n",
      "- the offensive_2\n",
      "- toll on livestock_0\n",
      "- toll on livestock_1\n",
      "- toll on livestock_2\n",
      "- totalitarian_0\n",
      "- totalitarian_1\n",
      "- totalitarian_2\n",
      "- tragedy_0\n",
      "- tragedy_1\n",
      "- tragedy_2\n",
      "- transport bottleneck_0\n",
      "- transport bottleneck_1\n",
      "- transport bottleneck_2\n",
      "- unable to sow_0\n",
      "- unable to sow_1\n",
      "- unable to sow_2\n",
      "- violent suppression_0\n",
      "- violent suppression_1\n",
      "- violent suppression_2\n",
      "- warlord_0\n",
      "- warlord_1\n",
      "- warlord_2\n",
      "- water availability_0\n",
      "- water availability_1\n",
      "- water availability_2\n",
      "- water distribution shortages_0\n",
      "- water distribution shortages_1\n",
      "- water distribution shortages_2\n",
      "- weather extremes_0\n",
      "- weather extremes_1\n",
      "- weather extremes_2\n",
      "- withheld relief_0\n",
      "- withheld relief_1\n",
      "- withheld relief_2\n",
      "- without international aid_0\n",
      "- without international aid_1\n",
      "- without international aid_2\n",
      "- wreaked havoc_0\n",
      "- wreaked havoc_1\n",
      "- wreaked havoc_2\n",
      "- year\n",
      "- years of warfare_0\n",
      "- years of warfare_1\n",
      "- years of warfare_2\n"
     ]
    }
   ],
   "source": [
    "columns_list = time_series.columns.to_list()\n",
    "\n",
    "print(\"\\nüóÇÔ∏è The column names in the dataset are as follows:\\n\")\n",
    "pretty_print_list(columns_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **traditional risk factors** used in the study are categorized into **time-variant** (changing over time) and **time-invariant** (fixed for a given district). Below is the mapping between these risk factors and their corresponding **columns in the time series dataset** which I picked directly from the paper itself.:\n",
    "\n",
    "---\n",
    "\n",
    "##### **üìå Time-Variant Factors (Change Over Time)**\n",
    "| **Traditional Risk Factor** | **Time Series Column** | **Description** |\n",
    "|----------------------------|-----------------------|----------------|\n",
    "| **Violent Conflict Events** | `acled_count` | Monthly count of conflict events. |\n",
    "| **Conflict Fatalities per Event** | `acled_fatalities` | Average number of fatalities per conflict event. |\n",
    "| **Food Prices Index (Log Nominal)** | `p_staple_food` | Monthly log nominal food price index. |\n",
    "| **Food Prices Year-on-Year Difference** | `p_staple_food_diff` | Change in food price index compared to the previous year. |\n",
    "| **Evapotranspiration Index (Mean)** | `et_mean` | Monthly mean of evapotranspiration (water loss from soil and plants). |\n",
    "| **Rainfall Index (Mean)** | `rain_mean` | Monthly mean rainfall in the district. |\n",
    "| **Rainfall Deviation from Average** | `rain_anom` | Difference between actual rainfall and seasonal average. |\n",
    "| **Normalized Difference Vegetation Index (Mean)** | `ndvi_mean` | Satellite-derived measure of vegetation health. |\n",
    "| **Vegetation Deviation from Average** | `ndvi_anom` | Difference between actual NDVI and historical average. |\n",
    "\n",
    "---\n",
    "\n",
    "##### **üìå Time-Invariant Factors (Fixed for a District)**\n",
    "| **Traditional Risk Factor** | **Time Series Column** | **Description** |\n",
    "|----------------------------|-----------------------|----------------|\n",
    "| **Population Count** | `pop` | Estimated population in the district. |\n",
    "| **Terrain Ruggedness Index** | `ruggedness_mean` | Measures how rough the terrain is. |\n",
    "| **District Size** | `area` | Total land area of the district. |\n",
    "| **Share of Cropland Use** | `cropland_pct` | Percentage of district area used for cropland. |\n",
    "| **Share of Pasture Use** | `pasture_pct` | Percentage of district area used for pasture. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = ['ndvi_mean', 'ndvi_anom', 'rain_mean', 'rain_anom', 'et_mean', 'et_anom', \n",
    "                                    'acled_count', 'acled_fatalities', 'p_staple_food'] # 9 traditional variant factors\n",
    "t_invariant_traditional_factors = ['area', 'cropland_pct', 'pop', 'ruggedness_mean', 'pasture_pct'] # 5 invariant factors\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There 167 news factors are as follows:\n",
      "\n",
      "\n",
      "- abnormally low rainfall_0\n",
      "- acute hunger_0\n",
      "- aid appeal_0\n",
      "- aid workers died_0\n",
      "- air attack_0\n",
      "- alarming level_0\n",
      "- anti-western policies_0\n",
      "- apathy_0\n",
      "- asylum seekers_0\n",
      "- authoritarian_0\n",
      "- bad harvests_0\n",
      "- blockade_0\n",
      "- bombing campaign_0\n",
      "- brain drain_0\n",
      "- brutal government_0\n",
      "- burning houses_0\n",
      "- call for donations_0\n",
      "- carbon_0\n",
      "- catastrophe_0\n",
      "- cattle death_0\n",
      "- cattle plague_0\n",
      "- cholera outbreak_0\n",
      "- civil strife_0\n",
      "- civilians uprooted_0\n",
      "- clan battle_0\n",
      "- clan warfare_0\n",
      "- clans_0\n",
      "- climate change_0\n",
      "- climatic hazards_0\n",
      "- collapse of government_0\n",
      "- collapsing economy_0\n",
      "- conflict_0\n",
      "- continued deterioration_0\n",
      "- continued strife_0\n",
      "- convoys_0\n",
      "- corrupt government_0\n",
      "- corruption_0\n",
      "- coup_0\n",
      "- cycle of poverty_0\n",
      "- cyclone_0\n",
      "- d'etat_0\n",
      "- dehydrated_0\n",
      "- destructive pattern_0\n",
      "- devastated the economy_0\n",
      "- dictators_0\n",
      "- displaced_0\n",
      "- disrupted trade_0\n",
      "- disruption to farming_0\n",
      "- drought_0\n",
      "- dysfunction_0\n",
      "- ecological crisis_0\n",
      "- economic crisis_0\n",
      "- economic impoverishment_0\n",
      "- environmental degradation_0\n",
      "- epidemics_0\n",
      "- failed crops_0\n",
      "- failed rains_0\n",
      "- farmland_0\n",
      "- flee_0\n",
      "- floods_0\n",
      "- food assistance_0\n",
      "- food crisis_0\n",
      "- food insecurity_0\n",
      "- foreign aid_0\n",
      "- foreign troops_0\n",
      "- forests destroyed_0\n",
      "- gangs of bandits_0\n",
      "- gastrointestinal_0\n",
      "- greenhouse gases_0\n",
      "- harvest decline_0\n",
      "- harvests are devastated_0\n",
      "- human rights abuses_0\n",
      "- humanitarian disaster_0\n",
      "- humanitarian situation_0\n",
      "- hunger crises_0\n",
      "- inadequate rainfall_0\n",
      "- increased external debt_0\n",
      "- infant mortality_0\n",
      "- infrastructure damage_0\n",
      "- internal strife_0\n",
      "- international alarm_0\n",
      "- international embargo_0\n",
      "- international intervention_0\n",
      "- international terrorists_0\n",
      "- jihadist groups_0\n",
      "- lack of agricultural infrastructure_0\n",
      "- lack of alternatives_0\n",
      "- lack of authority_0\n",
      "- lack of cultivation_0\n",
      "- lack of rains_0\n",
      "- lack of roads_0\n",
      "- land degradation_0\n",
      "- land grab_0\n",
      "- land invasions_0\n",
      "- land reform_0\n",
      "- land seizures_0\n",
      "- life-threatening hunger_0\n",
      "- livestock had died_0\n",
      "- locusts_0\n",
      "- looting_0\n",
      "- major offensive_0\n",
      "- makeshift camps_0\n",
      "- malnourished_0\n",
      "- man-made disaster_0\n",
      "- mass hunger_0\n",
      "- massive starvation_0\n",
      "- mayhem_0\n",
      "- migration_0\n",
      "- military dictatorship_0\n",
      "- military junta_0\n",
      "- militia groups_0\n",
      "- mismanagement_0\n",
      "- natural disaster_0\n",
      "- oppressive regimes_0\n",
      "- overthrow_0\n",
      "- pests_0\n",
      "- pirates_0\n",
      "- police torture_0\n",
      "- politically engineered_0\n",
      "- poor soil quality_0\n",
      "- population crisis_0\n",
      "- potato blight_0\n",
      "- power struggle_0\n",
      "- price of food_0\n",
      "- price rise_0\n",
      "- prolonged dry spell_0\n",
      "- prolonged fighting_0\n",
      "- pushing peasants off_0\n",
      "- rebel insurgency_0\n",
      "- reduced imports_0\n",
      "- reduced national output_0\n",
      "- refugees_0\n",
      "- regimes were toppled_0\n",
      "- repression_0\n",
      "- restricted humanitarian access_0\n",
      "- restricted relief flights_0\n",
      "- rinderpest_0\n",
      "- rise_0\n",
      "- rising food prices_0\n",
      "- rising inflation_0\n",
      "- rival warlords_0\n",
      "- scanty rainfall_0\n",
      "- secession_0\n",
      "- self reliance_0\n",
      "- severe rains_0\n",
      "- shortage of rains_0\n",
      "- siege_0\n",
      "- slashed export_0\n",
      "- slave trade_0\n",
      "- stolen food aid_0\n",
      "- terrorism_0\n",
      "- terrorist_0\n",
      "- the offensive_0\n",
      "- toll on livestock_0\n",
      "- totalitarian_0\n",
      "- tragedy_0\n",
      "- transport bottleneck_0\n",
      "- unable to sow_0\n",
      "- violent suppression_0\n",
      "- warlord_0\n",
      "- water availability_0\n",
      "- water distribution shortages_0\n",
      "- weather extremes_0\n",
      "- withheld relief_0\n",
      "- without international aid_0\n",
      "- wreaked havoc_0\n",
      "- years of warfare_0\n"
     ]
    }
   ],
   "source": [
    "print(f\"The {len(news_factors)} news factors are as follows:\\n\")\n",
    "pretty_print_list(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lagged(x, f, t):\n",
    "    \"\"\"\n",
    "    Retrieve the lagged value of a specified feature for a given time lag.\n",
    "\n",
    "    Parameters:\n",
    "    x (pd.Series): A row from the time_series DataFrame.\n",
    "    f (str): The feature/column name for which the lagged value is to be retrieved.\n",
    "    t (int): The time lag in months.\n",
    "\n",
    "    Returns:\n",
    "    float: The lagged value of the specified feature. If the lagged value is not available, returns the current value of the feature.\n",
    "    \"\"\"\n",
    "    admin_code = x['admin_code']\n",
    "    year = x['year']\n",
    "    month = x['month']\n",
    "    l_month = ((month-1-t)%12)+1\n",
    "    l_year = year\n",
    "    if month-t <= 0:\n",
    "        l_year -= 1\n",
    "    ts = time_series[time_series['admin_code'] == admin_code]\n",
    "    lagged_year_month = '{}_{}'.format(l_year, l_month)\n",
    "    if lagged_year_month in ts['year_month'].values:\n",
    "        ts = ts[ts['year_month'] == lagged_year_month]\n",
    "        return ts[f].values[0]\n",
    "    else:\n",
    "        return x[f]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_series['year_month'] = pd.to_datetime(time_series['year'].astype(str) + '-' + time_series['month'].astype(str))\n",
    "\n",
    "\n",
    "def create_lagged_features(df, feature, lag):\n",
    "    df_lagged = df[['admin_code', 'year_month', feature]].copy()\n",
    "    df_lagged['year_month'] += pd.DateOffset(months=lag)  \n",
    "    df_lagged.rename(columns={feature: f'{feature}_lag{lag}'}, inplace=True)\n",
    "    return df_lagged\n",
    "\n",
    "lagged_features = create_lagged_features(time_series, 'rainfall', 3)\n",
    "\n",
    "time_series = time_series.merge(lagged_features, on=['admin_code', 'year_month'], how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True):\n",
    "    if agg:\n",
    "        levels = ['', '_province', '_country']\n",
    "    else:\n",
    "        levels = ['']\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f+suffix\n",
    "            for t in range(start,end,diff):\n",
    "                if '{}_{}'.format(f_s,t) in time_series:\n",
    "                    continue\n",
    "                time_series['{}_{}'.format(f_s,t)] = time_series.apply(lambda x: get_lagged(x, f_s, t), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Admin level mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üåç The unique countries in the admin dataset are as follows:\n",
      "\n",
      "\n",
      "- Abyei\n",
      "- Afghanistan\n",
      "- Angola\n",
      "- Burkina Faso\n",
      "- Burundi\n",
      "- Cameroon\n",
      "- Central African Republic\n",
      "- Chad\n",
      "- Congo\n",
      "- Democratic Republic of the Congo\n",
      "- Djibouti\n",
      "- El Salvador\n",
      "- Ethiopia\n",
      "- Guatemala\n",
      "- Guinea\n",
      "- Haiti\n",
      "- Honduras\n",
      "- Iilemi triangle\n",
      "- Kenya\n",
      "- Liberia\n",
      "- Madagascar\n",
      "- Malawi\n",
      "- Mali\n",
      "- Mauritania\n",
      "- Mozambique\n",
      "- Niger\n",
      "- Nigeria\n",
      "- Rwanda\n",
      "- Senegal\n",
      "- Sierra Leone\n",
      "- Somalia\n",
      "- South Sudan\n",
      "- Sudan\n",
      "- Tajikistan\n",
      "- Tanzania\n",
      "- Uganda\n",
      "- Yemen\n",
      "- Zambia\n",
      "- Zimbabwe\n"
     ]
    }
   ],
   "source": [
    "unique_countries_admin_dataset = admins.country.unique()\n",
    "\n",
    "print(f\"\\nüåç The unique countries in the admin dataset are as follows:\\n\")\n",
    "pretty_print_list(unique_countries_admin_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import editdistance\n",
    "from fuzzywuzzy import fuzz\n",
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "#manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust filepath (file also in GitHub repository)\n",
    "# After validating the matches, the names are logged in this csv file\n",
    "valid_matching = pd.read_csv('matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched = valid_matching['missing'].unique()\n",
    "# matched = [bytes(m).decode(\"unicode_escape\") for  m in matched]\n",
    "missing_admin_names =  [m.decode(\"unicode_escape\").encode('ascii', 'backslashreplace') for m in missing_admin_names]\n",
    "print (len(missing_admin_names), len(matched))\n",
    "set(missing_admin_names).difference(matched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_province(x):\n",
    "    try:\n",
    "        if x in districts:\n",
    "            return admins[admins['district']==x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "        elif x.decode(\"unicode_escape\").encode('ascii', 'backslashreplace') in matched:\n",
    "            x = x.decode(\"unicode_escape\").encode('ascii', 'backslashreplace')\n",
    "            v = valid_matching[valid_matching['missing']==x]\n",
    "            if v['match'].values[0]=='district':\n",
    "                x = v['district'].values[0]\n",
    "                return admins[admins['district']==x]['province'].values[0]\n",
    "            elif v['match'].values[0]=='province':\n",
    "                return v['province'].values[0]\n",
    "    except:\n",
    "        raise Exception(\"Province not found for: {}\".format(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except:\n",
    "        print (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series['province'] = time_series['admin_name'].apply(lambda x: admin_to_province[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add province and country aggregate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_agg_factors(features, level='province'):\n",
    "    grouped_df = time_series.groupby(['year_month', level]).mean()\n",
    "    for f in features:\n",
    "        time_series['{}_{}'.format(f, level)] = time_series.apply(lambda x: grouped_df.ix[x['year_month'], x[level]][f], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_agg_factors(news_factors, level='country')\n",
    "add_agg_factors(t_variant_traditional_factors, level='province')\n",
    "add_agg_factors(t_variant_traditional_factors, level='country')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series.to_csv('agg_province_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time lagged features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_time_lagged(t_variant_traditional_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_time_lagged(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save data for Fig 3A, B, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import linear_model\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "test_splits = [\n",
    "    ((2010,7), (2011, 7)), \n",
    "    ((2011,7), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)), \n",
    "    ((2013,7), (2014, 7)), \n",
    "    ((2014,7), (2015, 7)), \n",
    "    ((2015,7), (2016, 7)), \n",
    "    ((2016,7), (2017, 7)), \n",
    "    ((2017,7), (2018, 7)),\n",
    "    ((2018,7), (2019, 7)), \n",
    "    ((2019,2), (2020, 2)),\n",
    "]\n",
    "train_splits = [\n",
    "    ((2009,7), (2010,4)),\n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2009,7), (2011,10)),\n",
    "    ((2009,7), (2012,7)),\n",
    "    ((2009,7), (2013,7)),\n",
    "    ((2009,7), (2014,1)),\n",
    "    ((2009,7), (2015,1)),\n",
    "    ((2009,7), (2015,10)),\n",
    "    ((2009,7), (2016,10)),\n",
    "    ((2009,7), (2017,2))]\n",
    "dev_splits = [\n",
    "    ((2010,4), (2010, 7)),\n",
    "    ((2011,1), (2011, 7)),\n",
    "    ((2011,10), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)),\n",
    "    ((2013,4), (2014, 7)),\n",
    "    ((2014,1), (2015, 7)),\n",
    "    ((2015,1), (2016, 7)),\n",
    "    ((2015,10), (2017, 7)),\n",
    "    ((2016,10), (2018, 7)),\n",
    "    ((2017,2), (2019, 2)),\n",
    "]\n",
    "rf = RandomForestRegressor(max_features='auto', n_estimators=100, \n",
    "                             min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0)\n",
    "ols = LinearRegression()\n",
    "\n",
    "lasso = linear_model.Lasso(alpha=0.1)\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return ['{}_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + ['{}_province_{}'.format(f, t) for f, t in zip(factors, range(3,9))] + ['{}_country_{}'.format(f, t) for f, t in zip(factors, range(3,9))]\n",
    "        \n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ], \n",
    "    'news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ], \n",
    "    'traditional+news': time_series[\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert': time_series['fews_proj_near_3'],\n",
    "    'expert+traditional': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors\n",
    "    ],\n",
    "    'expert+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ],\n",
    "    'expert+traditional+news': time_series[\n",
    "        ['fews_proj_near_3'] +\n",
    "        ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors +\n",
    "        get_agg_lagged_features(news_factors)\n",
    "    ]\n",
    "}\n",
    "\n",
    "labels_df = time_series['fews_ipc']\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[df['year'] >= start[0] & df['month'] >= start[1] & df['year'] <= end[0] & df['month'] <= end[1]]\n",
    "\n",
    "\n",
    "fig_3a = pd.DataFrame(columns=['method', 'split', 'features', 'country', 'rmse', 'lower_bound', 'upper_bound'])\n",
    "fig_3b = pd.DataFrame(columns=['method', 'split', 'features', 'aucpr'])\n",
    "fig_3c = pd.DataFrame(columns=['method', 'split', 'features', 'recall_at_80p'])\n",
    "\n",
    "thresholds = {'traditional': (2.236, 3.125), \n",
    "              'news': (1.907, 2.712), \n",
    "              'traditional+news': (2.105, 3.314),\n",
    "              'expert': (2, 3),\n",
    "              'expert+news': (1.912, 2.813),\n",
    "              'expert+traditional': (2.241, 3.132),\n",
    "              'expert+traditional+news': (2.172, 3.321)\n",
    "             }\n",
    "\n",
    "for train, dev, test in zip(train_splits, dev_splits, test_splits):\n",
    "    for f, D in features.items():\n",
    "        X = get_time_split(D, train[0], train[1])\n",
    "        y = get_time_split(labels_df, test[0], test[1])\n",
    "        X_test = get_time_split(D, test[0], test[1])\n",
    "        for name, regr in zip(['RF', 'OLS', 'Lasso'], [rf, ols, lasso]):\n",
    "            regr.fit(X, y)\n",
    "            preds = regr.predict(X_test)\n",
    "            labels = get_time_split(labels_df, test[0], test[1])\n",
    "            rmse = mean_squared_error(labels, preds, squared=False)\n",
    "            stderr = diebold_mariano(preds, labels)\n",
    "            upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "            lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "            precision, recall, thresholds = precision_recall_curve(labels, preds)\n",
    "            auc_precision_recall = auc(recall, precision)\n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], 'country': ['all'],\n",
    "                                           'rmse': [rmse], 'lower_bound': [lower_bound], 'upper_bound': [upper_bound]},\n",
    "                                          orient='columns')\n",
    "            fig_3a = pd.concat([fig_3a, _row], axis=0)\n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], \n",
    "                                           'aucpr': [auc_precision_recall]},\n",
    "                                          orient='columns')\n",
    "            fig_3b = pd.concat([fig_3b, _row], axis=0)\n",
    "            print (\"Method: {}, Split: {}, Features: {}, AUCPR: {}\".format(name, test, f, auc_precision_recall))\n",
    "            print (\"Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(name, test, f, rmse, lower_bound, upper_bound))\n",
    "            \n",
    "            recall_at_80p = 0\n",
    "            for p_t, p_t_add_3, p_t_min_3 in zip(preds, preds[3:] + [1,1,1], preds[:-3]+[5,5,5]):\n",
    "                u_b = thresholds[f]['upper_bound']\n",
    "                l_b = thresholds[f]['lower_bound']\n",
    "                if p_t >= u_b and p_t_add_3 >= u_b and p_t_min_3 <= l_b:\n",
    "                    recall_at_80p += 1\n",
    "            \n",
    "            _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], \n",
    "                                           'recall_at_80p': [recall_at_80p]},\n",
    "                                          orient='columns')\n",
    "            fig_3c = pd.concat([fig_3c, _row], axis=0)\n",
    "            \n",
    "            for country in time_series['country'].unique():\n",
    "                c_id = X_test[X_test['country']==country]\n",
    "                labels_c = labels[c_id]\n",
    "                preds_c = preds[c_id]\n",
    "                rmse = mean_squared_error(labels_c, preds_c, squared=False)\n",
    "                stderr = diebold_mariano(preds_c, labels_c)\n",
    "                upper_bound = np.sqrt(rmse**2 + 1.96*stderr)\n",
    "                lower_bound = np.sqrt(rmse**2 - 1.96*stderr)\n",
    "                _row = pd.DataFrame.from_dict({'method': [name], 'split': [test], 'features': [f], 'country': [country],\n",
    "                                           'rmse': [rmse], 'lower_bound': [lower_bound], 'upper_bound': [upper_bound]},\n",
    "                                          orient='columns')\n",
    "                fig_3a = pd.concat([fig_3a, _row], axis=0)\n",
    "                print (\"Country: {}, Method: {}, Split: {}, Features: {}, RMSE: {} [{}, {}]\".format(country, name, test, f, rmse, lower_bound, upper_bound))\n",
    "\n",
    "fig_3a.to_csv('fig_3a.csv')\n",
    "fig_3b.to_csv('fig_3b.csv')\n",
    "fig_3c.to_csv('fig_3c.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
