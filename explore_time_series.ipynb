{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "In this notebook, we will explore the `rime_series.csv` file that we have been provided for the paper `Predicting food insecurity through news streams`. The paper uses IPC classfiications from `fews.net` for ground truth data. \n",
    "\n",
    "The **Integrated Food Security Phase Classification (IPC)** is a standardized system used to **assess and classify food insecurity levels**. It helps governments, humanitarian organizations, and policymakers make informed decisions about **food crises, early warning systems, and response planning**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **🟢 IPC Classification Phases**\n",
    "The IPC system classifies food insecurity into **five phases**, with each phase indicating the severity of the crisis:\n",
    "\n",
    "| **IPC Phase** | **Classification**       | **Description** |\n",
    "|--------------|------------------------|----------------|\n",
    "| **1** 🟢 | **Minimal Food Insecurity** | Households can meet their food and non-food needs without external assistance. |\n",
    "| **2** 🟡 | **Stressed** | Households have minimally adequate food consumption but are at risk of deterioration if shocks occur. |\n",
    "| **3** 🟠 | **Crisis** | Households face food consumption gaps that lead to malnutrition or they must resort to severe coping strategies. |\n",
    "| **4** 🔴 | **Emergency** | Households experience large food consumption gaps, leading to high acute malnutrition and excessive mortality. |\n",
    "| **5** 🚨 | **Famine** | A catastrophic situation where starvation, death, and destitution are widespread. Requires immediate action. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas folium numpy matplotlib seaborn gdown --break-system-packages --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series = pd.read_csv(\"./data/time_series_with_causes_zscore_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Seed keyphrase\": [\n",
    "        \"famine\", \"food insecurity\", \"malnourished\", \"malnutrition\",\n",
    "        \"food crisis\", \"starvation\", \"hunger crises\", \"shortage of food\",\n",
    "        \"life-threatening hunger\", \"lack of food\", \"scarcity of food\",\n",
    "        \"acute hunger\", \"dearth of food\"\n",
    "    ],\n",
    "    \"Number of articles containing frames\": [\n",
    "        25637, 25404, 12102, 10372, 10154, 8012, 6518, 5482,\n",
    "        1895, 1266, 1058, 1043, 891\n",
    "    ]\n",
    "}\n",
    "\n",
    "pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_list(list_to_print):\n",
    "    formatted_columns = \"\\n- \" + \"\\n- \".join(list_to_print)  \n",
    "    formatted_columns = sorted(list_to_print)\n",
    "    print(\"\\n- \" + \"\\n- \".join(formatted_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series CSV\n",
    "\n",
    "In this section, we will analyze the data from the `time-series.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike previous datasets, this has more columns. \n",
    "\n",
    "The unnamed column is again the redundant index of the data frame and I will drop it. The `year_month` column is a combination of the year and month columns it seems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.drop_duplicates(inplace=True)\n",
    "df_time_series.drop(columns=[\"Unnamed: 0\"], inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series[:100].to_csv(\"time_series_sample.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of rows : \", df_time_series.shape[0])\n",
    "print(\"No. of columns : \", df_time_series.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data ranges from the year \", df_time_series['year'].min(), \" to \", df_time_series['year'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = df_time_series['country'].unique()\n",
    "formatted_countries = \"\\n- \" + \"\\n- \".join(sorted(unique_countries))\n",
    "\n",
    "print(f\"\\n🌍 The dataset covers the following {len(unique_countries)} countries:\\n\")\n",
    "print(formatted_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 15))\n",
    "plt.title(\"Distribution of articles across countries\")\n",
    "sns.countplot(y='country', data=df_time_series, order = df_time_series['country'].value_counts().index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='year', data=df_time_series)\n",
    "plt.xlabel(\"Year\")\n",
    "plt.title(\"Number of articles over the years\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mentioned_in_paper_set = set(\n",
    "    [\"Afghanistan\", \"Burkina Faso\", \"Chad\", \"Democratic Republic of the Congo\", \"Ethiopia\", \n",
    "    \"Guatemala\", \"Haiti\", \"Kenya\", \"Malawi\", \"Mali\", \"Mauritania\", \"Mozambique\", \"Niger\", \n",
    "    \"Nigeria\", \"Somalia\", \"South Sudan\", \"Sudan\", \"Uganda\", \"Republic of Yemen\", \"Zambia\", \n",
    "    \"Zimbabwe\"]\n",
    ")\n",
    "\n",
    "extra_countries = set(unique_countries) - countries_mentioned_in_paper_set\n",
    "formatted_difference = \"\\n- \" + \"\\n- \".join(sorted(list(extra_countries)))\n",
    "print(f\"Countries in dataset that are not mentioned in paper are {formatted_difference}\")\n",
    "\n",
    "missing_countries = countries_mentioned_in_paper_set - set(unique_countries)\n",
    "formatted_missing = \"\\n- \" + \"\\n- \".join(sorted(list(missing_countries)))\n",
    "print(f\"\\n\\nCountries mentioned in paper that are not in dataset are {formatted_missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so upon manual inspected, the countries the mismatch in country names is just due to some phrasing and spelling issues as can be seen above. Otherwise both have the same countries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next question is what do `admin_code` and `admin_name` mean? I think `admin_code` is the administrative code identifying the district or region. and `admin_name` is the name of the administrative unit (district/county). I will check this by checking if the `admin_code` is unique for each `admin_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_uniqueness = df_time_series[[\"admin_name\", \"admin_code\"]].drop_duplicates()\n",
    "check_uniqueness = check_uniqueness.duplicated(subset=[\"admin_name\"], keep=False)\n",
    "check_uniqueness[check_uniqueness == True]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code shows that each admin name has only one admin code so my assumption was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_districts = df_time_series['admin_name'].unique()\n",
    "\n",
    "print(f\"\\n🏙️ The dataset covers the following {len(unique_districts)} districts:\\n\")\n",
    "\n",
    "# pretty_print_list(unique_districts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper mentions:\n",
    "> The dataset used for the results presented contains 40,952 quarterly observations across `1162` districts in 21 countries over the period from July 2009 to February 2020. \n",
    "\n",
    "From the data, we can see that there are 1142 unique districts in the dataset. 20 districts are missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = df_time_series.columns.to_list()\n",
    "\n",
    "formatted_columns = \"\\n- \" + \"\\n- \".join(columns_list)  \n",
    "\n",
    "print(\"\\n🗂️ The column names in the dataset are as follows:\\n\")\n",
    "formatted_columns = sorted(columns_list)\n",
    "print(\"\\n- \" + \"\\n- \".join(formatted_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so going through the column names, a lot of these columns have a _0, _1, _2 at the end of their names. It seems to me that a lot of these column names correspond to indicator features (oth traditional and news based). The paper does mention that they will compare how good traditional factors are at predicting food insecurity as compared to news based factors so this makes sense. But why are there 3 columns for each feature ending with 0, 1 and 2? Are these measurements at district, province and country level? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_indicator_columns = [name for name in columns_list if not name.endswith((\"_0\", \"_1\", \"_2\"))]\n",
    "\n",
    "print(\"\\n📊 NON-INDICATOR COLUMNS 📊\")\n",
    "pretty_print_list(non_indicator_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_of_columns_ending_in_0 = df_time_series.columns.str.endswith('0').sum()\n",
    "print(\"The number of columns ending in '0' is: \", count_of_columns_ending_in_0)\n",
    "count_of_columns_ending_in_1 = df_time_series.columns.str.endswith('1').sum()\n",
    "print(\"The number of columns ending in '1' is: \", count_of_columns_ending_in_1)\n",
    "count_of_columns_ending_in_2 = df_time_series.columns.str.endswith('2').sum()\n",
    "print(\"The number of columns ending in '2' is: \", count_of_columns_ending_in_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the number of columns that end in `_0`, `_1` and `_2` is 167 which is the same as the final number of extracted text features from the news articles. So I think these columns are the extracted text features from the news articles.\n",
    "\n",
    "\n",
    "The **traditional risk factors** used in the study are categorized into **time-variant** (changing over time) and **time-invariant** (fixed for a given district). Below is the mapping between these risk factors and their corresponding **columns in the time series dataset** which I picked directly from the paper itself.:\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 Time-Variant Factors (Change Over Time)**\n",
    "| **Traditional Risk Factor** | **Time Series Column** | **Description** |\n",
    "|----------------------------|-----------------------|----------------|\n",
    "| **Violent Conflict Events** | `acled_count` | Monthly count of conflict events. |\n",
    "| **Conflict Fatalities per Event** | `acled_fatalities` | Average number of fatalities per conflict event. |\n",
    "| **Food Prices Index (Log Nominal)** | `p_staple_food` | Monthly log nominal food price index. |\n",
    "| **Food Prices Year-on-Year Difference** | `p_staple_food_diff` | Change in food price index compared to the previous year. |\n",
    "| **Evapotranspiration Index (Mean)** | `et_mean` | Monthly mean of evapotranspiration (water loss from soil and plants). |\n",
    "| **Rainfall Index (Mean)** | `rain_mean` | Monthly mean rainfall in the district. |\n",
    "| **Rainfall Deviation from Average** | `rain_anom` | Difference between actual rainfall and seasonal average. |\n",
    "| **Normalized Difference Vegetation Index (Mean)** | `ndvi_mean` | Satellite-derived measure of vegetation health. |\n",
    "| **Vegetation Deviation from Average** | `ndvi_anom` | Difference between actual NDVI and historical average. |\n",
    "\n",
    "---\n",
    "\n",
    "##### **📌 Time-Invariant Factors (Fixed for a District)**\n",
    "| **Traditional Risk Factor** | **Time Series Column** | **Description** |\n",
    "|----------------------------|-----------------------|----------------|\n",
    "| **Population Count** | `pop` | Estimated population in the district. |\n",
    "| **Terrain Ruggedness Index** | `ruggedness_mean` | Measures how rough the terrain is. |\n",
    "| **District Size** | `area` | Total land area of the district. |\n",
    "| **Share of Cropland Use** | `cropland_pct` | Percentage of district area used for cropland. |\n",
    "| **Share of Pasture Use** | `pasture_pct` | Percentage of district area used for pasture. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns have some columns related to `fews` lets see if we can find some more information on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fews = df_time_series.groupby(df_time_series[\"fews_ipc\"]).size().reset_index(name='counts')\n",
    "pd.DataFrame(df_fews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.countplot(x=\"fews_ipc\", data=df_time_series)\n",
    "plt.title(\"Distribution of FEWS IPC levels\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fews ipc` column seems to be the IPC categorization from `fews.net` that will act as ground truth data. Interestingly, no classification is of a level 5. Good for the world I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fews_ha = df_time_series.groupby(df_time_series[\"fews_ha\"]).size().reset_index(name='counts')\n",
    "pd.DataFrame(df_fews_ha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fews_ha_more = (\n",
    "    df_time_series\n",
    "    .groupby([\"fews_ha\", \"fews_ipc\", \"country\"])\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "pd.DataFrame(df_fews_ha_more)[df_fews_ha_more[\"fews_ha\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_df = df_time_series[[\"mayhem_0\", \"fews_ha\", \"fews_ipc\", \"country\", \"year\", \"year_month\", \"month\"]]\n",
    "\n",
    "small_df = small_df[small_df[\"fews_ha\"].notna()]\n",
    "\n",
    "small_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fews_ha_more = (\n",
    "    df_time_series\n",
    "    .groupby([\"fews_ha\", \"fews_ipc\", \"country\"])\n",
    "    .count()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "pd.DataFrame(df_fews_ha_more)[df_fews_ha_more[\"fews_ha\"] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I do not know what the fews_ha column means, It has only two values, 0 and 1. It could represent the number of hectares (ha) of land affected by food insecurity in a given district but how could that only be 0 or 1? I am not sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fews_proj_near = df_time_series.groupby(df_time_series[\"fews_proj_near\"]).size().reset_index(name='counts')\n",
    "pd.DataFrame(df_fews_proj_near)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going by the column values this seems just like IPC classification. However the name contains `proj` which could mean that this is a projected IPC classification. It likely refers to FEWS NET’s near-term food insecurity projection, predicting food security conditions within the next 3-6 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fews_proj_near_ha = df_time_series.groupby(df_time_series[\"fews_proj_near_ha\"]).size().reset_index(name='counts')\n",
    "pd.DataFrame(df_fews_proj_near_ha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fews_proj_ha` is likely FEWS NET’s projected number of hectares affected by food insecurity in the future as it has the same values as `fews_ha` but column name contains `proj`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We then convert each text feature into an indicator equal to one if it is mentioned in an article and zero otherwise. Each news indicator is constructed by counting the cooccurrences of a text feature and geographic mentions. \n",
    "\n",
    "Now, lets look at the value of the columns that end with `_0`, `_1` and `_2`. I think these are the extracted text features from the news articles at the district, province and country level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_series[[\"flee_0\", \"country\", \"admin_name\", \"year_month\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so the next step is identifying what `centx` and `centy` mean. I think these are the coordinates of the district. I will check this by plotting the districts on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centx_max_min = df_time_series[\"centx\"].max(), df_time_series[\"centx\"].min()\n",
    "centy_max_min = df_time_series[\"centy\"].max(), df_time_series[\"centy\"].min()\n",
    "\n",
    "print(\"The maximum and minimum values for 'centx' are: \", centx_max_min)\n",
    "print(\"The maximum and minimum values for 'centy' are: \", centy_max_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_time_series[:50]  \n",
    "map_center = [df[\"centy\"].mean(), df[\"centx\"].mean()]\n",
    "m = folium.Map(location=map_center, zoom_start=5)\n",
    "\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row[\"centy\"], row[\"centx\"]],\n",
    "        popup=row[\"admin_name\"], \n",
    "        icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
    "    ).add_to(m)\n",
    "\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to me that these are indeed longitude and latitude coordinates of the districts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some notes on the data\n",
    "\n",
    "### **Understanding the Different Columns in the Data (Based on the Paper & Code)**  \n",
    "\n",
    "The dataset used in the **food insecurity prediction model** consists of various **traditional risk factors, news-based indicators, and IPC classifications**. \n",
    "\n",
    "#### **1️⃣ General Column Categories**\n",
    "| **Column Type** | **Examples** | **Meaning** |\n",
    "|---------------|-----------|------------|\n",
    "| **Administrative Identifiers** | `admin_code`, `admin_name`, `year`, `month` | Identifies the **district, year, and month** for each data point. |\n",
    "| **IPC Classification** | `fews_ipc` | The **food insecurity phase** (IPC scale 1-5) for a given district & time. |\n",
    "| **Traditional Risk Factors** | `rain_mean`, `rain_anom`, `conflict_count`, `food_price` | Climate, economic, and conflict-related risk factors. |\n",
    "| **News-Based Features** | `drought_0`, `famine_1`, `displacement_2` | Text features extracted from **news articles**, indicating frequency of crisis-related terms. |\n",
    "| **Lagged Features** | `fews_ipc_3`, `rainfall_6` | Past values of a variable (used to capture historical trends). |\n",
    "\n",
    "\n",
    "#### **2️⃣ What Do `_0`, `_1`, `_2` Mean?**\n",
    "The **suffixes `_0`, `_1`, `_2`** in the dataset **represent different levels of geographic aggregation**.  I THINK! \n",
    "\n",
    "| **Suffix** | **Interpretation** | **Example** |\n",
    "|-----------|------------------|-----------|\n",
    "| **`_0`** | **District-Level (Local Impact)** | `drought_0` → How often \"drought\" appears in news **for the specific district**. |\n",
    "| **`_1`** | **Province-Level (Regional Impact)** | `drought_1` → Frequency of \"drought\" mentions **for the province** (aggregated across all districts in it). |\n",
    "| **`_2`** | **Country-Level (National Impact)** | `drought_2` → Frequency of \"drought\" mentions **for the entire country**. |\n",
    "\n",
    "🔹 **Why This Matters?**  \n",
    "- These levels **capture how crises propagate** from local to regional and national levels.  \n",
    "- **District-level (`_0`) features are direct indicators of food insecurity.**  \n",
    "- **Province (`_1`) & Country (`_2`) features account for broader shocks (e.g., drought in one district affecting neighboring areas).**  (BOOTIFUL)\n",
    "\n",
    "\n",
    "#### **3️⃣ Why Are These Columns Important?**\n",
    "1. **📉 Lagged Features for Trend Analysis**\n",
    "   - **Example:** `fews_ipc_3` → IPC value **3 months ago**.\n",
    "   - The model learns from **historical trends** to predict future food insecurity.\n",
    "\n",
    "2. **📰 News-Based Indicators for Early Warning**\n",
    "   - News mentions (`famine_0`, `hunger_1`, `migration_2`) act as **early warning signals**.\n",
    "   - These columns **capture crisis events before they impact food security levels**.\n",
    "\n",
    "3. **🌍 Multi-Level Aggregation for Broader Impact**\n",
    "   - The suffixes `_0`, `_1`, `_2` allow the model to detect **local vs. national trends**.\n",
    "   - Example: **A drought at the country level (`_2`) might influence multiple districts (`_0`).**\n",
    "\n",
    "\n",
    "### **4️⃣ Key Takeaways**\n",
    "✅ **Columns ending in `_0`, `_1`, `_2` represent district, province, and country-level aggregation.**  \n",
    "✅ **Traditional features & news indicators are lagged** to model past trends.  \n",
    "✅ **News-based columns capture early signals** of food insecurity before it escalates.  \n",
    "✅ **Multi-scale aggregation allows for a more comprehensive prediction model.**  \n",
    "\n",
    "---\n",
    "\n",
    "### **How Do We Know That `_0`, `_1`, `_2` Represent District, Province, and Country-Level Aggregation?**  \n",
    "\n",
    "This conclusion is based on **three main sources**:  \n",
    "\n",
    "1️⃣ **The Paper's Explanation**  \n",
    "2️⃣ **The Structure of the Dataset**  \n",
    "3️⃣ **The Code in `source_rf_regression_modelling.ipynb`**\n",
    "\n",
    "### **🔍 1️⃣ Evidence from the Paper**  \n",
    "The paper explicitly states that **features are computed at three levels**:\n",
    "\n",
    "> *\"The terms \\( v_{k,p,t} \\), \\( x_{w,p,t} \\), \\( v_{k,c,t} \\), and \\( x_{w,c,t} \\) account for shocks occurring in the province or the country that district \\( d \\) belongs to and that could affect the IPC phase in the district.\"*\n",
    "\n",
    "> In other words, we collect district-month–level data on ninetime-varying risk factors describing five different types of riskand district-level data on five time-invariant risk factors (fig. S6).The dataset covers 21 of the 37 countries in the FEWS NETdataset—Afghanistan, Burkina Faso, Chad, Democratic Republicof the Congo, Ethiopia, Guatemala, Haiti, Kenya, Malawi, Mali,Mauritania, Mozambique, Niger, Nigeria, Somalia, South Sudan,Sudan, Uganda, Republic of Yemen, Zambia, and Zimbabwe—over the period from July 2009 to July 2020.\n",
    "\n",
    "This shows that the paper has district level data which then it aggregates at the province and country level. \n",
    "\n",
    "The paper also mentions the following:\n",
    "- \\( v_{k,d,t} \\) → **Time-varying traditional factor at the district level.**  \n",
    "- \\( v_{k,p,t} \\) → **Same factor aggregated at the province level.**  \n",
    "- \\( v_{k,c,t} \\) → **Same factor aggregated at the country level.**  \n",
    "\n",
    "Similarly, for news-based factors:\n",
    "- \\( x_{w,d,t} \\) → **News feature at the district level.**  \n",
    "- \\( x_{w,p,t} \\) → **News feature at the province level.**  \n",
    "- \\( x_{w,c,t} \\) → **News feature at the country level.**  \n",
    "\n",
    "Thus, in the dataset, **the suffixes `_0`, `_1`, and `_2` align with district, province, and country levels**.\n",
    "\n",
    "\n",
    "### **📊 2️⃣ Evidence from the Dataset Structure**  \n",
    "\n",
    "- The dataset contains **repeating feature names** with **only `_0`, `_1`, `_2` differing**.\n",
    "- Example:\n",
    "\n",
    "| **Feature Name**  | **Likely Meaning** |\n",
    "|-------------------|-------------------|\n",
    "| `famine_0`       | **District-level** famine mentions |\n",
    "| `famine_1`       | **Province-level** famine mentions (aggregated across all districts) |\n",
    "| `famine_2`       | **Country-level** famine mentions (aggregated across all provinces) |\n",
    "\n",
    "- This pattern holds across **multiple text features** like `conflict_0`, `conflict_1`, `conflict_2`.\n",
    "\n",
    "\n",
    "### **💻 3️⃣ Evidence from the Code (`source_rf_regression_modelling.ipynb`)**  \n",
    "The notebook contains **explicit feature aggregation steps** that confirm `_0`, `_1`, `_2` refer to different geographic levels.\n",
    "\n",
    "For example, in the **feature engineering process**, the notebook:  \n",
    "1. **Generates new columns for each feature** at **different aggregation levels**.  \n",
    "2. **Applies province-level and country-level averages** to district level data by extracting olcumns that end in `_0`.  \n",
    "\n",
    "Relevant code snippet:\n",
    "```python\n",
    "news_factors = [name for name in time_series.columns.values if '_0' in name]\n",
    "\n",
    "def add_agg_factors(features, level='province'):\n",
    "    grouped_df = time_series.groupby(['year_month', level]).mean()\n",
    "    for f in features:\n",
    "        time_series['{}_{}'.format(f, level)] = time_series.apply(lambda x: grouped_df.loc[x['year_month'], x[level]][f], axis=1)\n",
    "```\n",
    "This means:\n",
    "- It **computes province and country-level aggregations** from district-level data.\n",
    "- The **suffix `_province` and `_country` correspond to `_1` and `_2`**.\n",
    "\n",
    "\n",
    "### **📌 Final Conclusion**  \n",
    "✅ **Suffix `_0` corresponds to district-level data.**  \n",
    "✅ **Suffix `_1` corresponds to province-level aggregation.**  \n",
    "✅ **Suffix `_2` corresponds to country-level aggregation.**  \n",
    "\n",
    "This is confirmed by:\n",
    "1. **The theoretical model in the paper.**  \n",
    "2. **The dataset’s structure and column naming.**  \n",
    "3. **The feature aggregation code in the provided notebook.**  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Why the Aggregation is Redone?\n",
    "Okay so if the aggregations are already done in the form of columns ending in _1 and _2, why is it being done again in the code?\n",
    "Even though **province and country-level features exist in the dataset (columns ending in _1, _2)**, the additional aggregation steps **ensure consistency** in feature engineering. The aggregation process accounts for:\n",
    "\n",
    "1. **Missing Data Handling** – Some features at the province/country level might have missing values, so recomputing ensures completeness.\n",
    "2. **Lagging Data** – Some aggregations are performed **after** lagging the time-series data, requiring recalculation.\n",
    "3. **Rolling Aggregations** – Some features might need rolling averages or weighted combinations over different time windows.\n",
    "\n",
    "Thus, the paper ensures robustness by explicitly **recomputing aggregations** rather than relying solely on precomputed features in the dataset.\n",
    "\n",
    "---\n",
    "\n",
    "If we are performing aggregations from scratch, then can we drop the `_1` and `_2` columns because they are redundant? \n",
    "\n",
    "However, before doing that, consider the following:\n",
    "\n",
    "### **✔ When You CAN Drop `_1` and `_2` Columns**\n",
    "✅ **If you are recalculating province- and country-level aggregations** from scratch using your own methodology.  \n",
    "✅ **If the `_1` and `_2` columns contain inconsistencies or missing data**, and you prefer to compute fresh, consistent aggregations.  \n",
    "✅ **If your aggregation logic involves different techniques** (e.g., rolling averages, weighted aggregation, or normalization beyond what's in `_1`, `_2`).  \n",
    "✅ **If you want complete control over how province- and country-level values are computed** rather than relying on precomputed ones.\n",
    "\n",
    "### **⚠ When You SHOULD Keep `_1` and `_2` Columns**\n",
    "❌ **If you want a quick, precomputed alternative** instead of redoing aggregations from raw data.  \n",
    "❌ **If you are unsure whether the precomputed aggregations match the ones in the paper exactly** (they may have specific pre-processing steps).  \n",
    "❌ **If you're using the original model without modification**—it might be designed to use these columns directly.  \n",
    "\n",
    "### **Final Decision?**\n",
    "- If your goal is **full replication from raw data**, **drop `_1` and `_2`** and recompute province/country aggregations from scratch.\n",
    "- If you want **a shortcut**, keep them and validate whether they match what you would compute.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "The **`fews_proj_near`** variable is used in the model as an **expert forecast** for food insecurity. According to the supplementary material of the paper, this variable represents **expert predictions of food insecurity** for a given district, typically based on the FEWS NET projections. It serves as a benchmark for comparison against the **traditional+news** model predictions.\n",
    "\n",
    "### **How is `fews_proj_near` Used?**\n",
    "1. **Included in Regression Models:**\n",
    "   - It is explicitly used in models that incorporate expert projections.\n",
    "   - The **\"expert\"** model only uses `fews_proj_near_3` as the input.\n",
    "   - The **\"expert + traditional\"** model combines it with traditional factors.\n",
    "   - The **\"expert + news\"** model integrates it with news-based features.\n",
    "\n",
    "2. **Time Lagging:**\n",
    "   - The model incorporates **`fews_proj_near_3`**, which means the **projection from 3 months ago** is used for prediction.\n",
    "   - This ensures that the model only relies on past information, preventing data leakage.\n",
    "\n",
    "3. **Comparison Against Other Models:**\n",
    "   - The **traditional+news model** is compared to expert forecasts (`fews_proj_near`) in terms of **Root Mean Squared Error (RMSE)**.\n",
    "   - Fig. S8 in the supplementary material shows RMSE comparisons of predictions **3 months ahead** using expert forecasts and **random forest regressions**.\n",
    "\n",
    "### **Why is `fews_proj_near` Important?**\n",
    "- It provides a **baseline** for evaluating model performance.\n",
    "- It helps **validate** the effectiveness of incorporating news-based indicators into predictions.\n",
    "- By omitting `fews_proj_near`, the study can assess whether **news and traditional factors alone** can predict food crises without relying on expert judgment.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world-bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
