{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "In this notebook, we will explore the 3 extra files that we have been provided for the paper `Predicting food insecurity through news streams`. The paper uses IPC classfiications from `fews.net` for ground truth data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pandas folium numpy matplotlib seaborn gdown --break-system-packages --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import folium\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_famine_country = pd.read_csv(\"./data/famine-country-province-district-years-CS.csv\")\n",
    "df_matching_districts = pd.read_csv(\"./data/matching_districts.csv\")\n",
    "df_nodes = pd.read_csv(\"./data/fig_1_nodes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Seed keyphrase\": [\n",
    "        \"famine\", \"food insecurity\", \"malnourished\", \"malnutrition\",\n",
    "        \"food crisis\", \"starvation\", \"hunger crises\", \"shortage of food\",\n",
    "        \"life-threatening hunger\", \"lack of food\", \"scarcity of food\",\n",
    "        \"acute hunger\", \"dearth of food\"\n",
    "    ],\n",
    "    \"Number of articles containing frames\": [\n",
    "        25637, 25404, 12102, 10372, 10154, 8012, 6518, 5482,\n",
    "        1895, 1266, 1058, 1043, 891\n",
    "    ]\n",
    "}\n",
    "\n",
    "pd.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_list(list_to_print):\n",
    "    formatted_columns = \"\\n- \" + \"\\n- \".join(list_to_print)  \n",
    "    formatted_columns = sorted(list_to_print)\n",
    "    print(\"\\n- \" + \"\\n- \".join(formatted_columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Famine CSV\n",
    "\n",
    "In this section, I will try and analyze the data from the `famine-country-province-district-years-CS.csv` file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_famine_country.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the `Unnamed` column is the index of the data but it is the same as the index of the data frame. So I will drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_famine_country.drop(columns=[\"Unnamed: 0\"], inplace=True) # this just seems like a redundant index column\n",
    "\n",
    "df_columns = pd.DataFrame(df_famine_country.columns.values)\n",
    "\n",
    "print(\"\\n🗂️ LIST OF ALL COLUMN NAMES IN THE DATASET 🗂️\")\n",
    "print(\"These are the different attributes available in the dataset for analysis:\\n\")\n",
    "df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of rows : \", df_famine_country.shape[0])\n",
    "print(\"No. of columns : \", df_famine_country.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The data ranges from the year \", df_famine_country['year'].min(), \" to \", df_famine_country['year'].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper mentions that they have used data from `from July 2009 to July 2020`. This means that this file does not contain the data for the entire period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_countries = df_famine_country['country'].unique()\n",
    "formatted_countries = \"\\n- \" + \"\\n- \".join(sorted(unique_countries))\n",
    "\n",
    "print(f\"\\n🌍 The dataset covers the following {len(unique_countries)} countries:\\n\")\n",
    "print(formatted_countries)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper says that they analyzed data from 21 countries, but this dataset contains 39 unique countries. Upon manual inspection Congo is mentioned twice so there are only 38 unique countries. This is very close to the mention of 37 countries in the FEWS net dataset as mentioned in paper. I assume this dataset is a subset of the FEWS net dataset.\n",
    "\n",
    ">  The dataset covers 21 of the 37 countries in the FEWS NET dataset—Afghanistan, Burkina Faso, Chad, Democratic Republic of the Congo, Ethiopia, Guatemala, Haiti, Kenya, Malawi, Mali, Mauritania, Mozambique, Niger, Nigeria, Somalia, South Sudan, Sudan, Uganda, Republic of Yemen, Zambia, and Zimbabwe—over the period from July 2009 to July 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_mentioned_in_paper_set = set(\n",
    "    [\"Afghanistan\", \"Burkina Faso\", \"Chad\", \"Democratic Republic of the Congo\", \"Ethiopia\", \n",
    "    \"Guatemala\", \"Haiti\", \"Kenya\", \"Malawi\", \"Mali\", \"Mauritania\", \"Mozambique\", \"Niger\", \n",
    "    \"Nigeria\", \"Somalia\", \"South Sudan\", \"Sudan\", \"Uganda\", \"Republic of Yemen\", \"Zambia\", \n",
    "    \"Zimbabwe\"]\n",
    ")\n",
    "\n",
    "extra_countries = set(unique_countries) - countries_mentioned_in_paper_set\n",
    "formatted_difference = \"\\n- \" + \"\\n- \".join(sorted(list(extra_countries)))\n",
    "print(f\"Countries in dataset that are not mentioned in paper are {formatted_difference}\")\n",
    "\n",
    "missing_countries = countries_mentioned_in_paper_set - set(unique_countries)\n",
    "formatted_missing = \"\\n- \" + \"\\n- \".join(sorted(list(missing_countries)))\n",
    "print(f\"\\n\\nCountries mentioned in paper that are not in dataset are {formatted_missing}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay so upon manual inspection Yemen, Congo are mentioned in the paper but jsut under different names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rows_for_country = df_famine_country.groupby(['country']).size().reset_index(name='counts')\n",
    "count_rows_for_country = count_rows_for_country.sort_values(by='counts', ascending=False)\n",
    "count_rows_for_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_rows_for_country_per_district = df_famine_country.groupby(['country', 'district']).size().reset_index(name='counts')\n",
    "count_rows_for_country_per_district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "sns.countplot(x='country', data=df_famine_country, order = df_famine_country['country'].value_counts().index)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Country')\n",
    "plt.ylabel('Number of rows')\n",
    "plt.title('Number of rows per country')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This to me seems like it is a dataset of famines in different countries and their district by years and dates. I am still confised by what `CS` column means. It could be IPC classification but that has 5 categories only from 1 to 5 whereas this column has values like 88 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_cs = pd.DataFrame(df_famine_country[\"CS\"].unique(), columns=[\"Unique CS Values\"])\n",
    "df_value_counts = df_famine_country[\"CS\"].value_counts().reset_index()\n",
    "df_value_counts.columns = [\"CS Value\", \"Count\"]\n",
    "df_columns = pd.DataFrame(df_famine_country.columns, columns=[\"Dataset Columns\"])\n",
    "\n",
    "print(\"\\n🌟 UNIQUE VALUES IN THE 'CS' COLUMN 🌟\")\n",
    "print(\"Below are all unique values found in the 'CS' column, which might represent different classifications or severity levels:\\n\")\n",
    "df_unique_cs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=df_value_counts[\"CS Value\"], y=df_value_counts[\"Count\"])\n",
    "plt.title(\"DISTRIBUTION OF 'CS' VALUES\")\n",
    "plt.xlabel(\"Unique 'CS' Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe it is a misclassification of the data? But upon inspecting more, there are about 4000 rows of data and it is not possible to be a misclassification. So I am still not sure what this column means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n📊 FREQUENCY DISTRIBUTION OF COLUMN 📊\")\n",
    "print(\"This table shows how frequently each unique value appears in the dataset, helping us understand the data distribution:\\n\")\n",
    "df_value_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Verdict (Subject to change)\n",
    "\n",
    "The `famine-country-province-district-years-CS.csv` file is used for administrative-level mapping, ensuring consistency across different datasets. It maps districts, provinces, and countries, aligning data from sources like FEWS NET and news reports to the correct geographic regions. The file helps detect missing or misnamed locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching districts CSV\n",
    "\n",
    "In this section, we will analyze the data from the `matching-districts.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matching_districts.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks like a relatively small dataset as compared to the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of rows : \", df_matching_districts.shape[0])\n",
    "print(\"No. of columns : \", df_matching_districts.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by looking at the head of the data this seems to me like it is some sort of correction of either the district names or province names in the dataset depending on the `match` column. Like the missing and district columns have more less the same values for each row so I think this is a correction of the district names. By analyzing the DF more in Data Wrangler, my suspicions have been proved right. (I think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(filename=\"matching.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Verdict (Subject to change)\n",
    "The **`matching_districts.csv`** file appears to contain **mapped corrections** or **standardized district names**, likely used to clean or align geographic data in the study.\n",
    "\n",
    "- The dataset consists of **four columns**:\n",
    "  1. **`missing`** → District names that were **incorrect, misspelled, or not found** in the main dataset.\n",
    "  2. **`district`** → The **corrected district name** that aligns with official records or another dataset.\n",
    "  3. **`province`** → The **province or administrative region** to which the district belongs.\n",
    "  4. **`match`** → Specifies whether the correction refers to a **district** or potentially another administrative level.\n",
    "\n",
    "This dataset is likely used for **data cleaning** to ensure that all districts match a **consistent naming standard**.\n",
    "\n",
    "---\n",
    "\n",
    "##### **🔍 Column-by-Column Breakdown**\n",
    "| **Column Name** | **Likely Meaning** |\n",
    "|---------------|----------------|\n",
    "| **`missing`** | Contains district names that were **inconsistent, misspelled, or missing** from the main dataset. |\n",
    "| **`district`** | The **corrected or standardized** district name that replaces the missing one. |\n",
    "| **`province`** | The **province or region** associated with the corrected district. |\n",
    "| **`match`** | Indicates whether the correction applies to a **district** or potentially another entity (e.g., province). |\n",
    "\n",
    "---\n",
    "\n",
    "This dataset helps by:\n",
    "✅ **Fixing inconsistencies** in district names across different datasets.  \n",
    "✅ **Ensuring accurate matching** of districts to food insecurity data.  \n",
    "✅ **Improving model accuracy**, as mismatched districts could lead to errors in food crisis predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> As can be seen above in the data wrangler Screenshot, the columns do have some weird encoding leading to many escaped characters.  \n",
    "> I will have to clean this up (later).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nodes CSV\n",
    "\n",
    "In this section, we will analyze the data from the `fig_1_nodes.csv` file. This file contains the 167 extracted text features in the `labels` column along with their frequency in the `size` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes[df_nodes[\"label\"]==\"rise\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the supplemental material, the number of articles for this term are 1,377,032. So maybe the size column is not the number of articles?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of rows : \", df_nodes.shape[0])\n",
    "print(\"No. of columns : \", df_nodes.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.groupby(df_nodes[\"type\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.groupby(df_nodes[\"cluster\"]).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of clusters is the same as mentioned in the paper. \n",
    "> To assess the content validity of these 167 features, we partition them into 12 semantically distinct clusters. Text features belonging to the same clusters co-occur in the news about twice as frequently as those in different clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodes.sort_values(by='size', ascending=False).head(5) # top 5 nodes by size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "world-bank",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
