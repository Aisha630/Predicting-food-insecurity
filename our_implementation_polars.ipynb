{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“Š **Re-Implementation of \"Predicting Food Crises Using News Streams\"**\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ” **Objective**\n",
    "\n",
    "This notebook aims to **reproduce and analyze** the methodology presented in the paper:\n",
    "\n",
    "ğŸ“„ **Paper:** [Predicting food crises using news streams](https://www.science.org/doi/10.1126/sciadv.abm3449)  \n",
    "ğŸ“Š **Dataset:** [Harvard Dataverse Repository](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/CJDWUW)  \n",
    "ğŸ“œ **Original Code & Methods:** [GitHub - Regression Modeling (Step 5)](https://github.com/philippzi98/food_insecurity_predictions_nlp/blob/main/Step%205%20-%20Regression%20Modelling/README.md)\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ›  **Methodology**\n",
    "\n",
    "This implementation follows the **key steps** outlined in the paper to predict **food insecurity crises** using a combination of:\n",
    "1ï¸âƒ£ **Traditional Risk Factors** (conflict, climate, food prices, etc.)  \n",
    "2ï¸âƒ£ **News-Based Indicators** (text feature frequencies from news articles)  \n",
    "3ï¸âƒ£ **Lagging & Aggregation** (temporal dependencies at district, province, and country levels)  \n",
    "4ï¸âƒ£ **Machine Learning Models** (Random Forest, OLS, Lasso)\n",
    "\n",
    "---\n",
    "\n",
    "#### ğŸ”— **Reference Materials**\n",
    "\n",
    "ğŸ“„ **Supplementary Material:** Available in `supplemental_material_from_paper.pdf`  \n",
    "ğŸ“Š **Datasets Used:**\n",
    "\n",
    "- `time_series_with_causes_zscore_full.csv` (Main dataset with time-series features)\n",
    "- `famine-country-province-district-years-CS.csv` (Food insecurity classification)\n",
    "- `matching_districts.csv` (Geographical standardization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“šğŸ”§ Import Libraries\n",
    "\n",
    "In this notebook, we will use uv to manage our Python environment and packages efficiently. uv is a modern and fast package manager that simplifies virtual environment creation, and dependency installation. We will create a virtual environment, install necessary libraries, and ensure our environment stays consistent across different setups.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncoment the below cell to install `uv` if you have not already. You can also install it trhiugh `pip` by running `!pip install uv` but this will be within your current python environment and not globally.\n",
    "\n",
    "# !curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "# !uv venv world-bank\n",
    "# !source world-bank/bin/activate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: beautifulsoup4==4.13.3 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 1)) (4.13.3)\n",
      "Requirement already satisfied: branca==0.8.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 2)) (0.8.1)\n",
      "Requirement already satisfied: certifi==2025.1.31 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 3)) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer==3.4.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: contourpy==1.3.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 5)) (1.3.1)\n",
      "Requirement already satisfied: cycler==0.12.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 6)) (0.12.1)\n",
      "Requirement already satisfied: filelock==3.17.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 7)) (3.17.0)\n",
      "Requirement already satisfied: folium==0.19.5 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 8)) (0.19.5)\n",
      "Requirement already satisfied: fonttools==4.56.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 9)) (4.56.0)\n",
      "Requirement already satisfied: gdown==5.2.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 10)) (5.2.0)\n",
      "Requirement already satisfied: idna==3.10 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 11)) (3.10)\n",
      "Requirement already satisfied: jinja2==3.1.5 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 12)) (3.1.5)\n",
      "Requirement already satisfied: kiwisolver==1.4.8 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 13)) (1.4.8)\n",
      "Requirement already satisfied: markupsafe==3.0.2 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 14)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib==3.10.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 15)) (3.10.1)\n",
      "Requirement already satisfied: numpy==2.2.3 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 16)) (2.2.3)\n",
      "Requirement already satisfied: packaging==24.2 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 17)) (24.2)\n",
      "Requirement already satisfied: pandas==2.2.3 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 18)) (2.2.3)\n",
      "Requirement already satisfied: pillow==11.1.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 19)) (11.1.0)\n",
      "Requirement already satisfied: pyparsing==3.2.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 20)) (3.2.1)\n",
      "Requirement already satisfied: pysocks==1.7.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 21)) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 22)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2025.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 23)) (2025.1)\n",
      "Requirement already satisfied: requests==2.32.3 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 24)) (2.32.3)\n",
      "Requirement already satisfied: seaborn==0.13.2 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 25)) (0.13.2)\n",
      "Requirement already satisfied: six==1.17.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 26)) (1.17.0)\n",
      "Requirement already satisfied: soupsieve==2.6 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 27)) (2.6)\n",
      "Requirement already satisfied: tqdm==4.67.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 28)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions==4.12.2 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 29)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2025.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 30)) (2025.1)\n",
      "Requirement already satisfied: urllib3==2.3.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 31)) (2.3.0)\n",
      "Requirement already satisfied: xyzservices==2025.1.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 32)) (2025.1.0)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 33)) (6.29.5)\n",
      "Requirement already satisfied: editdistance in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 34)) (0.8.1)\n",
      "Requirement already satisfied: fuzzywuzzy in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 35)) (0.18.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 36)) (1.6.1)\n",
      "Requirement already satisfied: python-Levenshtein in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from -r requirements.txt (line 37)) (0.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from tqdm==4.67.1->-r requirements.txt (line 28)) (0.4.6)\n",
      "Requirement already satisfied: comm>=0.1.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (0.2.2)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (1.8.14)\n",
      "Requirement already satisfied: ipython>=7.23.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (9.1.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (5.7.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (0.1.7)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (1.6.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (7.0.0)\n",
      "Requirement already satisfied: pyzmq>=24 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (26.4.0)\n",
      "Requirement already satisfied: tornado>=6.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (6.4.2)\n",
      "Requirement already satisfied: traitlets>=5.4.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipykernel->-r requirements.txt (line 33)) (5.14.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->-r requirements.txt (line 36)) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->-r requirements.txt (line 36)) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from scikit-learn->-r requirements.txt (line 36)) (3.6.0)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-Levenshtein->-r requirements.txt (line 37)) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from Levenshtein==0.27.1->python-Levenshtein->-r requirements.txt (line 37)) (3.13.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (0.19.2)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (0.6.3)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 33)) (4.3.7)\n",
      "Requirement already satisfied: pywin32>=300 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel->-r requirements.txt (line 33)) (310)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (0.8.4)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\bilal\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from stack_data->ipython>=7.23.1->ipykernel->-r requirements.txt (line 33)) (0.2.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image\n",
    "import os\n",
    "import gdown\n",
    "import zipfile\n",
    "from fuzzywuzzy import fuzz\n",
    "import math\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You already have the data downloaded and extracted\n"
     ]
    }
   ],
   "source": [
    "url = \"https://drive.google.com/uc?id=1YoQ1hz9RlaLr2xW3KoKCfJPyyO2PErym\"\n",
    "output = \"data.zip\"\n",
    "\n",
    "if not os.path.exists(\"./data\"):\n",
    "    gdown.download(url, output, quiet=False) \n",
    "    zipfile.ZipFile('data.zip', 'r').extractall()\n",
    "else:\n",
    "    print(\"You already have the data downloaded and extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‚ Load and Clean Data\n",
    "\n",
    "**Understanding the Time-Series Dataset & Column Selection**\n",
    "\n",
    "This dataset contains **district-level time-series data** on food insecurity risk factors, including:\n",
    "\n",
    "- **ğŸ“… Temporal Information:** `year`, `month`, `year_month`\n",
    "- **ğŸ“ Geographical Identifiers:** `admin_code`, `admin_name`, `province`, `country`\n",
    "- **ğŸŒ Traditional Risk Factors:** Climate (`rain_mean`, `ndvi_mean`), conflict (`acled_count`), food prices (`p_staple_food`)\n",
    "- **ğŸ“° News-Based Indicators:** Proportions of news articles mentioning crisis-related keywords (`conflict_0`, `famine_0`, etc.)\n",
    "- **ğŸ“‰ Food Insecurity Label:** `fews_ipc` (Integrated Phase Classification)\n",
    "\n",
    "ğŸ”¥ **Columns We Will Drop & Why**\n",
    "âœ” **Redundant Aggregations:** `_1`, `_2` columns (province & country-level values) since we will recompute aggregations from scratch anyways.  \n",
    "âœ” **Unnamed/Index Columns:** `Unnamed: 0` as it is unnecessary. It is just a duplicate of default index.\n",
    "âœ” **Unnecessary Identifiers:** If `admin_code` and `admin_name`, after matching these to `matching_districts.csv`, we can drop them.\n",
    "\n",
    "---\n",
    "\n",
    "> âš ï¸ **NOTE:**  \n",
    "> For a detailed explanation of the dataset and features, refer to the [`explore_time_series.ipynb`](./explore_time_series.ipynb) notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = pl.read_csv('./data/time_series_with_causes_zscore_full.csv')\n",
    "admins = pl.read_csv('./data/famine-country-province-district-years-CS.csv', schema_overrides={\"CS\": pl.Float64})\n",
    "valid_matching = pl.read_csv('./data/matching_districts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(time_series.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 532)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th></th><th>index</th><th>country</th><th>admin_code</th><th>admin_name</th><th>centx</th><th>centy</th><th>year_month</th><th>year</th><th>month</th><th>fews_ipc</th><th>fews_ha</th><th>fews_proj_near</th><th>fews_proj_near_ha</th><th>fews_proj_med</th><th>fews_proj_med_ha</th><th>ndvi_mean</th><th>ndvi_anom</th><th>rain_mean</th><th>rain_anom</th><th>et_mean</th><th>et_anom</th><th>acled_count</th><th>acled_fatalities</th><th>p_staple_food</th><th>area</th><th>cropland_pct</th><th>pop</th><th>ruggedness_mean</th><th>pasture_pct</th><th>change_fews</th><th>land seizures_0</th><th>land seizures_1</th><th>land seizures_2</th><th>slashed export_0</th><th>slashed export_1</th><th>slashed export_2</th><th>&hellip;</th><th>authoritarian_2</th><th>dictators_0</th><th>dictators_1</th><th>dictators_2</th><th>clans_0</th><th>clans_1</th><th>clans_2</th><th>gastrointestinal_0</th><th>gastrointestinal_1</th><th>gastrointestinal_2</th><th>terrorist_0</th><th>terrorist_1</th><th>terrorist_2</th><th>warlord_0</th><th>warlord_1</th><th>warlord_2</th><th>d&#x27;etat_0</th><th>d&#x27;etat_1</th><th>d&#x27;etat_2</th><th>overthrow_0</th><th>overthrow_1</th><th>overthrow_2</th><th>convoys_0</th><th>convoys_1</th><th>convoys_2</th><th>carbon_0</th><th>carbon_1</th><th>carbon_2</th><th>mayhem_0</th><th>mayhem_1</th><th>mayhem_2</th><th>dehydrated_0</th><th>dehydrated_1</th><th>dehydrated_2</th><th>mismanagement_0</th><th>mismanagement_1</th><th>mismanagement_2</th></tr><tr><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>30</td><td>&quot;Afghanistan&quot;</td><td>202</td><td>&quot;Kandahar&quot;</td><td>65.709343</td><td>31.043618</td><td>&quot;2009_07&quot;</td><td>2009</td><td>7</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.106035</td><td>106.547146</td><td>0.353588</td><td>-0.070848</td><td>0.191125</td><td>-0.073903</td><td>0</td><td>0</td><td>1.065669</td><td>54174.53381</td><td>1.417796</td><td>1.241226e6</td><td>101047.1587</td><td>16.246279</td><td>0.0</td><td>-0.765667</td><td>-0.426667</td><td>0.886</td><td>0.597667</td><td>-0.987</td><td>1.449333</td><td>&hellip;</td><td>0.75</td><td>0.496</td><td>1.557333</td><td>1.252333</td><td>0.827</td><td>-0.035667</td><td>-0.02</td><td>-0.192</td><td>0.281667</td><td>-0.259667</td><td>-0.284333</td><td>1.626</td><td>0.532667</td><td>-0.668667</td><td>1.497333</td><td>-0.794667</td><td>0.647333</td><td>1.652333</td><td>-0.029</td><td>-0.891333</td><td>0.848333</td><td>1.472667</td><td>0.112667</td><td>-0.887</td><td>-0.963667</td><td>1.265333</td><td>-0.493667</td><td>1.053</td><td>0.667</td><td>-0.171</td><td>-0.833</td><td>0.173667</td><td>0.168</td><td>1.284667</td><td>-0.073</td><td>-0.427667</td><td>0.668333</td></tr><tr><td>1</td><td>33</td><td>&quot;Afghanistan&quot;</td><td>202</td><td>&quot;Kandahar&quot;</td><td>65.709343</td><td>31.043618</td><td>&quot;2009_10&quot;</td><td>2009</td><td>10</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.103009</td><td>106.034013</td><td>0.409304</td><td>-0.116134</td><td>0.69447</td><td>0.225598</td><td>0</td><td>0</td><td>1.100531</td><td>54174.53381</td><td>1.417796</td><td>1.241226e6</td><td>101047.1587</td><td>16.246279</td><td>1.0</td><td>-0.556272</td><td>-0.791605</td><td>-0.903605</td><td>-0.933739</td><td>-0.645739</td><td>-0.918405</td><td>&hellip;</td><td>-1.027332</td><td>-0.665846</td><td>-0.591846</td><td>-1.039846</td><td>-0.756904</td><td>-0.590571</td><td>-1.234904</td><td>-0.545727</td><td>-0.474394</td><td>-0.841394</td><td>-1.037016</td><td>-0.917683</td><td>-0.787683</td><td>-0.811291</td><td>-0.713958</td><td>-1.257625</td><td>-0.850261</td><td>-0.831261</td><td>-0.759594</td><td>-0.948892</td><td>-1.198892</td><td>-0.883225</td><td>-0.728972</td><td>-1.203638</td><td>-0.874305</td><td>-0.765146</td><td>-1.141479</td><td>-0.660812</td><td>-0.63658</td><td>-0.520247</td><td>-0.782913</td><td>-0.671587</td><td>-0.612254</td><td>-0.926921</td><td>-0.510467</td><td>-0.625133</td><td>-0.452467</td></tr><tr><td>2</td><td>36</td><td>&quot;Afghanistan&quot;</td><td>202</td><td>&quot;Kandahar&quot;</td><td>65.709343</td><td>31.043618</td><td>&quot;2010_01&quot;</td><td>2010</td><td>1</td><td>2.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.1096</td><td>111.433187</td><td>3.894158</td><td>-2.333251</td><td>3.441319</td><td>-1.450951</td><td>0</td><td>0</td><td>0.98839</td><td>54174.53381</td><td>1.417796</td><td>1.280853e6</td><td>101047.1587</td><td>16.246279</td><td>0.0</td><td>-0.006667</td><td>0.431</td><td>0.67</td><td>0.755667</td><td>-0.263</td><td>-0.574</td><td>&hellip;</td><td>-0.307333</td><td>0.010333</td><td>0.485</td><td>-0.820333</td><td>1.460333</td><td>-0.351</td><td>0.817667</td><td>1.506333</td><td>1.484667</td><td>-0.378667</td><td>0.455</td><td>-0.871</td><td>0.766</td><td>1.595667</td><td>0.023667</td><td>-0.968667</td><td>0.571667</td><td>-0.837333</td><td>0.444667</td><td>0.279</td><td>0.078</td><td>0.614333</td><td>-0.868333</td><td>-0.598</td><td>1.316</td><td>0.058333</td><td>1.368</td><td>-0.134333</td><td>1.447667</td><td>-0.844333</td><td>0.778667</td><td>-0.676</td><td>-0.689667</td><td>0.293333</td><td>0.530333</td><td>-0.471333</td><td>0.955333</td></tr><tr><td>3</td><td>39</td><td>&quot;Afghanistan&quot;</td><td>202</td><td>&quot;Kandahar&quot;</td><td>65.709343</td><td>31.043618</td><td>&quot;2010_04&quot;</td><td>2010</td><td>4</td><td>2.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.111599</td><td>94.212242</td><td>1.609664</td><td>-0.788739</td><td>1.851542</td><td>-0.771469</td><td>0</td><td>0</td><td>0.992492</td><td>54174.53381</td><td>1.417796</td><td>1.280853e6</td><td>101047.1587</td><td>16.246279</td><td>-1.0</td><td>-0.193697</td><td>-0.613697</td><td>-0.307364</td><td>0.311536</td><td>0.337869</td><td>-0.524797</td><td>&hellip;</td><td>-0.369667</td><td>-0.090077</td><td>0.224923</td><td>-0.58841</td><td>-0.616381</td><td>-0.605381</td><td>-0.114381</td><td>-0.79397</td><td>0.29903</td><td>-0.63397</td><td>-0.722159</td><td>-0.130159</td><td>-0.123825</td><td>-0.130521</td><td>-0.578521</td><td>0.090146</td><td>0.04763</td><td>0.137297</td><td>-0.603036</td><td>0.362613</td><td>0.231613</td><td>0.018279</td><td>0.480986</td><td>-0.427347</td><td>-0.121014</td><td>0.026073</td><td>0.165406</td><td>-0.326927</td><td>-0.594877</td><td>0.16479</td><td>-0.90521</td><td>-0.62054</td><td>0.165794</td><td>0.045794</td><td>-1.0116</td><td>-0.8106</td><td>-0.2056</td></tr><tr><td>4</td><td>42</td><td>&quot;Afghanistan&quot;</td><td>202</td><td>&quot;Kandahar&quot;</td><td>65.709343</td><td>31.043618</td><td>&quot;2010_07&quot;</td><td>2010</td><td>7</td><td>1.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0.096943</td><td>97.411677</td><td>0.3938336</td><td>-0.030602</td><td>0.291468</td><td>0.026441</td><td>0</td><td>0</td><td>1.024889</td><td>54174.53381</td><td>1.417796</td><td>1.280853e6</td><td>101047.1587</td><td>16.246279</td><td>1.0</td><td>-0.787272</td><td>-0.725605</td><td>-0.879272</td><td>-0.598072</td><td>-0.803072</td><td>-0.817739</td><td>&hellip;</td><td>-0.748332</td><td>-0.611846</td><td>-0.511179</td><td>-0.470512</td><td>-0.791904</td><td>-1.053238</td><td>-0.653238</td><td>-0.509394</td><td>-0.462727</td><td>-0.856727</td><td>-0.69435</td><td>-1.102683</td><td>-1.13235</td><td>-1.215958</td><td>-0.832291</td><td>-0.948291</td><td>-0.865261</td><td>-0.812261</td><td>-0.645928</td><td>-1.119225</td><td>-0.977558</td><td>-0.758892</td><td>-1.060638</td><td>-0.876972</td><td>-1.210305</td><td>-0.673479</td><td>-1.090479</td><td>-1.085146</td><td>-0.709913</td><td>-0.867913</td><td>-0.770247</td><td>-0.787921</td><td>-0.974587</td><td>-0.946921</td><td>-0.611133</td><td>-0.7098</td><td>-0.6228</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 532)\n",
       "â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
       "â”‚     â”† index â”† country     â”† admin_code â”† â€¦ â”† dehydrated_ â”† mismanageme â”† mismanagem â”† mismanagem â”‚\n",
       "â”‚ --- â”† ---   â”† ---         â”† ---        â”†   â”† 2           â”† nt_0        â”† ent_1      â”† ent_2      â”‚\n",
       "â”‚ i64 â”† i64   â”† str         â”† i64        â”†   â”† ---         â”† ---         â”† ---        â”† ---        â”‚\n",
       "â”‚     â”†       â”†             â”†            â”†   â”† f64         â”† f64         â”† f64        â”† f64        â”‚\n",
       "â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•â•¡\n",
       "â”‚ 0   â”† 30    â”† Afghanistan â”† 202        â”† â€¦ â”† 1.284667    â”† -0.073      â”† -0.427667  â”† 0.668333   â”‚\n",
       "â”‚ 1   â”† 33    â”† Afghanistan â”† 202        â”† â€¦ â”† -0.926921   â”† -0.510467   â”† -0.625133  â”† -0.452467  â”‚\n",
       "â”‚ 2   â”† 36    â”† Afghanistan â”† 202        â”† â€¦ â”† 0.293333    â”† 0.530333    â”† -0.471333  â”† 0.955333   â”‚\n",
       "â”‚ 3   â”† 39    â”† Afghanistan â”† 202        â”† â€¦ â”† 0.045794    â”† -1.0116     â”† -0.8106    â”† -0.2056    â”‚\n",
       "â”‚ 4   â”† 42    â”† Afghanistan â”† 202        â”† â€¦ â”† -0.946921   â”† -0.611133   â”† -0.7098    â”† -0.6228    â”‚\n",
       "â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_variant_traditional_factors = [ 'p_staple_food']\n",
    "t_variant_traditional_factors = ['ndvi_mean', 'ndvi_anom', 'rain_mean', 'rain_anom', 'et_mean', 'et_anom', \n",
    "                                    'acled_count', 'acled_fatalities', 'p_staple_food']\n",
    "t_invariant_traditional_factors = ['area', 'cropland_pct', 'pop', 'ruggedness_mean', 'pasture_pct']\n",
    "news_factors = [name for name in time_series.columns if '_0' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'land seizures_0'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_factors[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count BEFORE dropping:  532\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count BEFORE dropping: \", len(time_series.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\"\", \"centx\", \"centy\", 'change_fews', 'fews_ha', 'fews_proj_med', 'fews_proj_med_ha', 'fews_proj_near_ha'] + [col for col in time_series.columns if col.endswith(('_1', '_2', '_3'))]\n",
    "time_series = time_series.drop(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential extra columns ['admin_code', 'admin_name', 'country', 'fews_ipc', 'fews_proj_near', 'index', 'month', 'year', 'year_month']\n"
     ]
    }
   ],
   "source": [
    "potential_extra_cols = set(time_series.columns) - set(t_variant_traditional_factors) - set(t_invariant_traditional_factors) - set(news_factors)\n",
    "potential_extra_cols = [col for col in potential_extra_cols if not col.endswith(('_1', '_2', '_3'))]\n",
    "print(\"Potential extra columns\", sorted(potential_extra_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns count after dropping:  190\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns count after dropping: \", len(time_series.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒ Admin Level Mapping: Standardizing Geographical Identifiers\n",
    "\n",
    "In this section, we will **map and standardize** the `admin_code` and `admin_name` fields to their corresponding **district, province, and country names**. This step is **crucial** for ensuring **consistency** across different datasets and enabling **accurate aggregations** at multiple administrative levels.\n",
    "\n",
    "ğŸ›  **Why is Admin Level Mapping Important?**\n",
    "âœ… Different datasets may use **slightly different spellings or formats** for district names.  \n",
    "âœ… Some district names might be **missing or misspelled**, requiring standardization.  \n",
    "âœ… We need to **match and align** district names across various sources before aggregating at **province and country levels**.  \n",
    "âœ… Proper mapping allows us to **merge datasets correctly** without losing information.  \n",
    "\n",
    "ğŸ“Œ **Steps in Admin Mapping**\n",
    "1ï¸âƒ£ **Load the `matching_districts.csv` file**, which provides the mapping between different district name variations.  \n",
    "2ï¸âƒ£ **Identify missing or unmatched `admin_name` values** and find their closest matches using fuzzy matching techniques.  \n",
    "3ï¸âƒ£ **Ensure that each `admin_code` uniquely maps to one `district`, `province`, and `country`.**  \n",
    "4ï¸âƒ£ **Replace inconsistent names** in the dataset with their standardized versions.  \n",
    "5ï¸âƒ£ **Aggregate data at the `province` and `country` levels** after ensuring all districts are correctly mapped.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n"
     ]
    }
   ],
   "source": [
    "print(admins.select(pl.col(\"country\").n_unique()).to_numpy()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'country', 'district', 'year', 'month', 'CS', 'province']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "admins.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_names = time_series['admin_name'].unique()\n",
    "districts = admins['district'].unique()\n",
    "provinces = admins['province'].unique()\n",
    "countries = admins['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1142 4113 474 39\n",
      "369\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "print (len(admin_names), len(districts), len(provinces), len(countries))\n",
    "print (len(set(admin_names).difference(districts)))\n",
    "missing_admin_names = set(admin_names).difference(districts)\n",
    "print (len(missing_admin_names.difference(provinces)))\n",
    "missing_admin_names = missing_admin_names.difference(provinces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fuzzy String Matching for Missing Names\n",
    "\n",
    "The function uses **fuzzy string matching** to find the best approximate matches for missing administrative names (e.g., districts and provinces). \n",
    "\n",
    "- Finds the **best matching district/province** for each missing name.\n",
    "- Uses **fuzzy string matching** to calculate the similarity between missing names and known names.\n",
    "- Returns a dictionary that maps each missing name to its closest match.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bindura Bindura Urban Kindia\n",
      "Southern Tigray Soum Tigray\n",
      "Chiredzi Chiredzi Rural Moyen-Chari\n",
      "Lughaye Lughaya Kayes\n",
      "Saint-Raphael Saint Raphael Batha\n",
      "Adan Hamdan `Adan\n",
      "Gwanda Gwanda Rural Grand Kru\n",
      "Kwekwe Kwekwe Urban Kwale\n",
      "Bura' Bura Guera\n",
      "KantchÃ© Kantche Kano\n",
      "Koibatek Kibra Kogi\n",
      "East al Gazera Ganze Gaza\n",
      "Kabia Mambah Kaba Kajiado\n",
      "Barh El Gazel Nord Barh el Gazel Nord Nord\n",
      "Kananga City of Kananga Haut-Katanga\n",
      "Amran `Amran `Amran\n",
      "Mbeere Mbeere North Mbeya\n",
      "Grande Riviere Du Nord Grande Riviere du Nord Nord\n",
      "Caynabo Caynaba Gao\n",
      "Tanganyka Tanga Tanga\n",
      "Adan Yabaal Aadan Yabaal `Adan\n",
      "Sar-e-Pul Say Sari Pul\n",
      "Gweru Gweru Urban Meru\n",
      "Barh El Gazel Sud Barh el Gazel Sud Sud\n",
      "North Shewa(R4) North Shewa North\n",
      "Shabelle Shebelle Middle Shabelle\n",
      "Shar'ab As Salam Shar`ab As Salam Sila\n",
      "Special Woreda Dedza Nord\n",
      "Sharq al Gazera Ganze Gaza\n",
      "Al Mahagil Mahagi Al Mahrah\n",
      "Lubumbashi City of Lubumbashi Lahij\n",
      "En Nuhud Al Nuhud Sud\n",
      "Ghebeish Nesh Gombe\n",
      "Chegutu Chegutu Rural Hodh ech Chargui\n",
      "Majang Lal Wa Sarjangal Mahajanga\n",
      "Beni City of Beni Benshangul Gumuz\n",
      "Bulo Burto Bulo-Burte Borno\n",
      "Al Roseires El Roseires Zaire\n",
      "Mwene-Ditu City of Mwene-Ditu Kitui\n",
      "Wardi Hawar Wadi Hawar Bari\n",
      "Khartoum Bahri Khartoum Khartoum\n",
      "Al Faw Bayt Al Faqih Al Jawf\n",
      "Wedza Hwedza Wardak\n",
      "Kisangani City of Kisangani Tanga\n",
      "Al Fasher El Fasher Al Mahrah\n",
      "Hamashkorieb Hamashkoreib Ghor\n",
      "Croix-Des-Bouquets Bo Ouest\n",
      "Rachuonyo Karachuonyo Oyo\n",
      "Cayes Les Cayes Kayes\n",
      "South al Gazera Ganze Gaza\n",
      "Central Kisii Kiri Central\n",
      "Ad Dinder Ad Dis Zinder\n",
      "Jebrat al Sheikh Jebrat El Sheikh Herat\n",
      "Kindu City of Kindu Kindia\n",
      "Keiyo Keiyo North Oyo\n",
      "Nahr Atbara Atbara Mara\n",
      "Mt Elgon Mt. Elgon Bong\n",
      "North al Gazera Ganze North\n",
      "Mutare Mutare Urban Matabeleland North\n",
      "As Salam Shar`ab As Salam Dar es Salaam\n",
      "Al Ma'afir Al Ma`afir Mara\n",
      "Ndjamena N'Djamena N'Djamena\n",
      "TÃ©ra Tera Taraba\n",
      "Butembo City of Butembo Kemo\n",
      "Nandi South Nnewi South Nandi\n",
      "Nandi North Nnewi North Nandi\n",
      "Barh El Gazel Ouest Barh el Gazel Ouest Ouest\n",
      "Butere Mumias Butere Mombasa\n",
      "BankilarÃ© Bankilare Sila\n",
      "FilinguÃ© Filingue Enugu\n",
      "Al Gutaina El Gutaina Rutana\n",
      "West Harerge West Hararge West Darfur\n",
      "Al Wazi'iyah Al Wazi`iyah Wajir\n",
      "Al Marawi'ah Marawi Mara\n",
      "Mayo Binder Mayo-Binder Zinder\n",
      "Gedio Gedeo Gedo\n",
      "Seteet Seme Tete\n",
      "Saint Louis Du Nord Saint-Louis du Nord Nord\n",
      "Shurugwi Shurugwi Rural Sud\n",
      "North Gonder North Gondar North\n",
      "Hareri Harper Harari\n",
      "Ville de Tahoua Tahoua Tahoua\n",
      "Ceca La Source Cerca La Source Sud\n",
      "La PendÃ© La Pende Lac\n",
      "Al Deain Doedain Al Mahwit\n",
      "Zallingi Zalingei Singida\n",
      "Western Tigray Wete Western\n",
      "Selti Selibaby Copperbelt\n",
      "Lac-LÃ©rÃ© Lac-Lere Lac\n",
      "Baydhaba Baydhabo Bay\n",
      "Chiengi Chienge Muchinga\n",
      "Teso Teso South Tshopo\n",
      "Burtinle Butinle Iilemi triangle\n",
      "Kelem Wellega Kelem Kwale\n",
      "Tesker Tasker Western\n",
      "Balleyara Bali Mara\n",
      "Al Rahd Al Wahdah Al Mahrah\n",
      "KT Kitui Central Kayes\n",
      "Ville de Maradi Maridi Mara\n",
      "Abu Hamad Abu Hamed Hilmand\n",
      "Port-Au-Prince Port au Prince Ituri\n",
      "At Ta'izziyah At Ta`izziyah Ta'izz\n",
      "Al Fushqa Al Husha' Arusha\n",
      "Chipinge Chipinge Urban Uige\n",
      "Ville de Niamey Nika Niamey\n",
      "South Khartoum Khartoum Khartoum\n",
      "Damagaram Takaya Takaya Mara\n",
      "Kabkabiya Kebkabiya Abia\n",
      "Port-Salut Port Salut Salamat\n",
      "Al Galabat Eastern El Galabat Gaza\n",
      "Al Gash Al Hashwah Al Mahrah\n",
      "Kajo-keji Kajo-Keji Kano\n",
      "Id El Ghanem Ganze Kanem\n",
      "Siti Kitui Central Tharaka Nithi\n",
      "Eastern Tigray Wase Tigray\n",
      "Kolwezi.1 City of Kolwezi Kwale\n",
      "Muranga Mkuranga Murang'a\n",
      "Bale.1 Bale Bay\n",
      "Owdweyne Oodweyne Benue\n",
      "MaÃ¯nÃ© Soroa Maine Soroa Sool\n",
      "Sheikh Jebrat El Sheikh Sahel\n",
      "Al Geneina El Geneina Peten\n",
      "Bukavu City of Bukavu Busia\n",
      "Djourouf Al Ahmar Sourou Dhamar\n",
      "Mwingi Mwingi Central Bamingui-Bangoran\n",
      "GothÃ¨ye Gotheye Gao\n",
      "Barh-KÃ´h Barh-Koh Bari\n",
      "Kibale Kabale Kidal\n",
      "MPongwe Mpongwe Bong\n",
      "Kolwezi City of Kolwezi Jonglei\n",
      "Rab Dhuure Rabdhuure Central Darfur\n",
      "Amanat Al 'Asimah Arsi Amanat Al `Asimah\n",
      "Zvishavane Zvishavane Rural Kanem\n",
      "Gebiley Gabiley White Nile\n",
      "Marakwet Marakwet East Elgeyo-Marakwet\n",
      "Meru Central Meru Central\n",
      "Ad Douiem El Douiem Ad Dali`\n",
      "Addabah Rabah Assaba\n",
      "Ville de Zinder Gile Zinder\n",
      "Ad Damazin Daman Adamawa\n",
      "Komonjdjari Komondjari Kemo\n",
      "North Shewa(R3) North Shewa North\n",
      "Mashra'ah wa Hadnan Mashra`ah wa Hadnan Kankan\n",
      "Um Al Gura Guera Guera\n",
      "Awi/Agew Awi Uige\n",
      "Hirat Herat Hiiraan\n",
      "Um Badda Fada Bay\n",
      "Al Kurumik Qulansiyah wa `Abd Al Kuri Ituri\n",
      "Baw Kisarawe Bauchi\n",
      "TillabÃ©ri Tillaberi Commune Tillaberi\n",
      "Ad Damer Ad Dihar Dhamar\n",
      "North Western Tigray Oru West Western\n",
      "Anse-D'Ainault `Ain Abia\n",
      "Mayo-Lemi Mayo-Lemie Oyo\n",
      "Laasqoray Say Tabora\n",
      "Sud-Kivu Kiru Sud\n",
      "Sowdari Sodari Bari\n",
      "Mole Saint Nicolas Mole Saint-Nicolas White Nile\n",
      "Meru South Meru Meru\n",
      "Maragua Maragwa Mara\n",
      "Merawi Marawi Mara\n",
      "Lulua Teculutan Lualaba\n",
      "Kuria Kuria West Ituri\n",
      "Sheikan Shiekan Shinyanga\n",
      "Bossaso Bo Grand Bassa\n",
      "South Gonder South Gondar Sud\n",
      "Acul Du Nord Acul du Nord Nord\n",
      "Al Jabalian Jaba Al Jawf\n",
      "Belet Weyne Bale Benue\n",
      "Kas Kasese Kasai-Oriental\n",
      "La Nya PendÃ© La Nya Lac\n",
      "Sharg En Nile Sahar Niger\n",
      "Valliere Vallieres Niger\n",
      "Um Kadada Um Keddada Kandahar\n",
      "Agnuak Awgu Ouaka\n",
      "Tulus Kalulushi Retalhuleu\n",
      "Gokwe South Gokwe South Rural Southern\n",
      "Banadir Banwa Banaadir\n",
      "Busia.1 Busia Busia\n",
      "Sami' Sami` Lomami\n",
      "Wadi Halfa Halfa Wadi Fira\n",
      "IllÃ©la Illela Matabeleland North\n",
      "Trans Mara Marka Mara\n",
      "Likasi City of Likasi Likouala\n",
      "Belet Xaawo Beled-Xaawo Gao\n",
      "AguiÃ© Aguie Hodh ech Chargui\n",
      "Shar'ab Ar Rawnah Shar`ab Ar Rawnah Mara\n",
      "Gourma-Rharous Gourma Ghor\n",
      "Bandarbeyla Bandar Beyla Mbeya\n",
      "Karary Karaye Kwara\n",
      "Port De Paix Port de Paix Pwani\n",
      "Al Gadaref Gada Gedaref\n",
      "MangalmÃ© Mangalme Tanga\n",
      "Nyala.1 Nyala Nampula\n",
      "Nord-Kivu Kiru Nord\n",
      "Sa'dah As Saddah Sa`dah\n",
      "East Harerge East Hararge East Darfur\n",
      "Doolo Doolow Pool\n",
      "Tayeeglow Tiyeglow Bay\n",
      "Meru North Meru North\n",
      "Hwange Hwange Rural Kanem\n",
      "Guji Gujii Guidimaka\n",
      "Belbedji Idjwi Abyei\n",
      "GourÃ© Gourma Ghor\n",
      "Mangwe (South) Mangwe Southern\n",
      "UMP Ulanga El Progreso\n",
      "Gonave La Gonave Gao\n",
      "Abu Jubaiyah Juba Raymah\n",
      "Addis Adaba Alaba Addis Ababa\n",
      "Iriba Kariba Central Equatoria\n",
      "Goma Goma Tsetse Bungoma\n",
      "Mbuji-Mayi City of Mbuji-Mayi Bay\n",
      "Segen Peoples' Segen Benue\n",
      "Bulilima (North) Bulilima North\n",
      "Lafon Lopa/Lafon Lac\n",
      "Mawza' Mawza` Gaza\n",
      "Anse-A-Veau `Ans Lamu\n",
      "Trou Du Nord Trou du Nord Nord\n",
      "Kasai.1 Kpaai Kasai\n",
      "Mayo Boneye Bo Bong\n",
      "Thika Thika Town Vihiga\n",
      "Ad Dali' Ad Dali` Ad Dali`\n",
      "Beitbridge Beitbridge Rural Uige\n",
      "Galdogob Goldogob Edo\n",
      "Gucha Kabuchai Ahuachapan\n",
      "Taleex Talex Woqooyi Galbeed\n",
      "Al Kamlin Kamuli Kigali\n",
      "Buret Bureti Logone Oriental\n",
      "Kadoma Kadoma Urban Kano\n",
      "Berber Berbera N'Zerekore\n"
     ]
    }
   ],
   "source": [
    "def find_matching(missing, names):\n",
    "    matching_districts = {}\n",
    "    for m in missing:\n",
    "        max_overlap = 0\n",
    "        nearest_d = None\n",
    "        for d in names:\n",
    "            d = str(d)\n",
    "            dist = fuzz.partial_ratio(m, d)\n",
    "            if dist > max_overlap:\n",
    "                max_overlap = dist\n",
    "                nearest_d = d\n",
    "        matching_districts[m] = nearest_d\n",
    "    return matching_districts\n",
    "\n",
    "\n",
    "matching = find_matching(missing_admin_names, districts)\n",
    "matching_p = find_matching(missing_admin_names, provinces)\n",
    "\n",
    "# manually verify matching and update\n",
    "for k in matching.keys():\n",
    "    print (k, matching[k], matching_p[k])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding Decoding\n",
    "\n",
    "`to_ascii_escaped(s)`: Converts a Unicode string to an ASCII-safe representation using **unicode-escape**.\n",
    "\n",
    "`from_ascii_escaped(escaped)`: Converts the escaped ASCII string back into its original Unicode form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    # Using 'unicode-escape' encoding produces a bytes object,\n",
    "    # then decode it to get an ASCII string.\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def from_ascii_escaped(escaped):\n",
    "    \"\"\"\n",
    "    Convert the ASCII-escaped string back to the original Unicode string.\n",
    "    \"\"\"\n",
    "    # Encode the ASCII string to bytes, then decode using 'unicode-escape'\n",
    "    return escaped.encode('ascii').decode('unicode-escape')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Province for a Given District or Province\n",
    "\n",
    "`find_province(x)`, finds the **province** corresponding to a given administrative name. It accounts for:\n",
    "- **Direct Lookups** (Exact match in known district/province lists)\n",
    "- **Fuzzy Matching** (Using ASCII-safe transformation for inconsistent text encoding)\n",
    "- **Validation Against a Predefined Mapping (`valid_matching`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define matched globally\n",
    "matched = valid_matching['missing'].unique()\n",
    "\n",
    "def to_ascii_escaped(s):\n",
    "    \"\"\"\n",
    "    Convert a Unicode string to an ASCII-safe string using unicode-escape.\n",
    "    This will replace non-ASCII characters with their escape sequences.\n",
    "    \"\"\"\n",
    "    if isinstance(s, bytes):\n",
    "        s = s.decode('utf-8')\n",
    "    return s.encode('unicode-escape').decode('ascii')\n",
    "\n",
    "def find_province(x):\n",
    "    try:\n",
    "        # Ensure x is a Unicode string.\n",
    "        if isinstance(x, bytes):\n",
    "            x = x.decode('utf-8')\n",
    "        \n",
    "        # Direct lookup in districts or provinces.\n",
    "        if x in districts:\n",
    "            return admins[admins['district'] == x]['province'].values[0]\n",
    "        elif x in provinces:\n",
    "            return x\n",
    "\n",
    "        # Convert x to an ASCII-escaped version.\n",
    "        escaped_x = to_ascii_escaped(x)\n",
    "        \n",
    "        # Check if the escaped version is in matched.\n",
    "        if escaped_x in matched:\n",
    "            v = valid_matching[valid_matching['missing'] == escaped_x]\n",
    "            if v['match'].values[0] == 'district':\n",
    "                x2 = v['district'].values[0]\n",
    "                return admins[admins['district'] == x2]['province'].values[0]\n",
    "            elif v['match'].values[0] == 'province':\n",
    "                return v['province'].values[0]\n",
    "        \n",
    "        # If no conditions are met, raise an exception.\n",
    "        raise Exception(\"No matching province found\")\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Province not found for: {} ({})\".format(x, e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Admin Names with Accented Characters and Mapping to Provinces\n",
    "\n",
    "Maps `admin_names` to provinces using the `find_province(a)` function.  \n",
    "If a **direct lookup fails**, it tries to handle cases where the **admin name contains accented characters** (`Ã©`, `Ã¨`, `Ã´`) ->  (encoding decoding issues resolved through directly replacing these with 'e' or 'o', leads to finding a valid match). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_to_province = {}\n",
    "for a in admin_names:\n",
    "    try:\n",
    "        admin_to_province[a] = find_province(a)\n",
    "    except Exception as e:\n",
    "        # Print the admin name that caused an error\n",
    "        print(\"Error with:\", a)\n",
    "        # Check if a contains accented characters \"Ã©\" or \"Ã¨\"\n",
    "        if 'Ã©' in a or 'Ã¨' in a or 'Ã´' in a:\n",
    "            a_modified = a.replace('Ã©', 'e').replace('Ã¨', 'e').replace('Ã´', 'o')\n",
    "            # Check if the modified name is in districts\n",
    "            if a_modified in districts:\n",
    "                # Use the modified name to look up the province from admins\n",
    "                try:\n",
    "                    province = admins[admins['district'] == a_modified]['province'].values[0]\n",
    "                    admin_to_province[a] = province\n",
    "                    print(f\"Replaced '{a}' with '{a_modified}', found province: {province}\")\n",
    "                except Exception as ex:\n",
    "                    print(f\"Modified name '{a_modified}' not found in admins: {ex}\")\n",
    "            else:\n",
    "                print(f\"Modified name '{a_modified}' not in districts.\")\n",
    "        else:\n",
    "            print(f\"No accented e found in '{a}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping Administrative Names to Provinces in time_series\n",
    "\n",
    "Maps `admin_name` to their respective **provinces** using a precomputed dictionary - >`admin_to_province` in `time_series`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series['province'] = time_series['admin_name'].apply(\n",
    "#     lambda x: admin_to_province[x] if x in admin_to_province else admin_to_province.get(x.replace('Ã´', 'o'))\n",
    "# )\n",
    "def get_province(admin_name):\n",
    "    return (\n",
    "        admin_to_province.get(admin_name)\n",
    "        or admin_to_province.get(admin_name.replace('Ã´', 'o').replace('Ã©', 'e').replace('Ã¨', 'e'))\n",
    "        or \"Unknown\"\n",
    "    )\n",
    "\n",
    "time_series = time_series.with_columns(\n",
    "    pl.col(\"admin_name\").map_elements(get_province, return_dtype=pl.Utf8).alias(\"province\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_series[[\"admin_name\", \"province\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# â³ Time Lagging & Feature Engineering\n",
    "\n",
    "#### ğŸ“… **Why Use Lagging?**\n",
    "\n",
    "To predict food insecurity **for a given quarter**, we use:\n",
    "\n",
    "- **6 months of historical values** for traditional & news-based features.\n",
    "- **Province & country-level aggregations** to capture broader shocks.\n",
    "- **6 quarters of lagged IPC phase values** to model temporal dependencies.\n",
    "\n",
    "#### âš¡ **Optimized Lagging Approach**\n",
    "\n",
    "To improve computational efficiency, we:\n",
    "âœ” Use `groupby()` for **fast province & country-level aggregations**.  \n",
    "âœ” Merge lagged data via `merge()` instead of slow `.apply()`.  \n",
    "âœ” Only keep **past data** to ensure no data leakage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_lagged(features, start=3, end=9, diff=1, agg=True, time_series=time_series):\n",
    "    levels = ['', '_province', '_country'] if agg else ['']\n",
    "    \n",
    "    # Work on a copy to avoid modifying the original during processing\n",
    "    working_df = time_series.copy()\n",
    "    \n",
    "    # Precompute a mapping for each feature (with its suffix) for fast lookups.\n",
    "    # For each row, its lookup key will be: admin_code + '_' + year_month.\n",
    "    lookup_maps = {}  # dict mapping f_s -> mapping dict\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f + suffix\n",
    "            # Build a mapping from key to first occurrence of f_s value.\n",
    "            # Key: admin_code + '_' + year_month\n",
    "            keys = working_df['admin_code'].astype(str) + '_' + working_df['year_month'].astype(str)\n",
    "            # If there are duplicates, the first occurrence will be used.\n",
    "            mapping = dict(zip(keys, working_df[f_s]))\n",
    "            lookup_maps[f_s] = mapping\n",
    "\n",
    "    # Prepare list to collect all new columns (as Series)\n",
    "    new_cols = {}\n",
    "    \n",
    "    # Process each feature and lag combination\n",
    "    for suffix in levels:\n",
    "        for f in features:\n",
    "            f_s = f + suffix\n",
    "            mapping = lookup_maps[f_s]\n",
    "            for t in range(start, end, diff):\n",
    "                col_name = f\"{f_s}_{t}\"\n",
    "                if col_name in time_series.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Compute lagged month and lagged year (vectorized)\n",
    "                month = working_df['month']\n",
    "                year = working_df['year']\n",
    "                l_month = ((month - 1 - t) % 12) + 1\n",
    "                l_year = np.where(month - t <= 0, year - 1, year) # If (month - t) is less than or equal to 0 (i.e., youâ€™ve gone into the previous year), then l_year is year - 1; otherwise, it remains year.\n",
    "                \n",
    "                # Build the reference key: admin_code + '_' + \"{l_year}_{l_month}\"\n",
    "                ref_key = working_df['admin_code'].astype(str) + '_' + \\\n",
    "                          l_year.astype(str) + '_' + \\\n",
    "                          l_month.astype(str)\n",
    "                \n",
    "                # Map the reference key to the lagged feature values using our precomputed mapping.\n",
    "                # Where no match is found, use the current value from working_df[f_s].\n",
    "                lagged_values = ref_key.map(mapping)\n",
    "                lagged_values = lagged_values.fillna(working_df[f_s])\n",
    "                \n",
    "                # Store the new column in our dictionary (preserving the original index)\n",
    "                new_cols[col_name] = lagged_values\n",
    "                \n",
    "    # If any new columns were created, add them to the original time_series DataFrame.\n",
    "    if new_cols:\n",
    "        new_cols_df = pd.DataFrame(new_cols, index=working_df.index)\n",
    "        time_series = pd.concat([time_series, new_cols_df], axis=1)\n",
    "        \n",
    "    return time_series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Province & Country-Level Aggregation\n",
    "\n",
    "This function aggregates feature values at the province and country levels to capture regional trends, aiding in food insecurity prediction. The process includes:\n",
    "\n",
    "- **Grouping by year_month and level:** Data is grouped by year_month and the specified level (province or country) to calculate the mean of features, reflecting regional trends over time.\n",
    "\n",
    "- **Applying transformations efficiently:** Instead of merging aggregated data, `transform(\"mean\")` is used to directly assign the computed mean to each row, avoiding unnecessary joins and improving performance.  \n",
    "\n",
    "#### âš¡ **Efficiency Gains**\n",
    "\n",
    "- **Fast Aggregation**: Uses `groupby()` for efficient aggregation.\n",
    "- **Avoids Costly Joins**: Eliminates the need for `merge()` by using `transform()` instead, reducing computational overhead.  \n",
    "- **Memory Efficiency**: Converts the `level` column to a categorical type to reduce memory usage.\n",
    "\n",
    "This approach ensures faster processing while maintaining the quality of aggregated features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_agg_factors(features, level='province'):\n",
    "    global time_series  \n",
    "\n",
    "    # Convert 'level' column to categorical for performance\n",
    "    time_series[level] = time_series[level].astype('category')\n",
    "    \n",
    "    # Compute grouped mean values for the given features\n",
    "    # TODO : Explain these arguments\n",
    "    grouped_df = time_series.groupby(['year_month', level], observed=True, sort=False)[features].transform(\"mean\")\n",
    "\n",
    "    # Rename columns to include level\n",
    "    grouped_df = grouped_df.rename(columns={f: f\"{f}_{level}\" for f in features})\n",
    "\n",
    "    # Use pd.concat() to add all columns at once, avoiding fragmentation\n",
    "    time_series = pd.concat([time_series, grouped_df], axis=1)\n",
    "\n",
    "    return time_series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m time_series = \u001b[43madd_agg_factors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnews_factors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36madd_agg_factors\u001b[39m\u001b[34m(features, level)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m time_series  \n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Convert 'level' column to categorical for performance\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m time_series[level] = \u001b[43mtime_series\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m(\u001b[33m'\u001b[39m\u001b[33mcategory\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Compute grouped mean values for the given features\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# TODO : Explain these arguments\u001b[39;00m\n\u001b[32m      9\u001b[39m grouped_df = time_series.groupby([\u001b[33m'\u001b[39m\u001b[33myear_month\u001b[39m\u001b[33m'\u001b[39m, level], observed=\u001b[38;5;28;01mTrue\u001b[39;00m, sort=\u001b[38;5;28;01mFalse\u001b[39;00m)[features].transform(\u001b[33m\"\u001b[39m\u001b[33mmean\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Series' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "time_series = add_agg_factors(news_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>gastrointestinal_0_country</th>\n",
       "      <th>terrorist_0_country</th>\n",
       "      <th>warlord_0_country</th>\n",
       "      <th>d'etat_0_country</th>\n",
       "      <th>overthrow_0_country</th>\n",
       "      <th>convoys_0_country</th>\n",
       "      <th>carbon_0_country</th>\n",
       "      <th>mayhem_0_country</th>\n",
       "      <th>dehydrated_0_country</th>\n",
       "      <th>mismanagement_0_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>-0.196791</td>\n",
       "      <td>-0.277796</td>\n",
       "      <td>-0.080313</td>\n",
       "      <td>-0.158093</td>\n",
       "      <td>-0.091979</td>\n",
       "      <td>-0.205168</td>\n",
       "      <td>-0.351945</td>\n",
       "      <td>-0.004046</td>\n",
       "      <td>0.020729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123518</td>\n",
       "      <td>-0.169664</td>\n",
       "      <td>-0.039284</td>\n",
       "      <td>0.096598</td>\n",
       "      <td>-0.145231</td>\n",
       "      <td>-0.058545</td>\n",
       "      <td>0.024883</td>\n",
       "      <td>0.039075</td>\n",
       "      <td>-0.060053</td>\n",
       "      <td>-0.112890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194285</td>\n",
       "      <td>-0.051662</td>\n",
       "      <td>0.112230</td>\n",
       "      <td>0.271666</td>\n",
       "      <td>0.351302</td>\n",
       "      <td>0.175470</td>\n",
       "      <td>0.236345</td>\n",
       "      <td>0.159935</td>\n",
       "      <td>0.198416</td>\n",
       "      <td>0.409551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073142</td>\n",
       "      <td>-0.122469</td>\n",
       "      <td>0.135643</td>\n",
       "      <td>0.204327</td>\n",
       "      <td>0.101177</td>\n",
       "      <td>-0.144836</td>\n",
       "      <td>0.222670</td>\n",
       "      <td>0.156061</td>\n",
       "      <td>0.274630</td>\n",
       "      <td>0.180825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.158150</td>\n",
       "      <td>-0.068429</td>\n",
       "      <td>-0.161717</td>\n",
       "      <td>-0.187331</td>\n",
       "      <td>-0.139090</td>\n",
       "      <td>-0.142929</td>\n",
       "      <td>-0.010496</td>\n",
       "      <td>-0.081932</td>\n",
       "      <td>0.007388</td>\n",
       "      <td>0.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_10</td>\n",
       "      <td>2010</td>\n",
       "      <td>10</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.010606</td>\n",
       "      <td>-0.085573</td>\n",
       "      <td>0.147253</td>\n",
       "      <td>-0.040194</td>\n",
       "      <td>0.053930</td>\n",
       "      <td>-0.185165</td>\n",
       "      <td>0.172638</td>\n",
       "      <td>-0.085029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>48</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_01</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.092620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059419</td>\n",
       "      <td>-0.050372</td>\n",
       "      <td>-0.144964</td>\n",
       "      <td>-0.140235</td>\n",
       "      <td>-0.056617</td>\n",
       "      <td>-0.232453</td>\n",
       "      <td>-0.117227</td>\n",
       "      <td>0.117000</td>\n",
       "      <td>-0.111434</td>\n",
       "      <td>-0.100282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>51</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_04</td>\n",
       "      <td>2011</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.131462</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.283481</td>\n",
       "      <td>-0.311409</td>\n",
       "      <td>-0.295271</td>\n",
       "      <td>-0.370462</td>\n",
       "      <td>-0.298859</td>\n",
       "      <td>-0.246249</td>\n",
       "      <td>-0.109567</td>\n",
       "      <td>-0.168876</td>\n",
       "      <td>-0.335914</td>\n",
       "      <td>-0.276873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>54</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_07</td>\n",
       "      <td>2011</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.106885</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198956</td>\n",
       "      <td>0.232582</td>\n",
       "      <td>0.165008</td>\n",
       "      <td>0.475172</td>\n",
       "      <td>0.257077</td>\n",
       "      <td>0.246208</td>\n",
       "      <td>0.089489</td>\n",
       "      <td>0.217305</td>\n",
       "      <td>0.162207</td>\n",
       "      <td>0.096265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>57</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2011_10</td>\n",
       "      <td>2011</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.103268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456875</td>\n",
       "      <td>-0.102239</td>\n",
       "      <td>0.338327</td>\n",
       "      <td>0.302879</td>\n",
       "      <td>0.120221</td>\n",
       "      <td>0.354626</td>\n",
       "      <td>0.248271</td>\n",
       "      <td>0.316393</td>\n",
       "      <td>0.335178</td>\n",
       "      <td>0.232545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 525 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      country  admin_code admin_name year_month  year  month  \\\n",
       "0     30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1     33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2     36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3     39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4     42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "5     45  Afghanistan         202   Kandahar    2010_10  2010     10   \n",
       "6     48  Afghanistan         202   Kandahar    2011_01  2011      1   \n",
       "7     51  Afghanistan         202   Kandahar    2011_04  2011      4   \n",
       "8     54  Afghanistan         202   Kandahar    2011_07  2011      7   \n",
       "9     57  Afghanistan         202   Kandahar    2011_10  2011     10   \n",
       "\n",
       "   fews_ipc  fews_proj_near  ndvi_mean  ...  gastrointestinal_0_country  \\\n",
       "0       1.0             NaN   0.106035  ...                    0.009191   \n",
       "1       1.0             NaN   0.103009  ...                   -0.123518   \n",
       "2       2.0             NaN   0.109600  ...                    0.194285   \n",
       "3       2.0             NaN   0.111599  ...                   -0.073142   \n",
       "4       1.0             NaN   0.096943  ...                    0.158150   \n",
       "5       2.0             NaN   0.095377  ...                    0.014290   \n",
       "6       2.0             NaN   0.092620  ...                   -0.059419   \n",
       "7       2.0             2.0   0.131462  ...                   -0.283481   \n",
       "8       1.0             1.0   0.106885  ...                    0.198956   \n",
       "9       1.0             1.0   0.103268  ...                    0.456875   \n",
       "\n",
       "   terrorist_0_country  warlord_0_country  d'etat_0_country  \\\n",
       "0            -0.196791          -0.277796         -0.080313   \n",
       "1            -0.169664          -0.039284          0.096598   \n",
       "2            -0.051662           0.112230          0.271666   \n",
       "3            -0.122469           0.135643          0.204327   \n",
       "4            -0.068429          -0.161717         -0.187331   \n",
       "5            -0.021839           0.010606         -0.085573   \n",
       "6            -0.050372          -0.144964         -0.140235   \n",
       "7            -0.311409          -0.295271         -0.370462   \n",
       "8             0.232582           0.165008          0.475172   \n",
       "9            -0.102239           0.338327          0.302879   \n",
       "\n",
       "   overthrow_0_country  convoys_0_country  carbon_0_country  mayhem_0_country  \\\n",
       "0            -0.158093          -0.091979         -0.205168         -0.351945   \n",
       "1            -0.145231          -0.058545          0.024883          0.039075   \n",
       "2             0.351302           0.175470          0.236345          0.159935   \n",
       "3             0.101177          -0.144836          0.222670          0.156061   \n",
       "4            -0.139090          -0.142929         -0.010496         -0.081932   \n",
       "5             0.147253          -0.040194          0.053930         -0.185165   \n",
       "6            -0.056617          -0.232453         -0.117227          0.117000   \n",
       "7            -0.298859          -0.246249         -0.109567         -0.168876   \n",
       "8             0.257077           0.246208          0.089489          0.217305   \n",
       "9             0.120221           0.354626          0.248271          0.316393   \n",
       "\n",
       "   dehydrated_0_country  mismanagement_0_country  \n",
       "0             -0.004046                 0.020729  \n",
       "1             -0.060053                -0.112890  \n",
       "2              0.198416                 0.409551  \n",
       "3              0.274630                 0.180825  \n",
       "4              0.007388                 0.138598  \n",
       "5              0.172638                -0.085029  \n",
       "6             -0.111434                -0.100282  \n",
       "7             -0.335914                -0.276873  \n",
       "8              0.162207                 0.096265  \n",
       "9              0.335178                 0.232545  \n",
       "\n",
       "[10 rows x 525 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series = add_agg_factors(news_factors, level='country')\n",
    "time_series.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_agg_factors(t_variant_traditional_factors, level='province')\n",
    "time_series = add_agg_factors(t_variant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_agg_factors(t_invariant_traditional_factors, level='province')\n",
    "time_series = add_agg_factors(t_invariant_traditional_factors, level='country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time lagged features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(t_variant_traditional_factors, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(news_factors, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(['fews_ipc'], end=21, diff=3, agg=False, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series = add_time_lagged(['fews_proj_near'], start=3, end=4, diff=1, agg=False, time_series=time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diebold_mariano(preds, labels):\n",
    "    sq_error = [(p-l)**2 for p,l in zip(preds, labels)]\n",
    "    mean = np.mean(sq_error)\n",
    "    n = len(preds)\n",
    "    gammas = {}\n",
    "    m = max(n,int(math.ceil(np.cbrt(n))+2))\n",
    "    for k in range(m):\n",
    "        gammas[k] = 0\n",
    "        for i in range(k+1, n):\n",
    "            gammas[k] += (sq_error[i] - mean)*(sq_error[i-k] - mean)\n",
    "        gammas[k] = gammas[k]/n\n",
    "    sum_gamma = gammas[0]\n",
    "    for k in range(1, m):\n",
    "        sum_gamma += 2*gammas[k]\n",
    "    return np.sqrt(sum_gamma/n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>country</th>\n",
       "      <th>admin_code</th>\n",
       "      <th>admin_name</th>\n",
       "      <th>year_month</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>fews_ipc</th>\n",
       "      <th>fews_proj_near</th>\n",
       "      <th>ndvi_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>mismanagement_0_country_6</th>\n",
       "      <th>mismanagement_0_country_7</th>\n",
       "      <th>mismanagement_0_country_8</th>\n",
       "      <th>fews_ipc_3</th>\n",
       "      <th>fews_ipc_6</th>\n",
       "      <th>fews_ipc_9</th>\n",
       "      <th>fews_ipc_12</th>\n",
       "      <th>fews_ipc_15</th>\n",
       "      <th>fews_ipc_18</th>\n",
       "      <th>fews_proj_near_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_07</td>\n",
       "      <td>2009</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.106035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>0.020729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2009_10</td>\n",
       "      <td>2009</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.103009</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_01</td>\n",
       "      <td>2010</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>0.409551</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_04</td>\n",
       "      <td>2010</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112890</td>\n",
       "      <td>0.180825</td>\n",
       "      <td>0.180825</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>202</td>\n",
       "      <td>Kandahar</td>\n",
       "      <td>2010_07</td>\n",
       "      <td>2010</td>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096943</td>\n",
       "      <td>...</td>\n",
       "      <td>0.138598</td>\n",
       "      <td>0.138598</td>\n",
       "      <td>0.138598</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 3728 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      country  admin_code admin_name year_month  year  month  \\\n",
       "0     30  Afghanistan         202   Kandahar    2009_07  2009      7   \n",
       "1     33  Afghanistan         202   Kandahar    2009_10  2009     10   \n",
       "2     36  Afghanistan         202   Kandahar    2010_01  2010      1   \n",
       "3     39  Afghanistan         202   Kandahar    2010_04  2010      4   \n",
       "4     42  Afghanistan         202   Kandahar    2010_07  2010      7   \n",
       "\n",
       "   fews_ipc  fews_proj_near  ndvi_mean  ...  mismanagement_0_country_6  \\\n",
       "0       1.0             NaN   0.106035  ...                   0.020729   \n",
       "1       1.0             NaN   0.103009  ...                  -0.112890   \n",
       "2       2.0             NaN   0.109600  ...                   0.409551   \n",
       "3       2.0             NaN   0.111599  ...                  -0.112890   \n",
       "4       1.0             NaN   0.096943  ...                   0.138598   \n",
       "\n",
       "   mismanagement_0_country_7  mismanagement_0_country_8  fews_ipc_3  \\\n",
       "0                   0.020729                   0.020729         1.0   \n",
       "1                  -0.112890                  -0.112890         1.0   \n",
       "2                   0.409551                   0.409551         1.0   \n",
       "3                   0.180825                   0.180825         2.0   \n",
       "4                   0.138598                   0.138598         1.0   \n",
       "\n",
       "   fews_ipc_6  fews_ipc_9  fews_ipc_12  fews_ipc_15  fews_ipc_18  \\\n",
       "0         1.0         1.0          1.0          1.0          1.0   \n",
       "1         1.0         1.0          1.0          1.0          1.0   \n",
       "2         2.0         2.0          2.0          1.0          2.0   \n",
       "3         1.0         2.0          2.0          2.0          1.0   \n",
       "4         1.0         1.0          1.0          1.0          1.0   \n",
       "\n",
       "   fews_proj_near_3  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "\n",
       "[5 rows x 3728 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_series.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and save data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.metrics import root_mean_squared_error, precision_recall_curve, auc\n",
    "\n",
    "test_splits = [\n",
    "    ((2010,7), (2011, 7)), \n",
    "    ((2011,7), (2012, 7)),\n",
    "    ((2012,7), (2013, 7)), \n",
    "    ((2013,7), (2014, 7)), \n",
    "    ((2014,7), (2015, 7)), \n",
    "    ((2015,7), (2016, 7)), \n",
    "    ((2016,7), (2017, 7)), \n",
    "    # ((2017,7), (2018, 7)),\n",
    "    # ((2018,7), (2019, 7)), \n",
    "    # ((2019,2), (2020, 2)),\n",
    "]\n",
    "train_splits_old = [\n",
    "    ((2009,7), (2010,4)),\n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2009,7), (2011,10)),\n",
    "    ((2009,7), (2012,7)),\n",
    "    ((2009,7), (2013,7)),\n",
    "    ((2009,7), (2014,1)),\n",
    "    ((2009,7), (2015,1)),\n",
    "    ((2009,7), (2015,10)),\n",
    "    ((2009,7), (2016,10)),\n",
    "    ((2009,7), (2017,2))\n",
    "]\n",
    "dev_splits = [\n",
    "    ((2010,4),  (2010, 7)),\n",
    "    ((2011,1),  (2011, 7)),\n",
    "    ((2011,10), (2012, 7)),\n",
    "    ((2012,7),  (2013, 7)),\n",
    "    ((2013,4),  (2014, 7)),\n",
    "    ((2014,1),  (2015, 7)),\n",
    "    ((2015,1),  (2016, 7)),\n",
    "    ((2015,10), (2017, 7)),\n",
    "    # ((2016,10), (2018, 7)),\n",
    "    # ((2017,2), (2019, 2)),\n",
    "]\n",
    "\n",
    "# i just wanted to keep the training on a year or less. All values are taken from original train split but the start date is increased to reduce the time it is trained on. This is to stay consistent with testing across one year only - bilal.\n",
    "train_splits_new = [ \n",
    "    ((2009,7), (2011,1)),\n",
    "    ((2010,7), (2012,7)),\n",
    "    ((2011,7), (2013,7)),\n",
    "    ((2012,7), (2014,1)),\n",
    "    ((2013,7), (2015,10)),\n",
    "    ((2014,7), (2016,10)),\n",
    "    ((2015,7), (2017,2)),\n",
    "]\n",
    "\n",
    "train_splits =  train_splits_new\n",
    "\n",
    "# just like them we will evaluate three dufferent models, Random Forest, OLS and Lasso. Random Forest is a tree-based model, OLS is a linear regression model and Lasso is a linear regression model with L1 regularization\n",
    "models = {\n",
    "    # 'RF': RandomForestRegressor(max_features='sqrt', n_estimators=100, min_samples_split=0.5, min_impurity_decrease=0.001, random_state=0)\n",
    "    # 'RF': RandomForestRegressor(max_features='sqrt', n_estimators=275, min_samples_split=2, min_samples_leaf=1, min_impurity_decrease=0.001, random_state=0) #changed min split val to 2 bcs previously it was a float, min leaf will hopefully prevent overfitting tho i think 2 would have been a safer val but that increases error -saf\n",
    "    # 'RF': RandomForestRegressor(\n",
    "    #     max_features='sqrt',  # Keep this\n",
    "    #     n_estimators=500,  # Increase trees to reduce variance\n",
    "    #     min_samples_split=5,  # ğŸš¨ Fix this, should be an integer\n",
    "    #     min_samples_leaf=2,  # Helps prevent overfitting\n",
    "    #     max_depth=None,  # Allow full tree growth\n",
    "    #     bootstrap=True,  # Default setting, makes it more robust\n",
    "    #     random_state=0\n",
    "    # )\n",
    "    'RF': RandomForestRegressor()\n",
    "    \n",
    "    # 'OLS': LinearRegression(),\n",
    "    # 'Lasso': Lasso(alpha=0.1)\n",
    "}\n",
    "\n",
    "def get_agg_lagged_features(factors):\n",
    "    return [f\"{f}_{t}\" for f in factors for t in range(3, 9)] + \\\n",
    "           [f\"{f}_province_{t}\" for f in factors for t in range(3, 9)] + \\\n",
    "           [f\"{f}_country_{t}\" for f in factors for t in range(3, 9)]\n",
    "\n",
    "features = {\n",
    "    'traditional': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors],\n",
    "    \n",
    "    'news': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(news_factors)],\n",
    "    \n",
    "    'traditional+news': time_series[['year', 'month'] + \n",
    "        [f\"fews_ipc_{t}\" for t in range(3, 21, 3)] + \n",
    "        get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "        t_invariant_traditional_factors + \n",
    "        get_agg_lagged_features(news_factors)],\n",
    "    \n",
    "    # 'expert': time_series[['fews_proj_near_3' ] + ['year', 'month']],\n",
    "    \n",
    "    # 'expert+traditional': time_series[ ['year', 'month']+ \n",
    "    #     ['fews_proj_near_3'] +\n",
    "    #     ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] + \n",
    "    #     get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "    #     t_invariant_traditional_factors\n",
    "    # ],\n",
    "    # 'expert+news': time_series[ ['year', 'month'] +\n",
    "    #     ['fews_proj_near_3'] +\n",
    "    #     ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "    #     get_agg_lagged_features(news_factors)\n",
    "    # ],\n",
    "    # 'expert+traditional+news': time_series[ ['year', 'month'] +\n",
    "    #     ['fews_proj_near_3'] +\n",
    "    #     ['{}_{}'.format('fews_ipc', t) for t in range(3,21,3)] +\n",
    "    #     get_agg_lagged_features(t_variant_traditional_factors) + \n",
    "    #     t_invariant_traditional_factors +\n",
    "    #     get_agg_lagged_features(news_factors)\n",
    "    # ]\n",
    "}\n",
    "\n",
    "labels_df = time_series[['fews_ipc', 'year', 'month']]\n",
    "\n",
    "def get_time_split(df, start, end):\n",
    "    return df[\n",
    "        (((df['year'] > start[0])) | ((df['year'] == start[0]) & (df['month'] >= start[1]))) &\n",
    "        (((df['year'] < end[0])) | ((df['year'] == end[0]) & (df['month'] <= end[1])))\n",
    "    ]\n",
    "\n",
    "thresholds = {'traditional': (2.236, 3.125), \n",
    "              'news': (1.907, 2.712), \n",
    "              'traditional+news': (2.105, 3.314),\n",
    "            #   'expert': (2, 3),\n",
    "            #   'expert+news': (1.912, 2.813),\n",
    "            #   'expert+traditional': (2.241, 3.132),\n",
    "            #   'expert+traditional+news': (2.172, 3.321)\n",
    "             }\n",
    "\n",
    "def train_and_evaluate(train, dev, test, f, D):\n",
    "    results = []\n",
    "    \n",
    "    X_train = get_time_split(D, train[0], train[1]).drop(columns=['year', 'month']).to_numpy()# not sure how okay it is to do fillna. When me and Bilal were running this we were getting the error that cannot run the model on NaN values. First we dropped na but this was causing the shape of the X_train to be different from the y_train. So we decided to fillna with 0. - aysha & bilal\n",
    "    \n",
    "    y_train = get_time_split(labels_df, train[0], train[1]).drop(columns=['year', 'month']).to_numpy().ravel()\n",
    "\n",
    "    nan_mask = np.isnan(X_train).any(axis=1)\n",
    "    X_train = X_train[~nan_mask]\n",
    "    y_train = y_train[~nan_mask]\n",
    "    \n",
    "    X_test = get_time_split(D, test[0], test[1]).drop(columns=['year', 'month']).to_numpy()\n",
    "    y_test = get_time_split(labels_df, test[0], test[1]).drop(columns=['year', 'month']).to_numpy().ravel()\n",
    "    nan_mask_test = np.isnan(X_test).any(axis=1)\n",
    "    X_test = X_test[~nan_mask_test]\n",
    "    y_test = y_test[~nan_mask_test]\n",
    "    \n",
    "    # check if X train is empty:\n",
    "    print(f\"Rows in X_train: {X_train.shape[0]} \\nRows in X_test: {X_test.shape[0]}\")\n",
    "    if X_train.shape[0] <= 0:\n",
    "        # print(f\"X train is empty for {f} from {train}\")\n",
    "        return results\n",
    "    if X_test.shape[0] <= 0:\n",
    "        # print(f\"X test is empty for {f} from {test}\")\n",
    "        return results\n",
    "       \n",
    "    # convert y_test into binary classification (1 if inside threshold, else 0)\n",
    "    lower, upper = thresholds[f]\n",
    "    y_test_binary = np.where((y_test >= lower) & (y_test <= upper), 1, 0)\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        rmse = root_mean_squared_error(y_test, preds)\n",
    "        rmse = root_mean_squared_error(y_test, preds)\n",
    "\n",
    "        # stderr = np.std(y_test - preds) / np.sqrt(len(y_test))\n",
    "        # upper_bound = np.sqrt(rmse**2 + 1.96 * stderr)\n",
    "        # lower_bound = np.sqrt(rmse**2 - 1.96 * stderr)\n",
    "        # precision, recall, _ = precision_recall_curve(y_test_binary, preds)\n",
    "        # aucpr = auc(recall, precision)\n",
    "\n",
    "        results.append({\n",
    "            'method': name, 'split': test, 'features': f, \n",
    "            'rmse': rmse,\n",
    "            # 'rmse': rmse, 'lower_bound': lower_bound, 'upper_bound': upper_bound,\n",
    "            # 'aucpr': aucpr\n",
    "        })\n",
    "\n",
    "        # print(f\"Method: {name}, Split: {test}, Features: {f}, AUCPR: {aucpr:.4f}\")\n",
    "        # print(f\"Method: {name}, Split: {test}, Features: {f}, RMSE: {rmse:.4f} [{lower_bound:.4f}, {upper_bound:.4f}]\")\n",
    "        print(f\"Method: {name}, Split: {test}, Features: {f}, RMSE: {rmse:.4f}\")\n",
    "        \n",
    "    #     # completely removed the part where they were doing country-wise evaluation. Do not see point - aysha\n",
    "    \n",
    "    return results\n",
    "\n",
    "# run in parallel on 4 cpu cores/decrease this if you do not want ur system to crash (speaking from experience)\n",
    "all_results = Parallel(n_jobs=4)(\n",
    "    delayed(train_and_evaluate)(train, dev, test, f, D) for train, dev, test in zip(train_splits, dev_splits, test_splits) for f, D in features.items()\n",
    ")\n",
    "\n",
    "\n",
    "# all_results = []\n",
    "# for train, dev, test in zip(train_splits, dev_splits, test_splits):\n",
    "#     for f, D in features.items():\n",
    "#         try:\n",
    "#             all_results.append(train_and_evaluate(train, dev, test, f, D))\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {train} & {dev} & {test}\")\n",
    "#             continue\n",
    "\n",
    "\n",
    "fig_3a = pd.DataFrame([res for sublist in all_results for res in sublist])\n",
    "# fig_3a.to_csv('fig_3a.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method  features        \n",
       "RF      news                0.023906\n",
       "        traditional         0.013558\n",
       "        traditional+news    0.023813\n",
       "Name: rmse, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig_3a.groupby(by=['method', 'features'])['rmse'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If the train and the test dataset are the same:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.099734\n",
    "        traditional         0.027667\n",
    "        traditional+news    0.096902\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "**If we use their provided train-test split:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.400070\n",
    "        traditional         0.134550\n",
    "        traditional+news    0.390469\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "\n",
    "**If we use dev-test split:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.388210\n",
    "        traditional         0.132620\n",
    "        traditional+news    0.364279\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "**If we use train+dev-test split:**\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.400070\n",
    "        traditional         0.134550\n",
    "        traditional+news    0.390469\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "The reason why we get the same value regardless of whether we use the train-test split, or if we use train+dev-test split is because for each value of test split, a pair on the corresponding index of train value is taken to test the two together. this means if the test split is a list of 5 tuples, you will only train on the first 5 tuples of the train list and test them across the test list. Therefore making ur train sets longer does not by definition allow u to train on more data like that.\n",
    "\n",
    "Using the same model they have advertised, and mostly the same data, I tried to train and test on similar length of data. I did not modify their test splits at all. Without modifying their train splits a lot either, I came up with a new train split (mentioned in the code above) that gives the following error:\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.135289\n",
    "        traditional         0.104422\n",
    "        traditional+news    0.132082\n",
    "Name: rmse, dtype: float64\n",
    "```\n",
    "After parameter tuning, I was able to reduce the RMSE even further.\n",
    "By adjusting hyperparameters of the model (increasing n_estimators, changing min_samples_split to an integer value, and min_impurity_decrease=0.001), and keeping the same train-test split logic, I obtained:\n",
    "```\n",
    "method  features        \n",
    "RF      news                0.130263\n",
    "        traditional         0.089540\n",
    "        traditional+news    0.125813\n",
    "Name: rmse, dtype: float64\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
